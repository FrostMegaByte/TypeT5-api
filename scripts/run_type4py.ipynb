{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from spot.utils import proj_root, os\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from typing import Any, List, Tuple, Dict, Set, Union, Optional\n",
      "def parse_qualified_name(tree: ast.Attribute):\n",
      "    segs = []\n",
      "    while isinstance(tree, ast.Attribute):\n",
      "        segs.append(tree.attr)\n",
      "        tree = tree.value  # type: ignore\n",
      "    assert isinstance(tree, ast.Name)\n",
      "    segs.append(tree.id)\n",
      "    return tuple(reversed(segs))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_code = \"\"\"\n",
    "def parse_qualified_name(tree: ast.Attribute):\n",
    "    segs = []\n",
    "    while isinstance(tree, ast.Attribute):\n",
    "        segs.append(tree.attr)\n",
    "        tree = tree.value  # type: ignore\n",
    "    assert isinstance(tree, ast.Name)\n",
    "    segs.append(tree.id)\n",
    "    return tuple(reversed(segs))\n",
    "\"\"\"\n",
    "from spot.experiments.type4py import cst, remove_newer_syntax\n",
    "\n",
    "bad_code = remove_newer_syntax(cst.parse_module(bad_code)).code\n",
    "print(bad_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': None,\n",
       " 'response': {'classes': [],\n",
       "  'funcs': [{'docstring': {'func': None, 'long_descr': None, 'ret': None},\n",
       "    'fn_lc': [[2, 0], [9, 32]],\n",
       "    'fn_var_ln': {'segs': [[3, 4], [3, 8]], 'tree': [[6, 8], [6, 12]]},\n",
       "    'fn_var_occur': {'segs': [['segs', 'append', 'tree', 'attr'],\n",
       "      ['segs', 'append', 'tree', 'id'],\n",
       "      ['tuple', 'reversed', 'segs']],\n",
       "     'tree': [['isinstance', 'tree', 'ast', 'Attribute'],\n",
       "      ['segs', 'append', 'tree', 'attr'],\n",
       "      ['tree', 'tree', 'value'],\n",
       "      ['isinstance', 'tree', 'ast', 'Name'],\n",
       "      ['segs', 'append', 'tree', 'id']]},\n",
       "    'name': 'parse_qualified_name',\n",
       "    'params': {'tree': 'ast.Attribute'},\n",
       "    'params_descr': {'tree': ''},\n",
       "    'params_occur': {'tree': [['isinstance', 'tree', 'ast', 'Attribute'],\n",
       "      ['segs', 'append', 'tree', 'attr'],\n",
       "      ['tree', 'tree', 'value'],\n",
       "      ['isinstance', 'tree', 'ast', 'Name'],\n",
       "      ['segs', 'append', 'tree', 'id']]},\n",
       "    'params_p': {'args': [], 'kwargs': [], 'tree': []},\n",
       "    'q_name': 'parse_qualified_name',\n",
       "    'ret_exprs': ['return tuple(reversed(segs))'],\n",
       "    'ret_type': '',\n",
       "    'ret_type_p': [['int', 0.33333333272983884],\n",
       "     ['Dict[str, Any]', 0.33333333272983884],\n",
       "     ['str', 9.706075425789312e-10],\n",
       "     ['Container[str]', 4.199380474972001e-10]],\n",
       "    'variables': {'segs': '', 'tree': ''},\n",
       "    'variables_p': {'segs': [['list', 0.5876554132417703],\n",
       "      ['List[str]', 0.12660490923610832],\n",
       "      ['Dict[str, Any]', 0.1102941312532389],\n",
       "      ['Dict[str, str]', 0.08174465269642418]],\n",
       "     'tree': [['set', 0.183019067575267]]}}],\n",
       "  'imports': [],\n",
       "  'mod_var_ln': {},\n",
       "  'mod_var_occur': {},\n",
       "  'no_types_annot': {'D': 0, 'I': 0, 'U': 3},\n",
       "  'session_id': '-uNvsskOrfqJZpS0_4KM_bQqZAwRFU-IoCbTkcweYqQ',\n",
       "  'set': None,\n",
       "  'tc': [False, None],\n",
       "  'type_annot_cove': 0.0,\n",
       "  'typed_seq': '',\n",
       "  'untyped_seq': '',\n",
       "  'variables': {},\n",
       "  'variables_p': {}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from spot.utils import proj_root, read_file\n",
    "\n",
    "bad_code = \"\"\"\n",
    "def parse_qualified_name(tree: ast.Attribute):\n",
    "    segs = []\n",
    "    while isinstance(tree, ast.Attribute):\n",
    "        segs.append(tree.attr)\n",
    "        tree = tree.value  # type: ignore\n",
    "    assert isinstance(tree, ast.Name)\n",
    "    segs.append(tree.id)\n",
    "    return tuple(reversed(segs))\n",
    "\"\"\"\n",
    "\n",
    "r = requests.post(\"https://type4py.com/api/predict?tc=0\", bad_code)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.model/dynamic_dataloader\n",
      "\tFuncSig((collate_fn: cst'torch.Tensor', dataset: cst'torch.Tensor', max_tokens: cst'int', shuffle: cst'Optional[bool]') -> cst'str')\n",
      "spot.model/DecodingArgs.scale_ctx_size\n",
      "\tMethodSig((factor: cst'float') -> cst'List[str]')\n",
      "spot.model/DecodingArgs.__repr__\n",
      "\tMethodSig(() -> cst'str')\n",
      "spot.model/DatasetPredResult.accuracies\n",
      "\tMethodSig((common_type_names: cst'str') -> cst'str')\n",
      "spot.model/DatasetPredResult.group_by_repo\n",
      "\tMethodSig(() -> cst'dict')\n",
      "spot.model/ModelWrapper.scale_ctx_size\n",
      "\tMethodSig(() -> cst'str')\n",
      "spot.model/ModelWrapper.decode_row\n",
      "\tMethodSig((n_labels: cst'int', row: cst'str') -> cst'str')\n",
      "spot.model/ModelWrapper.predict_on_batch\n",
      "\tMethodSig((batch: cst'bool', num_return_sequences: cst'Callable[..., T]') -> cst'str')\n",
      "spot.model/ModelWrapper.predict\n",
      "\tMethodSig((dataset: cst'numpy.ndarray', num_return_sequences: cst'int', tqdm_args: cst'bytes') -> cst'str')\n",
      "spot.model/ModelWrapper.save_pretrained\n",
      "\tMethodSig((path: cst'List[str]') -> MISSING)\n",
      "spot.model/ModelWrapper.to\n",
      "\tMethodSig((device: cst'bool') -> cst'numpy.ndarray')\n",
      "spot.model/ModelWrapper.from_pretrained\n",
      "\tMethodSig((path: cst'str') -> cst'int')\n",
      "spot.model/ModelWrapper.eval_on_dataset\n",
      "\tMethodSig((max_labels: cst'int', src_data: cst'str', tqdm_args: cst'dict') -> cst'int')\n"
     ]
    }
   ],
   "source": [
    "from spot.experiments.type4py import Type4PyResponseParser\n",
    "from spot.static_analysis import FunctionSignature\n",
    "\n",
    "pred_signatures = Type4PyResponseParser(\"spot.model\").parse(r.json())\n",
    "for path, sig in pred_signatures.items():\n",
    "    if isinstance(sig, FunctionSignature):\n",
    "        print(path)\n",
    "        print(\"\\t\" + str(sig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_signatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m ubiq_names \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     10\u001b[0m acc_metric \u001b[38;5;241m=\u001b[39m AccuracyMetric(common_type_names\u001b[38;5;241m=\u001b[39mubiq_names)\n\u001b[1;32m     11\u001b[0m analysis \u001b[38;5;241m=\u001b[39m SignatureErrorAnalysis(\n\u001b[0;32m---> 12\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspot\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpred_signatures\u001b[49m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspot\u001b[39m\u001b[38;5;124m\"\u001b[39m: label_signatures}, acc_metric,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m pretty_print_dict(analysis\u001b[38;5;241m.\u001b[39maccuracies)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_signatures' is not defined"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import PythonProject, SignatureErrorAnalysis, AccuracyMetric\n",
    "from spot.visualization import pretty_print_dict, assert_eq\n",
    "\n",
    "ex_proj = PythonProject.from_root(\n",
    "    proj_root(), # file_filter=lambda f: f.name == \"model.py\"\n",
    ")\n",
    "label_signatures = {e.path: e.get_signature() for e in ex_proj.all_elems()}\n",
    "\n",
    "ubiq_names = {\"str\", \"int\", \"list\", \"bool\", \"float\"}\n",
    "acc_metric = AccuracyMetric(common_type_names=ubiq_names)\n",
    "analysis = SignatureErrorAnalysis(\n",
    "    {\"spot\": pred_signatures}, {\"spot\": label_signatures}, acc_metric,\n",
    ")\n",
    "pretty_print_dict(analysis.accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test projects: 100%|██████████| 5/5 [00:03<00:00,  1.42it/s]\n",
      "Calling Type4Py: 100%|██████████| 93/93 [00:37<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import PythonProject\n",
    "from spot.utils import *\n",
    "from spot.visualization import pretty_print_dict, assert_eq\n",
    "from spot.experiments.type4py import eval_type4py_on_projects\n",
    "from spot.function_dataset import data_project_from_dir\n",
    "\n",
    "\n",
    "dataset_name = \"ManyTypes4Py\"\n",
    "\n",
    "# test_projects = [PythonProject.from_root(proj_root(), ignore_dirs={\".venv\", \"data\"})]\n",
    "\n",
    "repos_dir = get_dataset_dir(dataset_name) / \"repos\" / \"test\"\n",
    "test_repo_paths = [f for f in repos_dir.iterdir() if f.is_dir()][:5]\n",
    "test_projects = pmap(\n",
    "    data_project_from_dir,\n",
    "    test_repo_paths,\n",
    "    desc=\"Loading test projects\",\n",
    ")\n",
    "eval_r = eval_type4py_on_projects(test_projects, max_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 32.05% (count=964)\n",
      "acc_by_common:\n",
      "   rare: 2.28% (count=569)\n",
      "   common: 74.94% (count=395)\n",
      "acc_by_cat:\n",
      "   FuncArg: 32.14% (count=448)\n",
      "   FuncReturn: 32.65% (count=392)\n",
      "   ClassAtribute: 29.51% (count=122)\n",
      "   GlobalVar: 50.00% (count=2)\n",
      "acc_label_size: 1.2521\n",
      "acc_pred_size: 1.111\n",
      "n_label_types: 1211\n",
      "n_skipped_types: 0\n",
      "n_missing_types: 11\n"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import SignatureErrorAnalysis, AccuracyMetric\n",
    "\n",
    "ubiq_names = {\"str\", \"int\", \"list\", \"bool\", \"float\"}\n",
    "# acc_metric = AccuracyMetric(common_type_names=ubiq_names, match_base_only=True, name=\"base_acc\")\n",
    "acc_metric = AccuracyMetric(common_type_names=ubiq_names)\n",
    "analysis = SignatureErrorAnalysis(\n",
    "    eval_r.pred_maps, eval_r.label_maps, acc_metric, error_on_mismatched_signature=False\n",
    ")\n",
    "pretty_print_dict(analysis.accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
