{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from spot.utils import proj_root, os\n",
    "os.chdir(proj_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from typing import Any, List, Tuple, Dict, Set, Union, Optional\n",
      "def parse_qualified_name(tree: ast.Attribute):\n",
      "    segs = []\n",
      "    while isinstance(tree, ast.Attribute):\n",
      "        segs.append(tree.attr)\n",
      "        tree = tree.value  # type: ignore\n",
      "    assert isinstance(tree, ast.Name)\n",
      "    segs.append(tree.id)\n",
      "    return tuple(reversed(segs))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_code = \"\"\"\n",
    "def parse_qualified_name(tree: ast.Attribute):\n",
    "    segs = []\n",
    "    while isinstance(tree, ast.Attribute):\n",
    "        segs.append(tree.attr)\n",
    "        tree = tree.value  # type: ignore\n",
    "    assert isinstance(tree, ast.Name)\n",
    "    segs.append(tree.id)\n",
    "    return tuple(reversed(segs))\n",
    "\"\"\"\n",
    "from spot.experiments.type4py import cst, remove_newer_syntax\n",
    "\n",
    "bad_code = remove_newer_syntax(cst.parse_module(bad_code)).code\n",
    "print(bad_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': None,\n",
       " 'response': {'classes': [],\n",
       "  'funcs': [{'docstring': {'func': None, 'long_descr': None, 'ret': None},\n",
       "    'fn_lc': [[2, 0], [9, 32]],\n",
       "    'fn_var_ln': {'segs': [[3, 4], [3, 8]], 'tree': [[6, 8], [6, 12]]},\n",
       "    'fn_var_occur': {'segs': [['segs', 'append', 'tree', 'attr'],\n",
       "      ['segs', 'append', 'tree', 'id'],\n",
       "      ['tuple', 'reversed', 'segs']],\n",
       "     'tree': [['isinstance', 'tree', 'ast', 'Attribute'],\n",
       "      ['segs', 'append', 'tree', 'attr'],\n",
       "      ['tree', 'tree', 'value'],\n",
       "      ['isinstance', 'tree', 'ast', 'Name'],\n",
       "      ['segs', 'append', 'tree', 'id']]},\n",
       "    'name': 'parse_qualified_name',\n",
       "    'params': {'tree': 'ast.Attribute'},\n",
       "    'params_descr': {'tree': ''},\n",
       "    'params_occur': {'tree': [['isinstance', 'tree', 'ast', 'Attribute'],\n",
       "      ['segs', 'append', 'tree', 'attr'],\n",
       "      ['tree', 'tree', 'value'],\n",
       "      ['isinstance', 'tree', 'ast', 'Name'],\n",
       "      ['segs', 'append', 'tree', 'id']]},\n",
       "    'params_p': {'args': [], 'kwargs': [], 'tree': []},\n",
       "    'q_name': 'parse_qualified_name',\n",
       "    'ret_exprs': ['return tuple(reversed(segs))'],\n",
       "    'ret_type': '',\n",
       "    'ret_type_p': [['int', 0.33333333272983884],\n",
       "     ['Dict[str, Any]', 0.33333333272983884],\n",
       "     ['str', 9.706075425789312e-10],\n",
       "     ['Container[str]', 4.199380474972001e-10]],\n",
       "    'variables': {'segs': '', 'tree': ''},\n",
       "    'variables_p': {'segs': [['list', 0.5876554132417703],\n",
       "      ['List[str]', 0.12660490923610832],\n",
       "      ['Dict[str, Any]', 0.1102941312532389],\n",
       "      ['Dict[str, str]', 0.08174465269642418]],\n",
       "     'tree': [['set', 0.183019067575267]]}}],\n",
       "  'imports': [],\n",
       "  'mod_var_ln': {},\n",
       "  'mod_var_occur': {},\n",
       "  'no_types_annot': {'D': 0, 'I': 0, 'U': 3},\n",
       "  'session_id': 'fATejpmSRCTaT8vUUYKOCLBAIs6PcAtWKCce18bKrt8',\n",
       "  'set': None,\n",
       "  'tc': [False, None],\n",
       "  'type_annot_cove': 0.0,\n",
       "  'typed_seq': '',\n",
       "  'untyped_seq': '',\n",
       "  'variables': {},\n",
       "  'variables_p': {}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from spot.utils import proj_root, read_file\n",
    "\n",
    "bad_code = \"\"\"\n",
    "def parse_qualified_name(tree: ast.Attribute):\n",
    "    segs = []\n",
    "    while isinstance(tree, ast.Attribute):\n",
    "        segs.append(tree.attr)\n",
    "        tree = tree.value  # type: ignore\n",
    "    assert isinstance(tree, ast.Name)\n",
    "    segs.append(tree.id)\n",
    "    return tuple(reversed(segs))\n",
    "\"\"\"\n",
    "\n",
    "r = requests.post(\"https://type4py.com/api/predict?tc=0\", bad_code)\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.model/parse_qualified_name\n",
      "\tFuncSig(() -> int)\n"
     ]
    }
   ],
   "source": [
    "from spot.experiments.type4py import Type4PyResponseParser\n",
    "from spot.static_analysis import FunctionSignature\n",
    "\n",
    "pred_signatures = Type4PyResponseParser(\"spot.model\").parse(r.json())\n",
    "for path, sig in pred_signatures.items():\n",
    "    if isinstance(sig, FunctionSignature):\n",
    "        print(path)\n",
    "        print(\"\\t\" + str(sig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test projects: 100%|██████████| 3/3 [00:10<00:00,  3.43s/it]\n",
      "Calling Type4Py: 100%|██████████| 128/128 [01:26<00:00,  1.48it/s]\n",
      "WARNING:root:In project typilus module exp.type_check.custom_exceptions, Type4Py errored: Could not predict types for the given source file!\n"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import PythonProject\n",
    "from spot.utils import *\n",
    "from spot.model import ModelWrapper\n",
    "from spot.visualization import pretty_print_dict, assert_eq\n",
    "from spot.experiments.type4py import eval_type4py_on_projects\n",
    "from spot.function_dataset import data_project_from_dir\n",
    "\n",
    "\n",
    "# dataset_name = \"ManyTypes4Py\"\n",
    "dataset_name = \"InferTypes4Py\"\n",
    "\n",
    "# test_projects = [PythonProject.from_root(proj_root(), ignore_dirs={\".venv\", \"data\"})]\n",
    "\n",
    "repos_dir = get_dataset_dir(dataset_name) / \"repos\" / \"test\"\n",
    "test_repo_paths = [f for f in repos_dir.iterdir() if f.is_dir()]\n",
    "test_projects = pmap(\n",
    "    data_project_from_dir,\n",
    "    test_repo_paths,\n",
    "    desc=\"Loading test projects\",\n",
    ")\n",
    "eval_r = eval_type4py_on_projects(test_projects, max_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_acc:\n",
      "   plain_acc: 22.63% (count=2.5k)\n",
      "   plain_acc_by_common:\n",
      "      rare: 0.12% (count=813)\n",
      "      common: 33.33% (count=1.7k)\n",
      "   plain_acc_by_cat:\n",
      "      FuncArg: 19.89% (count=1.6k)\n",
      "      FuncReturn: 33.12% (count=640)\n",
      "      ClassAtribute: 12.50% (count=240)\n",
      "      GlobalVar: 75.00% (count=4)\n",
      "   plain_acc_label_size: 1.7436\n",
      "   plain_acc_pred_size: 1.2612\n",
      "   plain_acc_ignored_labels: 0\n",
      "   n_skipped_types: 23\n",
      "   n_missing_types: 113\n",
      "acc:\n",
      "   acc: 20.86% (count=2.4k)\n",
      "   acc_by_common:\n",
      "      rare: 0.12% (count=813)\n",
      "      common: 31.76% (count=1.5k)\n",
      "   acc_by_cat:\n",
      "      FuncArg: 21.87% (count=1.5k)\n",
      "      FuncReturn: 21.76% (count=602)\n",
      "      ClassAtribute: 12.18% (count=238)\n",
      "      GlobalVar: 0.00% (count=1)\n",
      "   acc_label_size: 1.6719\n",
      "   acc_pred_size: 1.181\n",
      "   acc_ignored_labels: 164\n",
      "   n_skipped_types: 23\n",
      "   n_missing_types: 113\n",
      "base_acc:\n",
      "   base_acc: 22.64% (count=2.4k)\n",
      "   base_acc_by_common:\n",
      "      rare: 0.17% (count=572)\n",
      "      common: 29.83% (count=1.8k)\n",
      "   base_acc_by_cat:\n",
      "      FuncArg: 23.58% (count=1.5k)\n",
      "      FuncReturn: 23.59% (count=602)\n",
      "      ClassAtribute: 14.29% (count=238)\n",
      "      GlobalVar: 0.00% (count=1)\n",
      "   base_acc_label_size: 1\n",
      "   base_acc_pred_size: 1\n",
      "   base_acc_ignored_labels: 164\n",
      "   n_skipped_types: 23\n",
      "   n_missing_types: 113\n"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import SignatureErrorAnalysis, AccuracyMetric\n",
    "\n",
    "common_names = ModelWrapper.load_common_type_names(\n",
    "    get_model_dir() / \"model-v7--TrainingConfig(drop_env_types=False)\"\n",
    ")\n",
    "metrics = AccuracyMetric.default_metrics(common_type_names=common_names)\n",
    "# acc_metric = AccuracyMetric(common_type_names=ubiq_names)\n",
    "\n",
    "accs = {\n",
    "    m.name: SignatureErrorAnalysis(\n",
    "        eval_r.pred_maps,\n",
    "        eval_r.label_maps,\n",
    "        m,\n",
    "        error_on_mismatched_signature=False,\n",
    "    ).accuracies\n",
    "    for m in metrics\n",
    "}\n",
    "pretty_print_dict(accs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
