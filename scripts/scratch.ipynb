{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "    body=[\n",
       "        ClassDef(\n",
       "            name=Name(\n",
       "                value='A',\n",
       "                lpar=[],\n",
       "                rpar=[],\n",
       "            ),\n",
       "            body=IndentedBlock(\n",
       "                body=[\n",
       "                    SimpleStatementLine(\n",
       "                        body=[\n",
       "                            Pass(\n",
       "                                semicolon=MaybeSentinel.DEFAULT,\n",
       "                            ),\n",
       "                        ],\n",
       "                        leading_lines=[],\n",
       "                        trailing_whitespace=TrailingWhitespace(\n",
       "                            whitespace=SimpleWhitespace(\n",
       "                                value='',\n",
       "                            ),\n",
       "                            comment=None,\n",
       "                            newline=Newline(\n",
       "                                value=None,\n",
       "                            ),\n",
       "                        ),\n",
       "                    ),\n",
       "                ],\n",
       "                header=TrailingWhitespace(\n",
       "                    whitespace=SimpleWhitespace(\n",
       "                        value='',\n",
       "                    ),\n",
       "                    comment=None,\n",
       "                    newline=Newline(\n",
       "                        value=None,\n",
       "                    ),\n",
       "                ),\n",
       "                indent=None,\n",
       "                footer=[],\n",
       "            ),\n",
       "            bases=[],\n",
       "            keywords=[],\n",
       "            decorators=[],\n",
       "            lpar=MaybeSentinel.DEFAULT,\n",
       "            rpar=MaybeSentinel.DEFAULT,\n",
       "            leading_lines=[],\n",
       "            lines_after_decorators=[],\n",
       "            whitespace_after_class=SimpleWhitespace(\n",
       "                value=' ',\n",
       "            ),\n",
       "            whitespace_after_name=SimpleWhitespace(\n",
       "                value='',\n",
       "            ),\n",
       "            whitespace_before_colon=SimpleWhitespace(\n",
       "                value='',\n",
       "            ),\n",
       "        ),\n",
       "    ],\n",
       "    header=[\n",
       "        EmptyLine(\n",
       "            indent=True,\n",
       "            whitespace=SimpleWhitespace(\n",
       "                value='',\n",
       "            ),\n",
       "            comment=None,\n",
       "            newline=Newline(\n",
       "                value=None,\n",
       "            ),\n",
       "        ),\n",
       "        EmptyLine(\n",
       "            indent=True,\n",
       "            whitespace=SimpleWhitespace(\n",
       "                value='',\n",
       "            ),\n",
       "            comment=None,\n",
       "            newline=Newline(\n",
       "                value=None,\n",
       "            ),\n",
       "        ),\n",
       "    ],\n",
       "    footer=[],\n",
       "    encoding='utf-8',\n",
       "    default_indent='    ',\n",
       "    default_newline='\\n',\n",
       "    has_trailing_newline=True,\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.utils import cst\n",
    "\n",
    "import_code = '''\n",
    "\n",
    "class A:\n",
    "    pass\n",
    "'''\n",
    "\n",
    "cst.parse_module(import_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModuleName = str\n",
      "ModulePath = str\n",
      "class ProjectPath(NamedTuple):\n",
      "    module: ...\n",
      "    path: ...\n",
      "    def __str__(self): ...\n",
      "    def __repr__(self): ...\n",
      "    def append(self, path): ...\n",
      "    def pop(self): ...\n",
      "    @staticmethod\n",
      "    def from_str(s): ...\n",
      "    path: ...\n",
      "    module: ...\n",
      "ProjNamespace = dict[str, ProjectPath]\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    name: ...\n",
      "    path: ...\n",
      "    in_class: ...\n",
      "    tree: ...\n",
      "    def __repr__(self): ...\n",
      "    path: ...\n",
      "@dataclass\n",
      "class PythonVariable:\n",
      "    name: ...\n",
      "    path: ...\n",
      "    in_class: ...\n",
      "    assignments: ...  \n",
      "    def __repr__(self): ...\n",
      "    path: ...\n",
      "PythonElem = PythonFunction | PythonVariable\n",
      "@dataclass\n",
      "class PythonClass:\n",
      "    name: ...\n",
      "    path: ...\n",
      "    attributes: ...\n",
      "    methods: ...\n",
      "    tree: ...\n",
      "    superclasses: ... = ...\n",
      "    def __repr__(self): ...\n",
      "    path: ...\n",
      "    attributes: ...\n",
      "    methods: ...\n",
      "@dataclass\n",
      "class PythonModule:\n",
      "    functions: ...\n",
      "    global_vars: ...\n",
      "    classes: ...\n",
      "    name: ...\n",
      "    imported_modules: ...\n",
      "    defined_symbols: ...\n",
      "    tree: ...\n",
      "    @staticmethod\n",
      "    def from_cst(module, name): ...\n",
      "    def __repr__(self): ...\n",
      "    def all_funcs(self): ...\n",
      "    def all_vars(self): ...\n",
      "    def all_elements(self): ...\n",
      "    classes: ...\n",
      "    functions: ...\n",
      "    global_vars: ...\n",
      "@dataclass\n",
      "class PythonProject:\n",
      "    modules: ...\n",
      "    symlinks: ...\n",
      "    @staticmethod\n",
      "    def from_modules(modules): ...\n",
      "    @staticmethod\n",
      "    def from_root(\n",
      "        root,\n",
      "        discard_bad_files = ...,\n",
      "        src_filter = ...,\n",
      "        drop_comments = ...,\n",
      "        ignore_dirs = ...,\n",
      "    ): ...\n",
      "    def all_funcs(self): ...\n",
      "    def all_vars(self): ...\n",
      "    def all_elems(self): ...\n",
      "    @staticmethod\n",
      "    def rel_path_to_module_name(rel_path): ...\n",
      "    modules: ...\n",
      "def to_abs_import_path(current_mod, path): ...\n",
      "_path_segs_cache = dict[str, list[str]]()\n",
      "def split_import_path(path): ...\n",
      "@dataclass\n",
      "class ProjectUsage:\n",
      "    user: ...\n",
      "    used: ...\n",
      "    call_site: ...\n",
      "    is_certain: ...  \n",
      "    def __str__(self): ...\n",
      "    is_certain: ...\n",
      "    user: ...\n",
      "    used: ...\n",
      "class ModuleHierarchy:\n",
      "    def __init__(self): ...\n",
      "    def __repr__(self): ...\n",
      "    def add_module(self, segs): ...\n",
      "    def resolve_path(self, segs): ...\n",
      "    @staticmethod\n",
      "    def from_modules(modules): ...\n",
      "    children: ...\n",
      "def sort_modules_by_imports(project): ...\n",
      "def build_project_namespaces(\n",
      "    project,\n",
      "): ...\n",
      "class _NsBuilder(cst.CSTVisitor):\n",
      "    def __init__(self, module_path, module2ns): ...\n",
      "    def visit_ImportFrom(self, node): ...\n",
      "    namespace: ...\n",
      "    module_path: ...\n",
      "    module2ns: ...\n",
      "class UsageAnalysis:\n",
      "    all_usages: ...\n",
      "    path2elem: ...\n",
      "    user2used: ...\n",
      "    used2user: ...\n",
      "    def get_var(self, path): ...\n",
      "    def get_func(self, path): ...\n",
      "    def __init__(self, project): ...\n",
      "    def find_class(self, mname, qname): ...\n",
      "    def generate_usages(\n",
      "        self,\n",
      "        mname,\n",
      "        caller,\n",
      "        span,\n",
      "        qname,\n",
      "    ): ...\n",
      "    def assert_usages(self, caller, *callees): ...\n",
      "    sorted_modules: ...\n",
      "    name2class_member: ...\n",
      "    all_usages: ...\n",
      "    ns_hier: ...\n",
      "    path2elem: ...\n",
      "    project: ...\n",
      "    user2used: ...\n",
      "    used2user: ...\n",
      "    path2class: ...\n",
      "def compute_module_usages(mod): ...\n",
      "class _VisitType(enum.Enum):\n",
      "    Root = ...\n",
      "    Class = ...\n",
      "    Function = ...\n",
      "class PythonModuleBuilder(cst.CSTVisitor):\n",
      "    def __init__(self, module_name): ...\n",
      "    def get_module(self): ...\n",
      "    def visit_FunctionDef(self, node): ...\n",
      "    def leave_FunctionDef(self, node): ...\n",
      "    def visit_ClassDef(self, node): ...\n",
      "    def leave_ClassDef(self, node): ...\n",
      "    def visit_AnnAssign(self, node): ...\n",
      "    def visit_Assign(self, node): ...\n",
      "    def visit_Import(self, node): ...\n",
      "    def visit_ImportFrom(self, node): ...\n",
      "    def visit_Module(self, node): ...\n",
      "    def generate_init_(self, cls): ...\n",
      "    functions: ...\n",
      "    defined_symbols: ...\n",
      "    classes: ...\n",
      "    global_vars: ...\n",
      "    current_class: ...\n",
      "    visit_stack: ...\n",
      "    module: ...\n",
      "    module_name: ...\n",
      "    imported_modules: ...\n",
      "def parse_module_path(\n",
      "    path_ex, cur_mod, dots\n",
      "): ...\n",
      "class UsageRecorder(cst.CSTVisitor):\n",
      "    def __init__(\n",
      "        self,\n",
      "        name_mapping,\n",
      "        span_mapping,\n",
      "    ): ...\n",
      "    def _resolve(self, name): ...\n",
      "    def record_name_use(self, name): ...\n",
      "    def visit_Attribute(self, node): ...\n",
      "    def on_visit(self, node): ...\n",
      "    def visit_Decorator(self, node): ...\n",
      "    def visit_Annotation(self, node): ...\n",
      "    name_mapping: ...\n",
      "    span_mapping: ...\n",
      "    usages: ...\n",
      "@lru_cache(...)\n",
      "def is_access_chain(node): ...\n",
      "def stub_from_module(m, rm_comments=..., rm_imports=...): ...\n",
      "CNode = TypeVar(\"CNode\", bound=cst.CSTNode)\n",
      "def remove_imports(\n",
      "    m,\n",
      "): ...\n",
      "def remove_comments(m): ...\n",
      "def remove_empty_lines(m): ...\n",
      "def remove_types(m, type_mask=...): ...\n",
      "@dataclass\n",
      "class ClassNamespace:\n",
      "    all_elems: ... = ...\n",
      "    declared_elems: ... = ...\n",
      "class StubGenerator(cst.CSTTransformer):\n",
      "    OMIT = ...\n",
      "    def __init__(self): ...\n",
      "    def register_elem(self, name, declared): ...\n",
      "    def visit_ClassDef(self, node): ...\n",
      "    def leave_ClassDef(self, node, updated): ...\n",
      "    def visit_FunctionDef(self, node): ...\n",
      "    def leave_FunctionDef(self, node, updated): ...\n",
      "    def leave_Annotation(self, node, updated): ...\n",
      "    def leave_Param(self, node, updated): ...\n",
      "    def leave_AnnAssign(self, node, updated): ...\n",
      "    def leave_Assign(self, node, updated): ...\n",
      "    def leave_Attribute(self, node, updated): ...\n",
      "    def leave_Decorator(self, node, updated): ...\n",
      "    ns_stack: ...\n",
      "    nest_level: ...\n",
      "class EmptyLineRemove(cst.CSTTransformer):\n",
      "    def on_leave(self, node, updated): ...\n",
      "class CommentRemover(cst.CSTTransformer):\n",
      "    def leave_IndentedBlock(\n",
      "        self, node, updated\n",
      "    ): ...\n",
      "    def leave_Module(self, node, updated): ...\n",
      "    def leave_EmptyLine(self, node, updated): ...\n",
      "    def leave_TrailingWhitespace(self, node, updated): ...\n",
      "    @staticmethod\n",
      "    def is_doc_string(node): ...\n",
      "class ImportsRemover(cst.CSTTransformer):\n",
      "    def __init__(self): ...\n",
      "    def leave_Import(self, node, updated): ...\n",
      "    def leave_ImportFrom(self, node, updated): ...\n",
      "    def visit_FunctionDef(self, node): ...\n",
      "    import_stmts: ...\n",
      "class AnnotRemover(cst.CSTTransformer):\n",
      "    def __init__(self, type_mask = ...): ...\n",
      "    def leave_FunctionDef(self, node, updated): ...\n",
      "    def leave_Param(self, node, updated): ...\n",
      "    def leave_AnnAssign(self, node, updated): ...\n",
      "    type_mask: ...\n",
      "def guess_src_root(proj_root): ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import cst, read_file, proj_root\n",
    "from spot.static_analysis import stub_from_module\n",
    "\n",
    "ex_m = cst.parse_module(read_file(proj_root() / \"src/spot/static_analysis.py\"))\n",
    "print(stub_from_module(ex_m).code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.static_analysis/to_abs_import_path\n",
      "\t spot.static_analysis/split_import_path \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "spot.static_analysis/split_import_path\n",
      "\t spot.static_analysis/_path_segs_cache \n",
      "spot.static_analysis/sort_modules_by_imports\n",
      "\t spot.static_analysis/PythonProject.modules   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.imported_modules   (maybe)\n",
      "\t spot.static_analysis/PythonModule.imported_modules   (maybe)\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "spot.static_analysis/build_project_namespaces\n",
      "\t spot.static_analysis/sort_modules_by_imports \n",
      "\t spot.static_analysis/ModuleName \n",
      "\t spot.static_analysis/ProjNamespace \n",
      "\t spot.static_analysis/_NsBuilder.__init__ \n",
      "\t spot.static_analysis/PythonModule.tree   (maybe)\n",
      "\t spot.static_analysis/PythonClass.tree   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.tree   (maybe)\n",
      "\t spot.static_analysis/PythonProject.modules   (maybe)\n",
      "\t spot.static_analysis/_NsBuilder.namespace   (maybe)\n",
      "\t spot.utils/MovingAvg.update   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.defined_symbols   (maybe)\n",
      "\t spot.static_analysis/PythonModule.defined_symbols   (maybe)\n",
      "spot.static_analysis/compute_module_usages\n",
      "\t spot.static_analysis/PythonModule.tree   (maybe)\n",
      "\t spot.static_analysis/PythonClass.tree   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.tree   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.__init__ \n",
      "\t spot.static_analysis/PythonModule.all_elements   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.assignments   (maybe)\n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.usages   (maybe)\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.path   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.path   (maybe)\n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.utils/TimeLogger.clear   (maybe)\n",
      "\t spot.utils/PickleCache.clear   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.classes   (maybe)\n",
      "\t spot.static_analysis/PythonModule.classes   (maybe)\n",
      "\t spot.static_analysis/PythonClass.superclasses   (maybe)\n",
      "spot.static_analysis/parse_module_path\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "spot.static_analysis/is_access_chain\n",
      "\t spot.static_analysis/is_access_chain \n",
      "spot.static_analysis/stub_from_module\n",
      "\t spot.static_analysis/remove_comments \n",
      "\t spot.static_analysis/remove_imports \n",
      "\t spot.static_analysis/StubGenerator.__init__ \n",
      "\t spot.static_analysis/remove_empty_lines \n",
      "spot.static_analysis/remove_imports\n",
      "\t spot.static_analysis/ImportsRemover.__init__ \n",
      "\t spot.static_analysis/ImportsRemover.import_stmts   (maybe)\n",
      "spot.static_analysis/remove_comments\n",
      "\t spot.static_analysis/CNode \n",
      "spot.static_analysis/remove_empty_lines\n",
      "\t spot.static_analysis/CNode \n",
      "spot.static_analysis/remove_types\n",
      "\t spot.static_analysis/CNode \n",
      "\t spot.static_analysis/AnnotRemover.__init__ \n",
      "spot.static_analysis/ProjectPath.__str__\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "spot.static_analysis/ProjectPath.append\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "spot.static_analysis/ProjectPath.pop\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "spot.static_analysis/ProjectPath.from_str\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "spot.static_analysis/PythonFunction.__repr__\n",
      "\t spot.static_analysis/PythonFunction.path \n",
      "spot.static_analysis/PythonFunction.in_class\n",
      "\t spot.static_analysis/PythonFunction.parent_class \n",
      "spot.static_analysis/PythonVariable.__repr__\n",
      "\t spot.static_analysis/PythonVariable.path \n",
      "spot.static_analysis/PythonVariable.in_class\n",
      "\t spot.static_analysis/PythonVariable.parent_class \n",
      "spot.static_analysis/PythonClass.__repr__\n",
      "\t spot.static_analysis/PythonClass.path \n",
      "\t spot.static_analysis/PythonClass.attributes \n",
      "\t spot.static_analysis/PythonClass.methods \n",
      "spot.static_analysis/PythonClass.is_dataclass\n",
      "\t spot.static_analysis/PythonClass.superclasses \n",
      "spot.static_analysis/PythonModule.from_cst\n",
      "\t spot.static_analysis/PythonModuleBuilder.__init__ \n",
      "\t spot.static_analysis/PythonModuleBuilder.get_module   (maybe)\n",
      "spot.static_analysis/PythonModule.__repr__\n",
      "\t spot.static_analysis/PythonModule.functions \n",
      "\t spot.static_analysis/PythonModule.classes \n",
      "spot.static_analysis/PythonModule.all_funcs\n",
      "\t spot.static_analysis/PythonModule.functions \n",
      "\t spot.static_analysis/PythonModule.classes \n",
      "spot.static_analysis/PythonModule.all_vars\n",
      "\t spot.static_analysis/PythonModule.global_vars \n",
      "\t spot.static_analysis/PythonModule.classes \n",
      "spot.static_analysis/PythonModule.all_elements\n",
      "\t spot.static_analysis/PythonModule.global_vars \n",
      "\t spot.static_analysis/PythonModule.functions \n",
      "\t spot.static_analysis/PythonModule.classes \n",
      "spot.static_analysis/PythonProject.from_modules\n",
      "\t spot.static_analysis/PythonProject.modules \n",
      "\t spot.static_analysis/PythonProject.symlinks \n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t scripts.train_dagger/m   (maybe)\n",
      "spot.static_analysis/PythonProject.from_root\n",
      "\t spot.static_analysis/PythonProject.rel_path_to_module_name \n",
      "\t spot.static_analysis/remove_comments \n",
      "\t spot.static_analysis/PythonModule.from_cst \n",
      "\t spot.static_analysis/PythonProject.modules \n",
      "\t spot.static_analysis/PythonProject.symlinks \n",
      "spot.static_analysis/PythonProject.all_funcs\n",
      "\t spot.static_analysis/PythonProject.all_funcs   (maybe)\n",
      "\t spot.static_analysis/PythonModule.all_funcs   (maybe)\n",
      "spot.static_analysis/PythonProject.all_vars\n",
      "\t spot.static_analysis/PythonModule.all_vars   (maybe)\n",
      "\t spot.static_analysis/PythonProject.all_vars   (maybe)\n",
      "spot.static_analysis/PythonProject.all_elems\n",
      "\t spot.static_analysis/PythonModule.all_elements   (maybe)\n",
      "spot.static_analysis/ProjectUsage.__str__\n",
      "\t spot.static_analysis/ProjectUsage.user \n",
      "\t spot.static_analysis/ProjectUsage.is_certain \n",
      "\t spot.static_analysis/ProjectUsage.used \n",
      "spot.static_analysis/ModuleHierarchy.__init__\n",
      "\t spot.static_analysis/ModuleHierarchy.children \n",
      "spot.static_analysis/ModuleHierarchy.__repr__\n",
      "\t spot.static_analysis/ModuleHierarchy.children \n",
      "spot.static_analysis/ModuleHierarchy.add_module\n",
      "\t spot.static_analysis/ModuleHierarchy.children   (maybe)\n",
      "\t spot.static_analysis/ModuleHierarchy.__init__ \n",
      "spot.static_analysis/ModuleHierarchy.resolve_path\n",
      "\t spot.static_analysis/ModuleHierarchy.children   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "spot.static_analysis/ModuleHierarchy.from_modules\n",
      "\t spot.static_analysis/ModuleHierarchy.__init__ \n",
      "\t spot.static_analysis/ModuleHierarchy.add_module   (maybe)\n",
      "\t spot.static_analysis/split_import_path \n",
      "spot.static_analysis/_NsBuilder.__init__\n",
      "\t spot.static_analysis/_NsBuilder.module_path \n",
      "\t spot.static_analysis/_NsBuilder.module2ns \n",
      "\t spot.static_analysis/_NsBuilder.namespace \n",
      "spot.static_analysis/_NsBuilder.visit_ImportFrom\n",
      "\t spot.static_analysis/parse_module_path \n",
      "\t spot.type_env/TypeInfState.module   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module   (maybe)\n",
      "\t spot.static_analysis/_NsBuilder.module_path \n",
      "\t spot.static_analysis/_NsBuilder.module2ns \n",
      "\t spot.utils/MovingAvg.update   (maybe)\n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.static_analysis/_NsBuilder.namespace \n",
      "spot.static_analysis/UsageAnalysis.get_var\n",
      "\t spot.static_analysis/UsageAnalysis.path2elem \n",
      "spot.static_analysis/UsageAnalysis.get_func\n",
      "\t spot.static_analysis/UsageAnalysis.path2elem \n",
      "spot.static_analysis/UsageAnalysis.__init__\n",
      "\t spot.static_analysis/UsageAnalysis.project \n",
      "\t spot.static_analysis/UsageAnalysis.ns_hier \n",
      "\t spot.static_analysis/ModuleHierarchy.from_modules \n",
      "\t spot.static_analysis/build_project_namespaces \n",
      "\t spot.static_analysis/UsageAnalysis.sorted_modules \n",
      "\t spot.static_analysis/UsageAnalysis.path2elem \n",
      "\t spot.static_analysis/PythonVariable.path   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.static_analysis/PythonProject.all_elems   (maybe)\n",
      "\t spot.static_analysis/ClassNamespace.all_elems   (maybe)\n",
      "\t spot.static_analysis/UsageAnalysis.path2class \n",
      "\t spot.static_analysis/PythonModuleBuilder.classes   (maybe)\n",
      "\t spot.static_analysis/PythonModule.classes   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/PythonClass.methods   (maybe)\n",
      "\t spot.static_analysis/compute_module_usages \n",
      "\t spot.static_analysis/PythonProject.modules   (maybe)\n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.utils/not_none \n",
      "\t spot.static_analysis/PythonClass.superclasses   (maybe)\n",
      "\t data.code.good_code_1/Foo.x   (maybe)\n",
      "\t data.code.env_code_2/Bar.x   (maybe)\n",
      "\t data.code_output.inference.env_code_2/Bar.x   (maybe)\n",
      "\t spot.static_analysis/UsageAnalysis.find_class \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.in_class   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.in_class   (maybe)\n",
      "\t spot.type_env/TypeInfState.module   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module   (maybe)\n",
      "\t spot.static_analysis/UsageAnalysis.name2class_member \n",
      "\t spot.utils/groupby \n",
      "\t spot.static_analysis/UsageAnalysis.generate_usages \n",
      "\t spot.static_analysis/ProjectUsage.user   (maybe)\n",
      "\t spot.static_analysis/ProjectUsage.used   (maybe)\n",
      "\t spot.static_analysis/ProjectUsage.is_certain   (maybe)\n",
      "\t spot.static_analysis/UsageAnalysis.all_usages \n",
      "\t spot.static_analysis/UsageAnalysis.user2used \n",
      "\t spot.static_analysis/UsageAnalysis.used2user \n",
      "spot.static_analysis/UsageAnalysis.find_class\n",
      "\t spot.static_analysis/to_abs_import_path \n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.static_analysis/ModuleHierarchy.resolve_path   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.static_analysis/UsageAnalysis.path2class \n",
      "spot.static_analysis/UsageAnalysis.generate_usages\n",
      "\t spot.static_analysis/ProjectUsage.user \n",
      "\t spot.static_analysis/ProjectUsage.used \n",
      "\t spot.static_analysis/ProjectUsage.call_site \n",
      "\t spot.static_analysis/ProjectUsage.is_certain \n",
      "\t spot.static_analysis/PythonVariable.path   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.is_dataclass   (maybe)\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/PythonClass.methods   (maybe)\n",
      "\t spot.static_analysis/to_abs_import_path \n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.static_analysis/ModuleHierarchy.resolve_path   (maybe)\n",
      "\t spot.static_analysis/UsageAnalysis.path2class \n",
      "\t spot.static_analysis/UsageAnalysis.path2elem \n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "spot.static_analysis/UsageAnalysis.assert_usages\n",
      "\t spot.static_analysis/ProjectPath.from_str \n",
      "\t spot.static_analysis/ProjectUsage.used   (maybe)\n",
      "\t spot.static_analysis/ProjectUsage.is_certain   (maybe)\n",
      "\t spot.utils/assert_eq \n",
      "\t spot.static_analysis/compute_module_usages \n",
      "\t spot.static_analysis/PythonProject.modules   (maybe)\n",
      "\t spot.type_env/TypeInfState.module   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module   (maybe)\n",
      "\t spot.utils/groupby \n",
      "spot.static_analysis/PythonModuleBuilder.__init__\n",
      "\t spot.static_analysis/PythonModuleBuilder.functions \n",
      "\t spot.static_analysis/PythonModuleBuilder.global_vars \n",
      "\t spot.static_analysis/PythonModuleBuilder.classes \n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.static_analysis/_VisitType.Root \n",
      "\t spot.static_analysis/PythonModuleBuilder.module \n",
      "\t spot.static_analysis/PythonModuleBuilder.imported_modules \n",
      "\t spot.static_analysis/PythonModuleBuilder.defined_symbols \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "spot.static_analysis/PythonModuleBuilder.get_module\n",
      "\t spot.static_analysis/PythonModuleBuilder.module \n",
      "\t spot.static_analysis/PythonModule.functions \n",
      "\t spot.static_analysis/PythonModule.global_vars \n",
      "\t spot.static_analysis/PythonModule.classes \n",
      "\t spot.static_analysis/PythonModule.name \n",
      "\t spot.static_analysis/PythonModule.imported_modules \n",
      "\t spot.static_analysis/PythonModule.defined_symbols \n",
      "\t spot.static_analysis/PythonModule.tree \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "\t spot.static_analysis/PythonModuleBuilder.imported_modules \n",
      "\t spot.static_analysis/PythonModuleBuilder.defined_symbols \n",
      "spot.static_analysis/PythonModuleBuilder.visit_FunctionDef\n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/_VisitType.Function \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name \n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonFunction.path \n",
      "\t spot.static_analysis/PythonFunction.parent_class \n",
      "\t spot.static_analysis/PythonFunction.tree \n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "\t spot.static_analysis/PythonVariable.path   (maybe)\n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.methods   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.functions \n",
      "\t spot.static_analysis/_VisitType.Root \n",
      "\t spot.static_analysis/PythonModuleBuilder.defined_symbols \n",
      "spot.static_analysis/PythonModuleBuilder.leave_FunctionDef\n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.static_analysis/_VisitType.Function \n",
      "\t spot.type_env/AnnotPath.pop   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.pop   (maybe)\n",
      "spot.static_analysis/PythonModuleBuilder.visit_ClassDef\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/_VisitType.Class \n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonClass.name \n",
      "\t spot.static_analysis/PythonClass.path \n",
      "\t spot.static_analysis/PythonClass.attributes \n",
      "\t spot.static_analysis/PythonClass.methods \n",
      "\t spot.static_analysis/PythonClass.tree \n",
      "\t spot.static_analysis/PythonClass.superclasses \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "spot.static_analysis/PythonModuleBuilder.leave_ClassDef\n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.static_analysis/_VisitType.Class \n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonModuleBuilder.classes \n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.generate_init_ \n",
      "\t spot.static_analysis/PythonModuleBuilder.defined_symbols \n",
      "\t spot.static_analysis/PythonVariable.path   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.path   (maybe)\n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.type_env/AnnotPath.pop   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.pop   (maybe)\n",
      "spot.static_analysis/PythonModuleBuilder.visit_AnnAssign\n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonVariable.path \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.static_analysis/_VisitType.Root \n",
      "\t spot.static_analysis/PythonVariable.name \n",
      "\t spot.static_analysis/PythonVariable.parent_class \n",
      "\t spot.static_analysis/PythonVariable.assignments \n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "\t spot.static_analysis/_VisitType.Class \n",
      "\t spot.static_analysis/PythonClass.attributes   (maybe)\n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/_VisitType.Function \n",
      "spot.static_analysis/PythonModuleBuilder.visit_Assign\n",
      "\t spot.static_analysis/PythonModuleBuilder.current_class \n",
      "\t spot.static_analysis/PythonVariable.path \n",
      "\t spot.static_analysis/ProjectPath.path \n",
      "\t spot.type_env/CodePathManager.path   (maybe)\n",
      "\t spot.static_analysis/PythonClass.path   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.path   (maybe)\n",
      "\t spot.type_env/TypeInfAction.path   (maybe)\n",
      "\t spot.type_env/AnnotInfo.path   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.visit_stack \n",
      "\t spot.static_analysis/_VisitType.Root \n",
      "\t spot.static_analysis/PythonVariable.name \n",
      "\t spot.static_analysis/PythonVariable.parent_class \n",
      "\t spot.static_analysis/PythonVariable.assignments \n",
      "\t spot.static_analysis/ProjectPath.module \n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "\t spot.static_analysis/_VisitType.Class \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/_VisitType.Function \n",
      "\t spot.static_analysis/PythonClass.attributes   (maybe)\n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "spot.static_analysis/PythonModuleBuilder.visit_Import\n",
      "\t spot.static_analysis/parse_module_path \n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "spot.static_analysis/PythonModuleBuilder.visit_ImportFrom\n",
      "\t spot.static_analysis/parse_module_path \n",
      "\t spot.type_env/TypeInfState.module   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.module   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module   (maybe)\n",
      "\t spot.static_analysis/PythonModuleBuilder.module_name \n",
      "spot.static_analysis/PythonModuleBuilder.visit_Module\n",
      "\t spot.static_analysis/PythonModuleBuilder.module \n",
      "spot.static_analysis/UsageRecorder.__init__\n",
      "\t spot.static_analysis/UsageRecorder.name_mapping \n",
      "\t spot.static_analysis/UsageRecorder.span_mapping \n",
      "\t spot.static_analysis/UsageRecorder.parents \n",
      "\t spot.static_analysis/UsageRecorder.usages \n",
      "spot.static_analysis/UsageRecorder._resolve\n",
      "\t spot.static_analysis/is_access_chain \n",
      "\t spot.static_analysis/UsageRecorder.name_mapping \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.data/GitRepo.name   (maybe)\n",
      "\t spot.static_analysis/PythonFunction.name   (maybe)\n",
      "\t spot.static_analysis/PythonClass.name   (maybe)\n",
      "\t spot.static_analysis/PythonVariable.name   (maybe)\n",
      "\t spot.static_analysis/PythonModule.name   (maybe)\n",
      "spot.static_analysis/UsageRecorder.is_call_name\n",
      "\t spot.static_analysis/UsageRecorder.parents \n",
      "spot.static_analysis/UsageRecorder.record_name_use\n",
      "\t spot.static_analysis/UsageRecorder._resolve \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.span_mapping \n",
      "\t spot.static_analysis/UsageRecorder.is_call_name \n",
      "spot.static_analysis/UsageRecorder.visit_Attribute\n",
      "\t spot.static_analysis/UsageRecorder._resolve \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.span_mapping \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.is_call_name \n",
      "spot.static_analysis/UsageRecorder.on_visit\n",
      "\t spot.static_analysis/UsageRecorder.record_name_use \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/UsageRecorder.on_visit   (maybe)\n",
      "\t spot.type_env/AnnotApplier.on_visit   (maybe)\n",
      "\t spot.type_env/AnnotCollector.on_visit   (maybe)\n",
      "\t spot.type_env/CodePathManager.on_visit   (maybe)\n",
      "spot.static_analysis/UsageRecorder.on_leave\n",
      "\t spot.type_env/AnnotPath.pop   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.pop   (maybe)\n",
      "spot.static_analysis/StubGenerator.__init__\n",
      "\t spot.static_analysis/StubGenerator.ns_stack \n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "spot.static_analysis/StubGenerator.register_elem\n",
      "\t spot.static_analysis/StubGenerator.ns_stack \n",
      "spot.static_analysis/StubGenerator.visit_ClassDef\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "\t spot.type_env/AnnotPath.append   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.append   (maybe)\n",
      "\t spot.static_analysis/ClassNamespace.all_elems \n",
      "\t spot.static_analysis/ClassNamespace.declared_elems \n",
      "spot.static_analysis/StubGenerator.leave_ClassDef\n",
      "\t spot.type_env/AnnotPath.pop   (maybe)\n",
      "\t spot.static_analysis/ProjectPath.pop   (maybe)\n",
      "\t spot.static_analysis/ClassNamespace.declared_elems   (maybe)\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "spot.static_analysis/StubGenerator.visit_FunctionDef\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "spot.static_analysis/StubGenerator.leave_FunctionDef\n",
      "\t spot.static_analysis/StubGenerator.register_elem \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "\t spot.static_analysis/StubGenerator.OMIT \n",
      "spot.static_analysis/StubGenerator.leave_AnnAssign\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "\t spot.type_env/AnnotPath.value   (maybe)\n",
      "\t spot.utils/MovingAvg.value   (maybe)\n",
      "spot.static_analysis/StubGenerator.leave_Assign\n",
      "\t spot.static_analysis/StubGenerator.nest_level \n",
      "spot.static_analysis/StubGenerator.leave_Attribute\n",
      "\t spot.static_analysis/StubGenerator.register_elem \n",
      "spot.static_analysis/CommentRemover.leave_IndentedBlock\n",
      "\t spot.static_analysis/CommentRemover.is_doc_string \n",
      "spot.static_analysis/CommentRemover.leave_Module\n",
      "\t spot.static_analysis/CommentRemover.leave_IndentedBlock \n",
      "spot.static_analysis/ImportsRemover.__init__\n",
      "\t spot.static_analysis/ImportsRemover.import_stmts \n",
      "spot.static_analysis/AnnotRemover.__init__\n",
      "\t spot.static_analysis/AnnotRemover.type_mask \n",
      "spot.static_analysis/AnnotRemover.leave_AnnAssign\n",
      "\t spot.static_analysis/AnnotRemover.type_mask \n"
     ]
    }
   ],
   "source": [
    "from spot import proj_root\n",
    "from spot.static_analysis import ProjectPath, UsageAnalysis, PythonProject\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "proj = PythonProject.from_root(proj_root())\n",
    "for caller, callees in UsageAnalysis(proj).user2used.items():\n",
    "    if caller.module == \"spot.static_analysis\":\n",
    "        print(caller)\n",
    "        for callee in callees:\n",
    "            print(\"\\t\", callee.used, \"\" if callee.is_certain else \"  (maybe)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from spot.tokenized_src import PreprocessArgs, proj_root\n",
    "from spot.function_dataset import repo_to_tk_srcs, dataset_from_repos\n",
    "\n",
    "srcs = repo_to_tk_srcs(proj_root(), PreprocessArgs(drop_env_types=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "map srcs_to_chunks: 100%|██████████| 561/561 [00:00<00:00, 1732.49it/s]\n",
      "verify_labels: 100%|██████████| 566/566 [00:00<00:00, 46315.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from spot.data import SrcDataset, CtxArgs\n",
    "\n",
    "sdata = SrcDataset(proj_root(), srcs)\n",
    "ctx_args = CtxArgs(1024, 128, 256, 512)\n",
    "cdata = sdata.to_chunks(ctx_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= file: spot.static_analysis/PythonFunction.name ========\n",
      "\n",
      "# BEGIN\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    name: <mask>\n",
      "\n",
      "# END\n",
      "# scripts.train_dagger\n",
      "m = not_none(re.match(\"step=(.+)\", model_path.name)).groups()[0]\n",
      "# spot.data\n",
      "def type_check_src_in_project(\n",
      "    src: TokenizedSrc,\n",
      "    preds: dict[int, str] | dict[int, PythonType],\n",
      "    project_root: Path,\n",
      "    preexisting: list[MypyFeedback] | str,\n",
      ") -> SrcCheckResult:\n",
      "    proc = multiprocessing.current_process()\n",
      "    cwd = project_root.parent.parent / proc.name / project_root.name\n",
      "    cwd.mkdir(parents=True, exist_ok=True)\n",
      "\n",
      "    for f in project_root.glob(\"**/*.py\"):\n",
      "        rel_path = f.relative_to(project_root)\n",
      "        (cwd / rel_path).parent.mkdir(parents=True, exist_ok=True)\n",
      "        shutil.copy(f, cwd / rel_path)\n",
      "\n",
      "    rel_path = src.file.relative_to(src.repo)\n",
      "    file_path = cwd / rel_path\n",
      "\n",
      "    def from_preds(preds: dict[int, str] | dict[int, PythonType]):\n",
      "        new_code = code_to_check_from_preds(src, preds)\n",
      "        file_path.write_text(new_code)\n",
      "        check_r = MypyChecker.check_project(cwd)\n",
      "        feedback: list[MypyFeedback] | str\n",
      "        if isinstance(check_r, str):\n",
      "            feedback = check_r\n",
      "        else:\n",
      "            feedback = check_r.error_dict.get(file_path.resolve(), [])\n",
      "        return SrcCheckResult(feedback, new_code)\n",
      "\n",
      "    return from_preds(preds).remove_preexisting(preexisting)\n",
      "\n",
      "# spot.data\n",
      "def type_accuracies(\n",
      "    pred_types: Sequence[PythonType],\n",
      "    label_types: Sequence[PythonType],\n",
      "    types_cat: Sequence[AnnotCat],\n",
      "    types_pos: Sequence[int],\n",
      "    normalize_types=True,\n",
      "    allow_implicit_none=False,\n",
      ") -> dict[str, Any]:\n",
      "    assert_eq(len(pred_types), len(label_types), len(types_cat), len(types_pos))\n",
      "\n",
      "    if normalize_types:\n",
      "        pred_types = [normalize_type(ty) for ty in pred_types]\n",
      "        label_types = [normalize_type(ty) for ty in label_types]\n",
      "\n",
      "    if allow_implicit_none:\n",
      "        pred_types = [remove_top_optional(t) for t in pred_types]\n",
      "        label_types = [remove_top_optional(t) for t in label_types]\n",
      "\n",
      "    def i_to_range(i):\n",
      "        if i == 0:\n",
      "            return range(0, 1)\n",
      "        p = int(math.log(i, 2))\n",
      "        return range(2**p, 2 ** (p + 1))\n",
      "\n",
      "    def ast_size(ty: PythonType) -> int:\n",
      "        return 1 + sum(ast_size(a) for a in ty.args)\n",
      "\n",
      "    def ast_overlap(ty1: PythonType, ty2: PythonType) -> int:\n",
      "        if ty1.head!= ty2.head:\n",
      "            return 0\n",
      "        return 1 + sum(ast_overlap(a1, a2) for a1, a2 in zip(ty1.args, ty2.args))\n",
      "\n",
      "    partial_by_cat = GroupedAccCounter[AnnotCat]()\n",
      "    partial_by_pos = GroupedAccCounter[range]()\n",
      "    full_acc = GroupedAccCounter[None]()\n",
      "    ast_acc = GroupedAccCounter[None]()\n",
      "\n",
      "    for p, l, cat, pos in zip(pred_types, label_types, types_cat, types_pos):\n",
      "        partial_by_cat.count(cat, p.head_name() == l.head_name(), 1)\n",
      "        partial_by_pos.count(i_to_range(pos), p.head_name() == l.head_name(), 1)\n",
      "        full_acc.count(None, p == l, 1)\n",
      "        ast_acc.count(None, ast_overlap(p, l), ast_size(l))\n",
      "\n",
      "    return {\n",
      "        \"partial_acc\": partial_by_cat.overall_acc(),\n",
      "        \"ast_acc\": ast_acc.overall_acc(),\n",
      "        \"full_acc\": full_acc.overall_acc(),\n",
      "        \"partial_acc_by_cat\": partial_by_cat.grouped_accs(\n",
      "            key=lambda x: x.name, sort_by=lambda x: x.value\n",
      "        ),\n",
      "        \"partial_acc_by_pos\": partial_by_pos.grouped_accs(sort_by=lambda x: x.start),\n",
      "        \"avg_label_size\": safe_div(\n",
      "            sum(ast_size(l) for l in label_types), len(label_types)\n",
      "        ),\n",
      "        \"avg_pred_size\": safe_div(\n",
      "            sum(ast_size(p) for p in pred_types), len(pred_types)\n",
      "        ),\n",
      "    }\n",
      "\n",
      "# spot.decode\n",
      "def collect_type_errors_in_project(\n",
      "    srcs: list[TokenizedSrc],\n",
      "    preds_list: list[dict[int, str]],\n",
      "    project_root: Path,\n",
      ") -> MypyResult | str:\n",
      "    proc = multiprocessing.current_process()\n",
      "    cwd = (project_root.parent.parent / proc.name / project_root.name).resolve()\n",
      "    cwd.mkdir(parents=True, exist_ok=True)\n",
      "\n",
      "    for f in project_root.glob(\"**/*.py\"):\n",
      "        rel_path = f.relative_to(project_root)\n",
      "        (cwd / rel_path).parent.mkdir(parents=True, exist_ok=True)\n",
      "        shutil.copy(f, cwd / rel_path)\n",
      "\n",
      "    for src, preds in zip(srcs, preds_list):\n",
      "        rel_path = src.file.relative_to(src.repo)\n",
      "        file_path = cwd / rel_path\n",
      "        new_code = code_to_check_from_preds(src, preds)\n",
      "        file_path.write_text(new_code)\n",
      "    check_r = MypyChecker.check_project(cwd)\n",
      "    if isinstance(check_r, MypyResult):\n",
      "        check_r.error_dict = {\n",
      "            f.relative_to(cwd): es for f, es in check_r.error_dict.items()\n",
      "        }\n",
      "    return check_r\n",
      "\n",
      "# tests.test_static_analysis\n",
      "def test_attribute_analysis():\n",
      "    code1 = \"\"\"\n",
      "# root.file1\n",
      "def bernouli():\n",
      "    return random.random() > 0.5\n",
      "\n",
      "Count = 1\n",
      "Count = bernouli()\n",
      "\n",
      "class A:\n",
      "    x: int\n",
      "    y: str = \"y_init\"\n",
      "    z: bool = bernouli()\n",
      "    s = 1\n",
      "\n",
      "    def __init__(self):\n",
      "        self.u: bool = bernouli()\n",
      "        self.v = self.foo()\n",
      "\n",
      "    def foo(self):\n",
      "        return {self.x: self.undefined}\n",
      "\n",
      "def inc():\n",
      "    global Count\n",
      "    Count += 1\n",
      "\n",
      "def list():\n",
      "    return [Count]\n",
      "\n",
      "def loop():\n",
      "    for x in Count:\n",
      "        print(x)\n",
      "\n",
      "def bar():\n",
      "    return A().y.x\n",
      "\"\"\"\n",
      "\n",
      "    project = PythonProject.from_modules(\n",
      "        [PythonModule.from_cst(cst.parse_module(code1), \"root.file1\")],\n",
      "    )\n",
      "    analysis = UsageAnalysis(project)\n",
      "\n",
      "    A_cls = project.modules[\"root.file1\"].classes[0]\n",
      "    A_attrs = set(A_cls.attributes.keys())\n",
      "    assert_eq(A_attrs, {\"x\", \"y\", \"z\", \"s\", \"u\", \"v\"})\n",
      "\n",
      "    def check_var(attr_path: str, n_initializers: int):\n",
      "        attr_p = ProjectPath.from_str(attr_path)\n",
      "        assert_eq(len(analysis.get_var(attr_p).assignments), n_initializers)\n",
      "\n",
      "    check_var(\"root.file1/Count\", 2)\n",
      "    check_var(\"root.file1/A.x\", 1)\n",
      "    check_var(\"root.file1/A.y\", 1)\n",
      "    check_var(\"root.file1/A.z\", 1)\n",
      "    check_var(\"root.file1/A.s\", 1)\n",
      "    check_var(\"root.file1/A.u\", 0)\n",
      "    check_var(\"root.file1/A.v\", 0)\n",
      "\n",
      "    analysis.assert_usages(\"root.file1/inc\", (\"root.file1/Count\", True))\n",
      "    analysis.assert_usages(\"root.file1/list\", (\"root.file1/Count\", True))\n",
      "    analysis.assert_usages(\"root.file1/loop\", (\"root.file1/Count\", True))\n",
      "    analysis.assert_usages(\n",
      "        \"root.file1/bar\",\n",
      "        (\"root.file1/A.__init__\", True),\n",
      "        (\"root.file1/A.y\", False),\n",
      "        (\"root.file1/A.x\", False),\n",
      "    )\n",
      "\n",
      "    analysis.assert_usages(\n",
      "        \"root.file1/A.__init__\",\n",
      "        (\"root.file1/A.u\", True),\n",
      "        (\"root.file1/A.v\", True),\n",
      "        (\"root.file1/A.foo\", True),\n",
      "        (\"root.file1/bernouli\", True),\n",
      "    )\n",
      "\n",
      "    analysis.assert_usages(\n",
      "        \"root.file1/A.foo\",\n",
      "        (\"root.file1/A.x\", True),\n",
      "    )\n",
      "\n",
      "    analysis.assert_usages(\"root.file1/Count\", (\"root.file1/bernouli\", True))\n",
      "    analysis.assert_usages(\"root.file1/A.x\")\n",
      "    analysis.assert_usages(\"root.file1/A.y\")\n",
      "    analysis.assert_usages(\"root.file1/A.z\", (\"root.file1/bernouli\", True))\n",
      "    analysis.assert_usages(\"root.file1/A.s\")\n",
      "    analysis.assert_usages(\"root.file1/A.u\")\n",
      "    analysis.assert_usages(\"root.file1/A.v\")\n",
      "\n",
      "    code2 = \"\"\"\n",
      "from root.file1 import A as Parent\n",
      "from root.file1 import *\n",
      "\n",
      "class B(Parent):\n",
      "    new_mem1: bool\n",
      "    def fly(self):\n",
      "        self.new_mem2 = self.foo()\n",
      "        return self.x\n",
      "\n",
      "class C():\n",
      "    y = \"y_C\"\n",
      "\n",
      "\n",
      "class D(A, C):\n",
      "    def __init__(self):\n",
      "        self.y += 1  # should use y from C\n",
      "        self.z * 2 # should use z from A\n",
      "\n",
      "def test_annot():\n",
      "    x: D = undefined\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "    project = PythonProject.from_modules(\n",
      "        [\n",
      "            PythonModule.from_cst(cst.parse_module(code1), \"root.file1\"),\n",
      "            PythonModule.from_cst(cst.parse_module(code2), \"root.file2\"),\n",
      "        ],\n",
      "    )\n",
      "...\n",
      "======= file: spot.static_analysis/PythonFunction.path ========\n",
      "\n",
      "# BEGIN\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    path: <mask>\n",
      "\n",
      "# END\n",
      "# spot.static_analysis\n",
      "def compute_module_usages(mod: PythonModule):\n",
      "    wrapper = cst.MetadataWrapper(mod.tree, unsafe_skip_copy=True)\n",
      "    name_map = wrapper.resolve(QualifiedNameProvider)\n",
      "    pos_map = wrapper.resolve(PositionProvider)\n",
      "\n",
      "    recorder = UsageRecorder(name_map, pos_map)\n",
      "    result = list[tuple[ProjectPath, CodeRange, QualifiedName, bool]]()\n",
      "\n",
      "    for e in mod.all_elements():\n",
      "        match e:\n",
      "            case PythonFunction():\n",
      "                e.tree.body.visit(recorder)\n",
      "            case PythonVariable():\n",
      "                for a in e.assignments:\n",
      "                    if a.value:\n",
      "                        a.value.visit(recorder)\n",
      "        best_callee = dict[QualifiedName, tuple[bool, CodeRange]]()\n",
      "        for span, qn, is_call in recorder.usages:\n",
      "            if qn not in best_callee or int(is_call) > int(best_callee[qn][0]):\n",
      "                best_callee[qn] = (is_call, span)\n",
      "        for qn, (is_call, span) in best_callee.items():\n",
      "            result.append((e.path, span, qn, is_call))\n",
      "        recorder.usages.clear()\n",
      "\n",
      "    for cls in mod.classes:\n",
      "        cls.superclasses = list()\n",
      "        for b in cls.tree.bases:\n",
      "            if b.value in name_map and name_map[b.value]:\n",
      "                cls.superclasses.extend(name_map[b.value])\n",
      "            elif isinstance(b.value, cst.Name):\n",
      "                cls.superclasses.append(\n",
      "                    QualifiedName(b.value.value, QualifiedNameSource.LOCAL)\n",
      "                )\n",
      "\n",
      "    return result\n",
      "\n",
      "# spot.tokenized_src\n",
      "def preprocess_code(code: str, args: PreprocessArgs) -> dict:\n",
      "    m = cst.parse_module(code)\n",
      "    preamble_segs = list[str]()\n",
      "\n",
      "    if args.drop_comments:\n",
      "        m = remove_comments(m)\n",
      "    if args.imports_in_preamble:\n",
      "        m, imports = remove_imports(m)\n",
      "        imports_part = cst.Module([cst.SimpleStatementLine([s]) for s in imports])\n",
      "        preamble_segs.append(imports_part.code)\n",
      "    if args.stub_in_preamble:\n",
      "        stub_m = stub_from_module(m)\n",
      "        preamble_segs.append(stub_m.code)\n",
      "\n",
      "    cst_code = m.code\n",
      "    annots_info, types = collect_user_annotations(m)\n",
      "    types_str = [\n",
      "        m.code_for_node(not_none(info.annot).annotation) for info in annots_info\n",
      "    ]\n",
      "    mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "    replaces = dict()\n",
      "    for info in annots_info:\n",
      "        replaces[info.path] = mask_annot\n",
      "    new_code = apply_annotations(m, replaces).code\n",
      "    code_segs = new_code.split(SpecialNames.TypeMask)\n",
      "\n",
      "    assert (\n",
      "        len(code_segs) == len(types) + 1\n",
      "    ), f\"{len(code_segs)}!= {len(types) + 1}. replaces: {replaces}\\ncode: {new_code}\"\n",
      "    return {\n",
      "        \"preamble\": \"\".join(preamble_segs),\n",
      "        \"code_segs\": code_segs,\n",
      "        \"types\": types,\n",
      "        \"types_str\": types_str,\n",
      "        \"annots_info\": annots_info,\n",
      "        \"cst_code\": cst_code,\n",
      "        \"prev_types\": None,\n",
      "    }\n",
      "\n",
      "# spot.tokenized_src\n",
      "def feedbacks_to_tokenized_src(\n",
      "    src: TokenizedSrc,\n",
      "    current_code: str,\n",
      "    feedbacks: list[MypyFeedback],\n",
      "    patch_predictions: bool = False,\n",
      ") -> TokenizedSrc:\n",
      "    try:\n",
      "        m = cst.parse_module(current_code)\n",
      "    except Exception as e:\n",
      "        raise RuntimeError(\n",
      "            f\"Failed to parse file: '{src.file}' with content:\\n{current_code}\"\n",
      "        ) from e\n",
      "    m_code = m.code\n",
      "    assert (\n",
      "        m_code.rstrip() == current_code.rstrip()\n",
      "    ), f\"String diffferences: {show_string_diff(current_code, m_code)}\"\n",
      "    current_annots, _ = collect_user_annotations(m)\n",
      "    preds_map = dict[CodeRange, str]()\n",
      "    types = list[PythonType]()\n",
      "    prev_types = dict[int, PythonType]()\n",
      "    types_str = list[str]()\n",
      "    annots_info = list[AnnotInfo]()\n",
      "    path2label_id = {info.path: i for i, info in enumerate(src.types_info)}\n",
      "\n",
      "    for a in current_annots:\n",
      "        if a.path in path2label_id:\n",
      "            assert (r := a.annot_range) is not None\n",
      "            assert (annot := a.annot) is not None\n",
      "            prev_type = preds_map[r] = m.code_for_node(annot.annotation)\n",
      "            li = path2label_id[a.path]\n",
      "            prev_types[li] = parse_type_str(prev_type)\n",
      "            types.append(src.types[li])\n",
      "            types_str.append(src.types_str[li])\n",
      "            annots_info.append(a)\n",
      "    pos_to_msg = {f.position: f.message for f in feedbacks}\n",
      "    new_code = patch_code_with_extra(\n",
      "        current_code, preds_map, pos_to_msg, patch_predictions\n",
      "    )\n",
      "    code_segs = new_code.split(SpecialNames.TypeMask)\n",
      "    assert (\n",
      "        len(code_segs) == len(types) + 1\n",
      "    ), f\"{len(code_segs)}!= {len(types)} + 1.\\nNew Code:\\n{new_code}\"\n",
      "\n",
      "    new_src = tokenized_src_from_segs(\n",
      "        file=src.file,\n",
      "        repo=src.repo,\n",
      "        cst_code=new_code,\n",
      "        preamble=src.preamble_code,\n",
      "        tokenized_preamble=src.tokenized_preamble,\n",
      "        code_segs=code_segs,\n",
      "        types=types,\n",
      "        types_str=types_str,\n",
      "        annots_info=annots_info,\n",
      "        prev_types=prev_types,\n",
      "    )\n",
      "    new_src.feedbacks = feedbacks\n",
      "    return new_src\n",
      "\n",
      "# spot.data\n",
      "def R1_srcs_from_preds(\n",
      "    r0_src: SrcDataset,\n",
      "    chunks_info: list[SrcChunkInfo],\n",
      "    src_files: list[Path],\n",
      "    r0_preds: list[list[PythonType]],\n",
      "    tc_args: TypeCheckArgs,\n",
      "    max_workers: int,\n",
      "    tqdm_args: dict = {},\n",
      ") -> SrcDataset:\n",
      "    file2preds = dict[Path, dict[AnnotPath, str]]()\n",
      "    for preds, chunk_info in zip(r0_preds, chunks_info):\n",
      "        assert_eq(len(preds), len(chunk_info.types))\n",
      "        file = (r0_src.repos_root / chunk_info.src_file).resolve()\n",
      "        for i, pred in enumerate(preds):\n",
      "            if file not in file2preds:\n",
      "                file2preds[file] = dict()\n",
      "            label_path = chunk_info.annots_info[i].path\n",
      "            file2preds[file][label_path] = str(pred)\n",
      "\n",
      "    file2src = r0_src.file2src()\n",
      "    file2preds1 = dict[Path, dict[int, str]]()\n",
      "\n",
      "    for f, ls in file2preds.items():\n",
      "        src = file2src[f]\n",
      "        path2id = {info.path: i for i, info in enumerate(src.types_info)}\n",
      "        try:\n",
      "            file2preds1[f] = {path2id[path]: label for path, label in ls.items()}\n",
      "        except Exception as e:\n",
      "            raise RuntimeError(f\"In file {f}. path2id={path2id}\") from e\n",
      "\n",
      "    return r0_src.add_type_checker_feedback(\n",
      "        file2preds1,\n",
      "        tc_args=tc_args,\n",
      "        max_workers=max_workers,\n",
      "        tqdm_args=tqdm_args,\n",
      "    )\n",
      "\n",
      "# spot.function_dataset\n",
      "def repo_to_tk_srcs(\n",
      "    repo: Path,\n",
      "    pre_args: PreprocessArgs,\n",
      "    max_line_width: int = 200,\n",
      ") -> list[TokenizedSrc]:\n",
      "    def src_filter(text):\n",
      "        width = max(len(l) for l in text.split(\"\\n\"))\n",
      "        return width <= max_line_width\n",
      "\n",
      "    proj = PythonProject.from_root(\n",
      "        repo,\n",
      "        True,\n",
      "        src_filter,\n",
      "        drop_comments=pre_args.drop_comments,\n",
      "    )\n",
      "\n",
      "    analysis = UsageAnalysis(proj)\n",
      "    sorted_moduels = analysis.sorted_modules\n",
      "\n",
      "\n",
      "    srcs = list[TokenizedSrc]()\n",
      "    for mpath in sorted_moduels:\n",
      "        mod = proj.modules[mpath]\n",
      "        preamble_segs = list[str]()\n",
      "        if pre_args.imports_in_preamble:\n",
      "            wo_imports, imports = remove_imports(mod.tree)\n",
      "            imports_part = cst.Module([cst.SimpleStatementLine([s]) for s in imports])\n",
      "            preamble_segs.append(imports_part.code)\n",
      "        if pre_args.stub_in_preamble:\n",
      "            preamble_segs.append(stub_from_module(mod.tree).code)\n",
      "        preamble = \"\".join(preamble_segs)\n",
      "        tokenized_preamble = DefaultTokenizer.encode(preamble, add_special_tokens=False)\n",
      "\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in mod.all_elements():\n",
      "            main_m = module_from_elems([elem], analysis.path2class)\n",
      "            annots_info, types = collect_user_annotations(main_m)\n",
      "            if len(annots_info) == 0:\n",
      "                continue  \n",
      "            for info in annots_info:\n",
      "                info.annot_range = None\n",
      "            types_str = [\n",
      "                main_m.code_for_node(not_none(info.annot).annotation)\n",
      "                for info in annots_info\n",
      "            ]\n",
      "            replaces = dict()\n",
      "            for info in annots_info:\n",
      "                replaces[info.path] = mask_annot\n",
      "            new_code = (\n",
      "                \"# BEGIN\\n\" + apply_annotations(main_m, replaces).code + \"# END\\n\"\n",
      "            )\n",
      "            code_segs = new_code.split(SpecialNames.TypeMask)\n",
      "            assert (\n",
      "                len(code_segs) == len(types) + 1\n",
      "            ), f\"{len(code_segs)}!= {len(types) + 1}. replaces: {replaces}\\ncode: {new_code}\"\n",
      "\n",
      "            right_tks = None\n",
      "            if pre_args.show_callers:\n",
      "                caller_us = [\n",
      "                    u\n",
      "                    for u in not_none(analysis).used2user.get(elem.path, [])\n",
      "                    if u.user!= u.used\n",
      "                ]\n",
      "                certain_callers = [u for u in caller_us if u.is_certain]\n",
      "                potential_callers = [u for u in caller_us if not u.is_certain]\n",
      "...\n",
      "======= file: spot.static_analysis/PythonFunction.parent_class ========\n",
      "\n",
      "# BEGIN\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    parent_class: <mask>\n",
      "\n",
      "# END\n",
      "# spot.function_dataset\n",
      "def module_from_elems(\n",
      "    elems: Sequence[PythonElem],\n",
      "    path2class: dict[ProjectPath, PythonClass],\n",
      "    reversed: bool = False,\n",
      ") -> cst.Module:\n",
      "    gvars = list[PythonVariable]()\n",
      "    gfuncs = list[PythonFunction]()\n",
      "    gclasses = dict[ProjectPath, list[PythonElem]]()\n",
      "\n",
      "    for elem in elems:\n",
      "        if elem.parent_class:\n",
      "            used = gclasses.setdefault(elem.parent_class, [])\n",
      "            used.append(elem)\n",
      "        else:\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                gvars.append(elem)\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                gfuncs.append(elem)\n",
      "\n",
      "    stmt_groups = list[list]()\n",
      "\n",
      "    def location_lines(path: ProjectPath):\n",
      "        return [\n",
      "            cst.EmptyLine(comment=cst.Comment(\"# \" + path.module)),\n",
      "        ]\n",
      "\n",
      "    for var in gvars:\n",
      "        stmt_groups.append(\n",
      "            location_lines(var.path) + var.assignments + [cst.EmptyLine()]\n",
      "        )\n",
      "\n",
      "    for func in gfuncs:\n",
      "        stmt_groups.append(\n",
      "            [\n",
      "                func.tree.with_changes(leading_lines=location_lines(func.path)),\n",
      "                cst.EmptyLine(),\n",
      "            ]\n",
      "        )\n",
      "\n",
      "    for path, elems in gclasses.items():\n",
      "        cls = path2class[path]\n",
      "        cls_body = []\n",
      "        for e in elems:\n",
      "            if isinstance(e, PythonVariable):\n",
      "                cls_body.extend([cst.SimpleStatementLine([a]) for a in e.assignments])\n",
      "        for e in elems:\n",
      "            if isinstance(e, PythonFunction):\n",
      "                cls_body.append(e.tree)\n",
      "                cls_body.append(cst.EmptyLine())\n",
      "        if not cls_body:\n",
      "            continue\n",
      "        new_body = cst.IndentedBlock(body=cls_body)\n",
      "        stmts = [\n",
      "            cls.tree.with_changes(\n",
      "                leading_lines=location_lines(cls.path),\n",
      "                body=new_body,\n",
      "            ),\n",
      "            cst.EmptyLine(),\n",
      "        ]\n",
      "        stmt_groups.append(stmts)\n",
      "\n",
      "    if reversed:\n",
      "        stmt_groups.reverse()\n",
      "\n",
      "    return cst.Module(body=list(seq_flatten(stmt_groups)))\n",
      "\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "\n",
      "    def in_class(self) -> bool:\n",
      "        return self.parent_class is not None\n",
      "    \n",
      "\n",
      "# spot.static_analysis\n",
      "class PythonModuleBuilder(cst.CSTVisitor):\n",
      "\n",
      "    def visit_FunctionDef(self, node: cst.FunctionDef):\n",
      "        parent_type = self.visit_stack[-1]\n",
      "        self.visit_stack.append(_VisitType.Function)\n",
      "        if parent_type == _VisitType.Function:\n",
      "            return False\n",
      "        for dec in node.decorators:\n",
      "            match dec.decorator:\n",
      "                case cst.Name(\"overload\") | cst.Attribute(attr=cst.Name(\"overload\")):\n",
      "                    return False\n",
      "\n",
      "        name = node.name.value\n",
      "        path = self.current_class.name + \".\" + name if self.current_class else name\n",
      "        func = PythonFunction(\n",
      "            name=node.name.value,\n",
      "            path=ProjectPath(self.module_name, path),\n",
      "            tree=node,\n",
      "            parent_class=self.current_class.path if self.current_class else None,\n",
      "        )\n",
      "        fs = self.current_class.methods if self.current_class else self.functions\n",
      "        fs[func.name] = func\n",
      "\n",
      "        if parent_type == _VisitType.Root:\n",
      "            self.defined_symbols[func.name] = func.path\n",
      "    \n",
      "\n",
      "\n",
      "======= file: spot.static_analysis/PythonFunction.tree ========\n",
      "\n",
      "# BEGIN\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    tree: <mask>\n",
      "\n",
      "# END\n",
      "# spot.static_analysis\n",
      "def build_project_namespaces(\n",
      "    project: PythonProject,\n",
      ") -> dict[ModuleName, ProjNamespace]:\n",
      "    sorted_modules = sort_modules_by_imports(project)\n",
      "    result = dict[ModuleName, ProjNamespace]()\n",
      "    for mod in sorted_modules:\n",
      "        mv = _NsBuilder(mod, result)\n",
      "        project.modules[mod].tree.visit(mv)\n",
      "        new_ns = mv.namespace\n",
      "        new_ns.update(project.modules[mod].defined_symbols)\n",
      "        result[mod] = new_ns\n",
      "    return result\n",
      "\n",
      "# spot.static_analysis\n",
      "def compute_module_usages(mod: PythonModule):\n",
      "    wrapper = cst.MetadataWrapper(mod.tree, unsafe_skip_copy=True)\n",
      "    name_map = wrapper.resolve(QualifiedNameProvider)\n",
      "    pos_map = wrapper.resolve(PositionProvider)\n",
      "\n",
      "    recorder = UsageRecorder(name_map, pos_map)\n",
      "    result = list[tuple[ProjectPath, CodeRange, QualifiedName, bool]]()\n",
      "\n",
      "    for e in mod.all_elements():\n",
      "        match e:\n",
      "            case PythonFunction():\n",
      "                e.tree.body.visit(recorder)\n",
      "            case PythonVariable():\n",
      "                for a in e.assignments:\n",
      "                    if a.value:\n",
      "                        a.value.visit(recorder)\n",
      "        best_callee = dict[QualifiedName, tuple[bool, CodeRange]]()\n",
      "        for span, qn, is_call in recorder.usages:\n",
      "            if qn not in best_callee or int(is_call) > int(best_callee[qn][0]):\n",
      "                best_callee[qn] = (is_call, span)\n",
      "        for qn, (is_call, span) in best_callee.items():\n",
      "            result.append((e.path, span, qn, is_call))\n",
      "        recorder.usages.clear()\n",
      "\n",
      "    for cls in mod.classes:\n",
      "        cls.superclasses = list()\n",
      "        for b in cls.tree.bases:\n",
      "            if b.value in name_map and name_map[b.value]:\n",
      "                cls.superclasses.extend(name_map[b.value])\n",
      "            elif isinstance(b.value, cst.Name):\n",
      "                cls.superclasses.append(\n",
      "                    QualifiedName(b.value.value, QualifiedNameSource.LOCAL)\n",
      "                )\n",
      "\n",
      "    return result\n",
      "\n",
      "# spot.function_dataset\n",
      "def repo_to_tk_srcs(\n",
      "    repo: Path,\n",
      "    pre_args: PreprocessArgs,\n",
      "    max_line_width: int = 200,\n",
      ") -> list[TokenizedSrc]:\n",
      "    def src_filter(text):\n",
      "        width = max(len(l) for l in text.split(\"\\n\"))\n",
      "        return width <= max_line_width\n",
      "\n",
      "    proj = PythonProject.from_root(\n",
      "        repo,\n",
      "        True,\n",
      "        src_filter,\n",
      "        drop_comments=pre_args.drop_comments,\n",
      "    )\n",
      "\n",
      "    analysis = UsageAnalysis(proj)\n",
      "    sorted_moduels = analysis.sorted_modules\n",
      "\n",
      "\n",
      "    srcs = list[TokenizedSrc]()\n",
      "    for mpath in sorted_moduels:\n",
      "        mod = proj.modules[mpath]\n",
      "        preamble_segs = list[str]()\n",
      "        if pre_args.imports_in_preamble:\n",
      "            wo_imports, imports = remove_imports(mod.tree)\n",
      "            imports_part = cst.Module([cst.SimpleStatementLine([s]) for s in imports])\n",
      "            preamble_segs.append(imports_part.code)\n",
      "        if pre_args.stub_in_preamble:\n",
      "            preamble_segs.append(stub_from_module(mod.tree).code)\n",
      "        preamble = \"\".join(preamble_segs)\n",
      "        tokenized_preamble = DefaultTokenizer.encode(preamble, add_special_tokens=False)\n",
      "\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in mod.all_elements():\n",
      "            main_m = module_from_elems([elem], analysis.path2class)\n",
      "            annots_info, types = collect_user_annotations(main_m)\n",
      "            if len(annots_info) == 0:\n",
      "                continue  \n",
      "            for info in annots_info:\n",
      "                info.annot_range = None\n",
      "            types_str = [\n",
      "                main_m.code_for_node(not_none(info.annot).annotation)\n",
      "                for info in annots_info\n",
      "            ]\n",
      "            replaces = dict()\n",
      "            for info in annots_info:\n",
      "                replaces[info.path] = mask_annot\n",
      "            new_code = (\n",
      "                \"# BEGIN\\n\" + apply_annotations(main_m, replaces).code + \"# END\\n\"\n",
      "            )\n",
      "            code_segs = new_code.split(SpecialNames.TypeMask)\n",
      "            assert (\n",
      "                len(code_segs) == len(types) + 1\n",
      "            ), f\"{len(code_segs)}!= {len(types) + 1}. replaces: {replaces}\\ncode: {new_code}\"\n",
      "\n",
      "            right_tks = None\n",
      "            if pre_args.show_callers:\n",
      "                caller_us = [\n",
      "                    u\n",
      "                    for u in not_none(analysis).used2user.get(elem.path, [])\n",
      "                    if u.user!= u.used\n",
      "                ]\n",
      "                certain_callers = [u for u in caller_us if u.is_certain]\n",
      "                potential_callers = [u for u in caller_us if not u.is_certain]\n",
      "                right_m = module_from_elems(\n",
      "                    [\n",
      "                        analysis.path2elem[p.user]\n",
      "                        for p in certain_callers + potential_callers\n",
      "                    ],\n",
      "                    analysis.path2class,\n",
      "                )\n",
      "                if pre_args.drop_env_types:\n",
      "                    right_m = remove_types(right_m)\n",
      "                right_tks = DefaultTokenizer.encode(\n",
      "                    right_m.code, add_special_tokens=False\n",
      "                )\n",
      "\n",
      "            left_tks = None\n",
      "            if pre_args.show_callees:\n",
      "                callee_us = [\n",
      "                    u\n",
      "                    for u in not_none(analysis).user2used.get(elem.path, [])\n",
      "                    if u.user!= u.used\n",
      "                ]\n",
      "                certain_callees = [u for u in callee_us if u.is_certain]\n",
      "                potential_callees = [u for u in callee_us if not u.is_certain]\n",
      "                left_m = module_from_elems(\n",
      "                    [\n",
      "                        analysis.path2elem[p.used]\n",
      "                        for p in certain_callees + potential_callees\n",
      "                    ],\n",
      "                    analysis.path2class,\n",
      "                    reversed=True,\n",
      "                )\n",
      "                if pre_args.drop_env_types:\n",
      "                    left_m = remove_types(left_m)\n",
      "                left_tks = DefaultTokenizer.encode(\n",
      "                    left_m.code, add_special_tokens=False\n",
      "                )\n",
      "\n",
      "            file = Path(elem.path.module) / elem.path.path\n",
      "\n",
      "            src = tokenized_src_from_segs(\n",
      "                file=file,\n",
      "                repo=repo,\n",
      "                preamble=preamble,\n",
      "                tokenized_preamble=tokenized_preamble,\n",
      "                code_segs=code_segs,\n",
      "                types=types,\n",
      "                types_str=types_str,\n",
      "                annots_info=annots_info,\n",
      "                cst_code=main_m.code,\n",
      "                left_extra_tks=left_tks,\n",
      "                right_extra_tks=right_tks,\n",
      "            )\n",
      "            srcs.append(src)\n",
      "\n",
      "    return srcs\n",
      "\n",
      "# spot.function_dataset\n",
      "def module_from_elems(\n",
      "    elems: Sequence[PythonElem],\n",
      "    path2class: dict[ProjectPath, PythonClass],\n",
      "    reversed: bool = False,\n",
      ") -> cst.Module:\n",
      "    gvars = list[PythonVariable]()\n",
      "    gfuncs = list[PythonFunction]()\n",
      "    gclasses = dict[ProjectPath, list[PythonElem]]()\n",
      "\n",
      "    for elem in elems:\n",
      "        if elem.parent_class:\n",
      "            used = gclasses.setdefault(elem.parent_class, [])\n",
      "            used.append(elem)\n",
      "        else:\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                gvars.append(elem)\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                gfuncs.append(elem)\n",
      "\n",
      "    stmt_groups = list[list]()\n",
      "\n",
      "    def location_lines(path: ProjectPath):\n",
      "        return [\n",
      "            cst.EmptyLine(comment=cst.Comment(\"# \" + path.module)),\n",
      "        ]\n",
      "\n",
      "    for var in gvars:\n",
      "        stmt_groups.append(\n",
      "            location_lines(var.path) + var.assignments + [cst.EmptyLine()]\n",
      "        )\n",
      "\n",
      "    for func in gfuncs:\n",
      "        stmt_groups.append(\n",
      "            [\n",
      "                func.tree.with_changes(leading_lines=location_lines(func.path)),\n",
      "                cst.EmptyLine(),\n",
      "            ]\n",
      "        )\n",
      "\n",
      "    for path, elems in gclasses.items():\n",
      "        cls = path2class[path]\n",
      "        cls_body = []\n",
      "        for e in elems:\n",
      "            if isinstance(e, PythonVariable):\n",
      "                cls_body.extend([cst.SimpleStatementLine([a]) for a in e.assignments])\n",
      "        for e in elems:\n",
      "            if isinstance(e, PythonFunction):\n",
      "                cls_body.append(e.tree)\n",
      "                cls_body.append(cst.EmptyLine())\n",
      "        if not cls_body:\n",
      "            continue\n",
      "        new_body = cst.IndentedBlock(body=cls_body)\n",
      "        stmts = [\n",
      "            cls.tree.with_changes(\n",
      "                leading_lines=location_lines(cls.path),\n",
      "                body=new_body,\n",
      "            ),\n",
      "            cst.EmptyLine(),\n",
      "        ]\n",
      "        stmt_groups.append(stmts)\n",
      "\n",
      "    if reversed:\n",
      "        stmt_groups.reverse()\n",
      "\n",
      "    return cst.Module(body=list(seq_flatten(stmt_groups)))\n",
      "\n",
      "# spot.static_analysis\n",
      "...\n",
      "======= file: spot.static_analysis/PythonFunction.in_class ========\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "    parent_class: ProjectPath | None\n",
      "\n",
      "# BEGIN\n",
      "# spot.static_analysis\n",
      "@dataclass\n",
      "class PythonFunction:\n",
      "\n",
      "    def in_class(self) -> <mask>:\n",
      "        return self.parent_class is not None\n",
      "    \n",
      "\n",
      "# END\n",
      "# spot.static_analysis\n",
      "class UsageAnalysis:\n",
      "\n",
      "    def __init__(self, project: PythonProject):\n",
      "        self.project = project\n",
      "        self.ns_hier = ModuleHierarchy.from_modules(project.modules.keys())\n",
      "        module2ns = build_project_namespaces(project)\n",
      "        self.sorted_modules = list(module2ns.keys())\n",
      "\n",
      "        self.path2elem = {v.path: v for v in project.all_elems()}\n",
      "        self.path2class = {\n",
      "            cls.path: cls for mod in project.modules.values() for cls in mod.classes\n",
      "        }\n",
      "\n",
      "        for mname, ns in module2ns.items():\n",
      "            for s, p in ns.items():\n",
      "                if p in self.path2class:\n",
      "                    cls = self.path2class[p]\n",
      "                    self.path2class.setdefault(ProjectPath(mname, s), cls)\n",
      "                    if \"__init__\" in cls.methods:\n",
      "                        self.path2elem.setdefault(\n",
      "                            ProjectPath(mname, s),\n",
      "                            self.path2class[p].methods[\"__init__\"],\n",
      "                        )\n",
      "                elif p in self.path2elem:\n",
      "                    self.path2elem.setdefault(ProjectPath(mname, s), self.path2elem[p])\n",
      "\n",
      "        mod2usages = {\n",
      "            mname: compute_module_usages(project.modules[mname])\n",
      "            for mname in self.sorted_modules\n",
      "        }\n",
      "        for mname in self.sorted_modules:\n",
      "            mod = project.modules[mname]\n",
      "            for cls in mod.classes:\n",
      "                path_prefix = ProjectPath(mname, cls.name)\n",
      "                bases = not_none(cls.superclasses)\n",
      "                parents = [\n",
      "                    x for p in bases if (x := self.find_class(mname, p)) is not None\n",
      "                ]\n",
      "                for parent in parents:\n",
      "                    for a_name, a in parent.attributes.items():\n",
      "                        self.path2elem[path_prefix.append(a_name)] = a\n",
      "                    for m_name, m in parent.methods.items():\n",
      "                        self.path2elem[path_prefix.append(m_name)] = m\n",
      "                for m in cls.methods.values():\n",
      "                    self.path2elem[m.path] = m\n",
      "                for a in cls.attributes.values():\n",
      "                    self.path2elem[a.path] = a\n",
      "\n",
      "        for f in list(self.path2elem.values()):\n",
      "            if f.in_class and f.name == \"__init__\":\n",
      "                cons_p = ProjectPath(f.path.module, f.path.path[: -len(\".__init__\")])\n",
      "                self.path2elem[cons_p] = f\n",
      "\n",
      "        all_class_members = {x.path for x in project.all_elems() if x.in_class}\n",
      "        self.name2class_member = groupby(\n",
      "            [self.path2elem[p] for p in all_class_members], lambda e: e.name\n",
      "        )\n",
      "\n",
      "        best_usages = dict[tuple[ProjectPath, ProjectPath], ProjectUsage]()\n",
      "        for mname, usages in mod2usages.items():\n",
      "            for caller, span, qname, is_call in usages:\n",
      "                for u in self.generate_usages(mname, caller, span, qname, is_call):\n",
      "                    up = u.user, u.used\n",
      "                    if (\n",
      "                        up not in best_usages\n",
      "                        or u.is_certain > best_usages[up].is_certain\n",
      "                    ):\n",
      "                        best_usages[up] = u\n",
      "        all_usages = list(best_usages.values())\n",
      "        self.all_usages = all_usages\n",
      "        self.user2used = groupby(all_usages, lambda u: u.user)\n",
      "        self.used2user = groupby(all_usages, lambda u: u.used)\n",
      "    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for src in [s for s in srcs if \"static_analysis/PythonFunction\" in str(s.file)][:10]:\n",
    "    print(f\"======= file: {src.file} ========\")\n",
    "    src.print_code(max_lines=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainingConfig(imports_in_preamble=False)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.data import PreprocessArgs, repr_modified_args\n",
    "\n",
    "repr_modified_args(TrainingConfig(pre_args=PreprocessArgs(imports_in_preamble=False)), flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(proj'root.file3/usage1', CodeRange(start=CodePosition(line=6, column=4), end=CodePosition(line=6, column=9)), QualifiedName(name='gf', source=<QualifiedNameSource.IMPORT: 1>))\n",
      "(proj'root.file3/usage1', CodeRange(start=CodePosition(line=7, column=4), end=CodePosition(line=7, column=8)), QualifiedName(name='C', source=<QualifiedNameSource.IMPORT: 1>))\n"
     ]
    }
   ],
   "source": [
    "from spot.static_analysis import cst, PythonModule, compute_module_usages, PythonProject\n",
    "\n",
    "code1 = \"\"\"\n",
    "# root.file1\n",
    "\n",
    "# global function\n",
    "def gf(x):\n",
    "    return x * x\n",
    "\n",
    "# with inner function\n",
    "def gf_with_inner(x):\n",
    "    def inner(y):\n",
    "        return y * y\n",
    "    return inner(x)\n",
    "\n",
    "# class\n",
    "class C:\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "    \n",
    "    def foo(self, y):\n",
    "        return self.x + y\n",
    "\n",
    "    @staticmethod\n",
    "    def s_method(x):\n",
    "        return x + 1\n",
    "    \n",
    "\"\"\"\n",
    "code2 = \"\"\"\n",
    "# root.file2\n",
    "from .file1 import gf\n",
    "from root.file1 import gf_with_inner\n",
    "import root.file1\n",
    "import root.file1 as f1\n",
    "\n",
    "def usage1(x):\n",
    "    gf(x) + root.file1.C(5)\n",
    "    foo(5)\n",
    "\n",
    "def usage2(x):\n",
    "    def inner():\n",
    "        1 + gf_with_inner(x)\n",
    "    return inner()\n",
    "\n",
    "def usage_method1(x):\n",
    "    x = f1.C(5)\n",
    "    1 + x.foo(3)\n",
    "\n",
    "def usage_method2(x):\n",
    "    (1 + f1.C(5)).foo(3)\n",
    "\n",
    "def usage_local():\n",
    "    usage1(3)\n",
    "    UsageClass(4)\n",
    "\n",
    "@f1.C(1)\n",
    "def usage_dec():\n",
    "    pass\n",
    "\n",
    "class UsageClass:\n",
    "    def __init__(self, x):\n",
    "        self.x = gf_with_inner(x)\n",
    "        self.y = self.foo(5)\n",
    "\n",
    "    def foo(self, y):\n",
    "        return usage_local(f1.gf(y))\n",
    "\n",
    "    @staticmethod\n",
    "    def s_method(x):\n",
    "        return x\n",
    "\n",
    "class SubClass(UsageClass):\n",
    "    def use(self):\n",
    "        self.foo(5)\n",
    "        f1.C.s_method(5)\n",
    "\"\"\"\n",
    "\n",
    "code3 = \"\"\"\n",
    "# root.file3\n",
    "from .file1 import *\n",
    "\n",
    "def usage1(x):\n",
    "    gf(5)\n",
    "    C(5)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "project = PythonProject.from_modules(\n",
    "        [\n",
    "            PythonModule.from_cst(cst.parse_module(code1), \"root.file1\"),\n",
    "            PythonModule.from_cst(cst.parse_module(code2), \"root.file2\"),\n",
    "            PythonModule.from_cst(cst.parse_module(code3), \"root.file3\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for u in compute_module_usages(project.modules[\"root.file3\"]):\n",
    "    print(str(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root.file1': {'gf': proj'root.file1/gf',\n",
       "  'C': proj'root.file1/C',\n",
       "  'gf_with_inner': proj'root.file1/gf_with_inner'},\n",
       " 'root.file2': {'gf': proj'root.file1/gf',\n",
       "  'gf_with_inner': proj'root.file1/gf_with_inner',\n",
       "  'usage2': proj'root.file2/usage2',\n",
       "  'UsageClass': proj'root.file2/UsageClass',\n",
       "  'usage_method1': proj'root.file2/usage_method1',\n",
       "  'usage_method2': proj'root.file2/usage_method2',\n",
       "  'usage_local': proj'root.file2/usage_local',\n",
       "  'SubClass': proj'root.file2/SubClass',\n",
       "  'usage1': proj'root.file2/usage1',\n",
       "  'usage_dec': proj'root.file2/usage_dec'},\n",
       " 'root.file3': {'gf': proj'root.file1/gf',\n",
       "  'C': proj'root.file1/C',\n",
       "  'gf_with_inner': proj'root.file1/gf_with_inner',\n",
       "  'usage1': proj'root.file3/usage1'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.static_analysis import build_project_namespaces\n",
    "build_project_namespaces(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(proj'root.file3/usage1',\n",
       "  CodeRange(start=CodePosition(line=6, column=4), end=CodePosition(line=6, column=9)),\n",
       "  QualifiedName(name='gf', source=<QualifiedNameSource.IMPORT: 1>)),\n",
       " (proj'root.file3/usage1',\n",
       "  CodeRange(start=CodePosition(line=7, column=4), end=CodePosition(line=7, column=8)),\n",
       "  QualifiedName(name='C', source=<QualifiedNameSource.IMPORT: 1>))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.static_analysis import compute_module_usages\n",
    "\n",
    "compute_module_usages(project.modules[\"root.file3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local name: gf_with_inner.<locals>.inner\n",
      "Segs: ['gf_with_inner', '<locals>', 'inner']\n",
      "Local name: usage2.<locals>.inner\n",
      "Segs: ['usage2', '<locals>', 'inner']\n",
      "Local name: usage_method1.<locals>.x.foo\n",
      "Segs: ['usage_method1', '<locals>', 'x', 'foo']\n",
      "Case 3\n",
      "Local name: <method>.foo\n",
      "Local name: usage1\n",
      "Segs: ['usage1']\n",
      "Case 1\n",
      "Local name: UsageClass\n",
      "Segs: ['UsageClass']\n",
      "Case 2\n",
      "Local name: UsageClass.__init__.<locals>.self.foo\n",
      "Segs: ['UsageClass', 'foo']\n",
      "Case 1\n",
      "Local name: usage_local\n",
      "Segs: ['usage_local']\n",
      "Case 1\n",
      "Local name: SubClass.use.<locals>.self.foo\n",
      "Segs: ['SubClass', 'foo']\n",
      "Case 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FunctionUsage(caller=proj'root.file2/SubClass.use', callee=proj'root.file1/C.foo', call_site=CodeRange(start=CodePosition(line=42, column=8), end=CodePosition(line=42, column=19)), is_certain=False),\n",
       " FunctionUsage(caller=proj'root.file2/SubClass.use', callee=proj'root.file2/UsageClass.foo', call_site=CodeRange(start=CodePosition(line=42, column=8), end=CodePosition(line=42, column=19)), is_certain=False)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.static_analysis import UsageAnalysis, build_project_namespaces\n",
    "\n",
    "build_project_namespaces(project)\n",
    "\n",
    "analysis = UsageAnalysis(project)\n",
    "analysis.caller2callees[ProjectPath(\"root.file2\", \"SubClass.use\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@wraps(function)\n",
      "def catch_permission_denied(function):\n",
      "    import some.inner.imports\n",
      "    @wraps(function)\n",
      "    def decorated(x: <mask>, y: <mask>) -> <mask>:\n",
      "        try:\n",
      "            return function(*args, **kwargs)\n",
      "\n",
      "        except InsufficientPrivilege as error:\n",
      "            LOG.error(\"Forbidden: %s\", error) \n",
      "            raise Forbidden()\n",
      "\n",
      "    return decorated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import libcst as cst\n",
    "\n",
    "from spot.tokenized_src import TokenizedSrc, PreprocessArgs\n",
    "from spot.utils import Path, decode_tokens\n",
    "\n",
    "ex_code = '''# document comment 1\n",
    "  # document comment 2\n",
    "\"\"\"String document commnet\"\"\"\n",
    "import os; import spot;\n",
    "from sys import argv, exit\n",
    "# after import\n",
    "@wraps(function)\n",
    "def catch_permission_denied(function):\n",
    "    import some.inner.imports\n",
    "    \"\"\"\n",
    "    Decorator to catch :class:`psycopg2.ProgrammingError` exceptions with the\n",
    "    ``INSUFFICIENT_PRIVILEGE`` error code and rethrow them as\n",
    "    :class:`~werkzeug.exceptions.Forbidden` exceptions instead.\n",
    "    \"\"\"\n",
    "    @wraps(function)\n",
    "    def decorated(x: str, y: int) -> str:\n",
    "        try:\n",
    "            # comment 1\n",
    "            # comment 1 cont\n",
    "            return function(*args, **kwargs)\n",
    "\n",
    "        except InsufficientPrivilege as error:\n",
    "            LOG.error(\"Forbidden: %s\", error) # comment 2\n",
    "            raise Forbidden()\n",
    "\n",
    "    return decorated\n",
    "'''\n",
    "pre_args = PreprocessArgs(stub_in_preamble=True)\n",
    "ex_src = TokenizedSrc.parse(ex_code, Path(\"test_file\"), Path(\"test_repo\"), pre_args)\n",
    "print(decode_tokens(ex_src.tokenized_code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc4db6cf4c24dc09970460392d6c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='preamble', min=1), IntSlider(value=100, description='le…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spot.data import src_to_chunks_, CtxArgs, PreprocessArgs\n",
    "from ipywidgets import interactive\n",
    "\n",
    "pre_args = PreprocessArgs(stub_in_preamble=True)\n",
    "ex_src = TokenizedSrc.parse(ex_code, Path(\"test_file\"), Path(\"test_repo\"), pre_args)\n",
    "\n",
    "\n",
    "def print_code(\n",
    "    preamble: int,\n",
    "    left: int,\n",
    "    right: int,\n",
    "    ctx_size: int,\n",
    "    max_labels: int,\n",
    "    chunk_id: int,\n",
    "    inline_prev: bool,\n",
    "):\n",
    "    chunks = []\n",
    "    args = CtxArgs(ctx_size, preamble, left, right, max_labels=max_labels, inline_prev_gold=inline_prev)\n",
    "    src_to_chunks_(chunks, [], ex_src, (0, len(ex_src.types)), args)\n",
    "    print(decode_tokens(chunks[chunk_id][\"input_ids\"]))\n",
    "\n",
    "\n",
    "interactive(\n",
    "    print_code,\n",
    "    preamble=(1, 100),\n",
    "    left=(1, 200),\n",
    "    right=(1, 100),\n",
    "    ctx_size=(1, 500),\n",
    "    max_labels=(1, 10),\n",
    "    chunk_id=(0,1),\n",
    "    inline_prev=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from spot.data import GitRepo, ModuleRemapUnpickler\n",
    "from spot.type_env import (\n",
    "    AnnotPath,\n",
    "    MypyChecker,\n",
    "    SelectAnnotations,\n",
    "    TypeInfAction,\n",
    "    TypeInfEnv,\n",
    "    TypeInfState,\n",
    "    mypy_checker,\n",
    ")\n",
    "from spot.utils import cst, proj_root, read_file, seq_flatten, tqdm, write_file\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "datadir = Path(os.getenv(\"datadir\"))\n",
    "repos_dir = datadir / \"SPOT-data/repos\"\n",
    "\n",
    "useful_repos_path = proj_root() / \"scripts\" / \"useful_repos.pkl\"\n",
    "rename_module = lambda n: \"spot.data\" if n == \"spot.data_prepare\" else n\n",
    "with useful_repos_path.open(\"rb\") as f:\n",
    "    useful_repos: list[GitRepo] = ModuleRemapUnpickler(f, rename_module).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pre-trained model and tokenizer\n",
    "from spot.utils import get_data_dir\n",
    "\n",
    "model_dir = \"Salesforce/codet5-base\"\n",
    "# model_dir = datadir / \"checkpoints/saved/SPOT-CodeT5-no_margin/\"\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.t5 import T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "model: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_dir\n",
    ").to(device)\n",
    "max_target_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9077, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.data import mask_type_annots, output_ids_as_types, tokenize_masked\n",
    "\n",
    "test_code = \"\"\"\n",
    "@dataclass\n",
    "class GitRepo:\n",
    "    author: str\n",
    "    name: str\n",
    "    url: str\n",
    "    stars: int\n",
    "    forks: int\n",
    "\n",
    "    def authorname(self):\n",
    "        return self.author + \"__\" + self.name\n",
    "\n",
    "    def repo_dir(self, repos_dir: Path) -> Path:\n",
    "        return repos_dir / \"downloaded\" / self.authorname()\n",
    "\n",
    "    def download(self, repos_dir: Path, timeout=None) -> bool:\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_model(code: str, num_beams=16):\n",
    "    masked = mask_type_annots((Path(\"no_source\"), code))\n",
    "    tks = tokenize_masked(masked, tokenizer, device)\n",
    "    input_ids = tks[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        loss = model.forward(**tks).loss\n",
    "        dec = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_target_length,\n",
    "            num_beams=num_beams,\n",
    "            # do_sample=True,\n",
    "        )[0]\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"predicted_types\": output_ids_as_types(dec, tokenizer),\n",
    "        \"labels\": output_ids_as_types(tks[\"labels\"][0], tokenizer),\n",
    "        \"generation\": tokenizer.decode(dec),\n",
    "        \"input_ids\": input_ids[0],\n",
    "        \"output_ids\": dec,\n",
    "        \"annots_info\": masked[\"annots_info\"],\n",
    "    }\n",
    "\n",
    "\n",
    "result = run_model(test_code, num_beams=10)\n",
    "result[\"loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot import PythonType\n",
    "from spot.type_env import apply_annotations\n",
    "\n",
    "\n",
    "def type_to_annot(ty: PythonType) -> str:\n",
    "    return cst.Annotation(cst.parse_expression(str(ty)))\n",
    "\n",
    "\n",
    "def run_aug_model(src: Path, cwd: Path):\n",
    "    result = run_model(read_file(src), num_beams=10)\n",
    "    pred_annots = {\n",
    "        info.path: type_to_annot(t)\n",
    "        for info, t in zip(result[\"annots_info\"], result[\"predicted_types\"])\n",
    "    }\n",
    "    m1 = apply_annotations(cst.parse_module(read_file(src)), pred_annots)\n",
    "    write_file(src, m1.code)\n",
    "    checker_r = MypyChecker.check_project(src, cwd)\n",
    "    pos_to_preds = {\n",
    "        info.annot_range: str(ty)\n",
    "        for info, ty in zip(result[\"annots_info\"], result[\"predicted_types\"])\n",
    "    }\n",
    "    return {\n",
    "        \"model_result\": result,\n",
    "        \"module\": m1,\n",
    "        \"checker_feedback\": checker_r,\n",
    "        \"pos_to_preds\": pos_to_preds,\n",
    "    }\n",
    "\n",
    "\n",
    "aug_r = run_aug_model(inference_dir / \"env_code_2.py\", inference_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- model output ----\n",
      "<pad><s><extra_id_0>int<extra_id_1>int<extra_id_2>int<extra_id_3>int<extra_id_4>int, y : int<extra_id_5>int<extra_id_6>Optional[int]<extra_id_7>int<extra_id_8>int<extra_id_9>Bar[int, int, int, float, float]</s>\n",
      "---- checker_feedback ----\n",
      "env_code_2.py:20:14: error: Incompatible types in assignment (expression has type \"str\", variable has type \"int\")  [assignment]\n",
      "env_code_2.py:32:29: error: Argument 1 to \"len\" has incompatible type \"int\"; expected \"Sized\"  [arg-type]\n",
      "env_code_2.py:35:6: error: \"Bar\" expects no type arguments, but 5 given  [type-arg]\n",
      "Found 3 errors in 1 file (checked 1 source file)\n",
      "\n",
      "---- new input ----\n",
      "# Env example 2: some existing annotations\n",
      "\n",
      "from typing import *\n",
      "\n",
      "\n",
      "def fib(n: /* int */<extra_id_0>):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fib(n - 1) + fib(n - 2)\n",
      "\n",
      "\n",
      "def foo(bar: /* int */<extra_id_1>):\n",
      "    return fib(bar)\n",
      "\n",
      "\n",
      "class Bar:\n",
      "    z: /* int */<extra_id_2> = /* error: Incompatible types in assignment (expression has type \"str\", variable has type \"int\")  */\"hello\"\n",
      "    w: /* int */<extra_id_3>\n",
      "\n",
      "    def __init__(self, x: /* Any */<extra_id_4>):\n",
      "        self.x: /* int */<extra_id_5> = x\n",
      "        self.y: /* Optional[int] */<extra_id_6> = None\n",
      "        self.reset(self.z)\n",
      "\n",
      "    def reset(self, w0):\n",
      "        self.w = w0\n",
      "\n",
      "    def foo(self, z: /* int */<extra_id_7>) -> /* int */<extra_id_8>:\n",
      "        return self.x + len(/* error: Argument 1 to \"len\" has incompatible type \"int\"; expected \"Sized\"  */z)\n",
      "\n",
      "\n",
      "bar: /* Bar[int, int, int, float, float] *//* error: \"Bar\" expects no type arguments, but 5 given  */<extra_id_9> = Bar(3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import patch_code_with_extra\n",
    "\n",
    "print(\"---- predicted types ----\")\n",
    "print(aug_r[\"model_result\"][\"predicted_types\"])\n",
    "print(\"---- model output ----\")\n",
    "print(tokenizer.decode(aug_r[\"model_result\"][\"output_ids\"], skip_special_tokens=False))\n",
    "print(\"---- checker_feedback ----\")\n",
    "print(aug_r[\"checker_feedback\"].output_str)\n",
    "\n",
    "print(\"---- new input ----\")\n",
    "new_input = patch_code_with_extra(\n",
    "    aug_r[\"module\"].code,\n",
    "    aug_r[\"pos_to_preds\"],\n",
    "    aug_r[\"checker_feedback\"].error_dict[\"env_code_2.py\"],\n",
    ")\n",
    "print(new_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountedAcc(16.23%, count=573)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from spot.utils import Path, run_long_task, DefaultTokenizer, not_none, CountedAcc\n",
    "from spot import proj_root\n",
    "from spot.function_dataset import guess_src_root\n",
    "\n",
    "datadir = Path(not_none(os.getenv(\"datadir\")))\n",
    "repos_dir = datadir / \"SPOT-data/repos/\"\n",
    "\n",
    "repos_split_path = proj_root() /  \"data/repos_split.pkl\"\n",
    "with repos_split_path.open(\"rb\") as f:\n",
    "    repos_split = pickle.load(f)\n",
    "\n",
    "root_is_src = list[bool]()\n",
    "for repo in repos_split[\"train\"]:\n",
    "    rd = repo.repo_dir(repos_dir)\n",
    "    root_is_src.append(guess_src_root(rd).name == \"src\")\n",
    "\n",
    "CountedAcc(sum(root_is_src), len(root_is_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_projects: 573\n",
      "src_in_root: 93\n",
      "package_in_root: 203\n",
      "setup_in_root: 107\n",
      "weird_repos: 170\n"
     ]
    }
   ],
   "source": [
    "src_in_root = 0\n",
    "package_in_root = 0\n",
    "setup_in_root = 0\n",
    "n_proj = 0\n",
    "\n",
    "weird_repos = []\n",
    "setup_files = []\n",
    "\n",
    "for repo in repos_split[\"train\"]:\n",
    "    rd: Path = repo.repo_dir(repos_dir)\n",
    "    n_proj += 1\n",
    "    files = list(rd.iterdir())\n",
    "    if rd / \"src\" in files:\n",
    "        src_in_root += 1\n",
    "    elif rd / (pname := rd.name.split(\"__\")[-1]) in files:\n",
    "        package_in_root += 1\n",
    "    elif rd / \"setup.cfg\" in files:\n",
    "        setup_in_root += 1\n",
    "        setup_files.append(rd / \"setup.cfg\")\n",
    "    else:\n",
    "        weird_repos.append(repo)\n",
    "\n",
    "print(\"n_projects:\", n_proj)\n",
    "print(\"src_in_root:\", src_in_root)\n",
    "print(\"package_in_root:\", package_in_root)\n",
    "print(\"setup_in_root:\", setup_in_root)\n",
    "print(\"weird_repos:\", len(weird_repos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: downloaded/tiangolo__uvicorn-gunicorn-docker\n",
      "scripts\n",
      ".gitignore\n",
      "mypy.ini\n",
      "README.md\n",
      "tests\n",
      ".github\n",
      ".mypy_cache\n",
      ".git\n",
      "docker-images\n",
      "pyproject.toml\n",
      "LICENSE\n",
      "Repo: downloaded/uwbmrb__BMRBDep\n",
      ".gitignore\n",
      "install.sh\n",
      "ADIT-NMR Testing.ods\n",
      "README.md\n",
      "FrontEnd\n",
      "deploy.sh\n",
      "BackEnd\n",
      "nginx_configuration_example.conf\n",
      "upgrade.sh\n",
      "apache_configuration_example.conf\n",
      ".mypy_cache\n",
      ".git\n",
      "wsgi.conf\n",
      "installation.md\n",
      ".editorconfig\n",
      "Dockerfile\n",
      "build_docker.sh\n",
      "run_locally.sh\n",
      ".dockerignore\n",
      "Repo: downloaded/jfcherng__Sublime-VisualizeZeroWidthChars\n",
      "messages\n",
      "dependencies.json\n",
      "docs\n",
      ".flake8\n",
      "boot.py\n",
      "scripts\n",
      ".gitignore\n",
      "typings\n",
      "mypy.ini\n",
      ".python-version\n",
      "messages.json\n",
      "README.md\n",
      "menus\n",
      "plugin\n",
      ".github\n",
      ".mypy_cache\n",
      ".git\n",
      "pyproject.toml\n",
      "VisualizeZeroWidthChars.sublime-settings\n",
      "CHANGELOG.md\n",
      "requirements.txt\n",
      ".gitattributes\n",
      "LICENSE\n",
      ".editorconfig\n",
      "Repo: downloaded/chaosdorf__mpd-mqtt-gateway\n",
      ".gitignore\n",
      "gateway.py\n",
      ".github\n",
      "Pipfile\n",
      ".mypy_cache\n",
      "server.py\n",
      ".git\n",
      "Dockerfile\n",
      "Pipfile.lock\n",
      "Repo: downloaded/Celeo__Preston\n",
      "preston\n",
      ".gitignore\n",
      "README.md\n",
      "pytest.ini\n",
      "tests\n",
      ".github\n",
      ".mypy_cache\n",
      "poetry.lock\n",
      ".git\n",
      "pyproject.toml\n",
      "LICENSE\n",
      ".vscode\n",
      "Repo: downloaded/andrewscwei__rbc-statement-parser\n",
      "parse_csv.py\n",
      ".gitignore\n",
      "__pycache__\n",
      "README.md\n",
      "parse_tbl.py\n",
      "Pipfile\n",
      ".mypy_cache\n",
      ".git\n",
      "config\n",
      "LICENSE\n",
      "parse_pdf.py\n",
      "utils.py\n",
      "Pipfile.lock\n",
      "Repo: downloaded/devonhollowood__adventofcode\n",
      "2016\n",
      "README.md\n",
      "2019\n",
      "2017\n",
      ".mypy_cache\n",
      "2015\n",
      ".git\n",
      "LICENSE\n",
      "2018\n",
      "2021\n",
      "2020\n",
      "Repo: downloaded/tedle__uitabot\n",
      "scripts\n",
      ".gitignore\n",
      "web-client\n",
      "README.md\n",
      "CONFIG.md\n",
      "config.example.json\n",
      "COMMANDS.md\n",
      ".github\n",
      "bot\n",
      ".mypy_cache\n",
      ".git\n",
      "CHANGELOG.md\n",
      ".gitattributes\n",
      "LICENSE\n",
      "Repo: downloaded/JohnStrunk__ocs-monkey\n",
      "build.sh\n",
      "chaos_runner.py\n",
      ".gitignore\n",
      "mypy.ini\n",
      "log_gather.py\n",
      ".travis\n",
      "README.md\n",
      "setup-env.sh\n",
      "kube.py\n",
      ".github\n",
      "util.py\n",
      "event.py\n",
      ".mypy_cache\n",
      ".git\n",
      "tox.ini\n",
      "osio-workload\n",
      "workload_runner.py\n",
      "requirements.txt\n",
      "oc_in_cluster.sh\n",
      "test_kube.py\n",
      "osio.py\n",
      "LICENSE\n",
      "Dockerfile\n",
      "failure.py\n",
      "helm\n",
      "conftest.py\n",
      "log_gather_ocs.py\n",
      "failure_ocs.py\n",
      ".dockerignore\n",
      "Repo: downloaded/jmanuel1__material-search\n",
      "scripts\n",
      ".gitignore\n",
      "elements\n",
      "README.md\n",
      "package.json\n",
      "images\n",
      "manifest.json\n",
      "robots.txt\n",
      ".mypy_cache\n",
      "polymer.json\n",
      ".git\n",
      "gulpfile.js\n",
      "requirements.txt\n",
      "index.html\n",
      ".gitattributes\n",
      "yarn.lock\n",
      "favicon.ico\n",
      "styles\n",
      "test\n",
      "LICENSE.md\n"
     ]
    }
   ],
   "source": [
    "for repo in weird_repos[:10]:\n",
    "    rd: Path = repo.repo_dir(repos_dir)\n",
    "    print(\"Repo:\", rd.relative_to(repos_dir))\n",
    "    for f in rd.iterdir():\n",
    "        print(f.relative_to(rd))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
