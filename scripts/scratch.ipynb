{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from spot.data import GitRepo, ModuleRemapUnpickler\n",
    "from spot.type_env import (\n",
    "    AnnotPath,\n",
    "    MypyChecker,\n",
    "    SelectAnnotations,\n",
    "    TypeInfAction,\n",
    "    TypeInfEnv,\n",
    "    TypeInfState,\n",
    "    collect_annotations,\n",
    "    mypy_checker,\n",
    ")\n",
    "from spot.utils import cst, proj_root, read_file, seq_flatten, tqdm, write_file\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "datadir = Path(os.getenv(\"datadir\"))\n",
    "repos_dir = datadir / \"SPOT-data/repos\"\n",
    "\n",
    "useful_repos_path = proj_root() / \"scripts\" / \"useful_repos.pkl\"\n",
    "rename_module = lambda n: \"spot.data\" if n == \"spot.data_prepare\" else n\n",
    "with useful_repos_path.open(\"rb\") as f:\n",
    "    useful_repos: list[GitRepo] = ModuleRemapUnpickler(f, rename_module).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loading pre-trained model and tokenizer\n",
    "\n",
    "model_dir = datadir / \"checkpoints/saved/SPOT-CodeT5-with_margin/\"\n",
    "# model_dir = datadir / \"checkpoints/saved/SPOT-CodeT5-no_margin/\"\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.t5 import T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "model: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_dir\n",
    ").to(device)\n",
    "max_target_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "inference_dir = Path(\"data/code_output/inference\")\n",
    "if inference_dir.exists():\n",
    "    shutil.rmtree(inference_dir)\n",
    "inference_dir.mkdir(parents=True)\n",
    "write_file(inference_dir / \"env_code_1.py\", read_file(\"data/code/env_code_1.py\"))\n",
    "write_file(inference_dir / \"env_code_2.py\", read_file(\"data/code/env_code_2.py\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9077, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.data import mask_type_annots, output_ids_as_types, tokenize_masked\n",
    "\n",
    "test_code = \"\"\"\n",
    "@dataclass\n",
    "class GitRepo:\n",
    "    author: str\n",
    "    name: str\n",
    "    url: str\n",
    "    stars: int\n",
    "    forks: int\n",
    "\n",
    "    def authorname(self):\n",
    "        return self.author + \"__\" + self.name\n",
    "\n",
    "    def repo_dir(self, repos_dir: Path) -> Path:\n",
    "        return repos_dir / \"downloaded\" / self.authorname()\n",
    "\n",
    "    def download(self, repos_dir: Path, timeout=None) -> bool:\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_model(code: str, num_beams=16):\n",
    "    masked = mask_type_annots((Path(\"no_source\"), code))\n",
    "    tks = tokenize_masked(masked, tokenizer, device)\n",
    "    input_ids = tks[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        loss = model.forward(**tks).loss\n",
    "        dec = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_target_length,\n",
    "            num_beams=num_beams,\n",
    "            # do_sample=True,\n",
    "        )[0]\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"predicted_types\": output_ids_as_types(dec, tokenizer),\n",
    "        \"labels\": output_ids_as_types(tks[\"labels\"][0], tokenizer),\n",
    "        \"generation\": tokenizer.decode(dec),\n",
    "        \"input_ids\": input_ids[0],\n",
    "        \"output_ids\": dec,\n",
    "        \"annots_info\": masked[\"annots_info\"],\n",
    "    }\n",
    "\n",
    "\n",
    "result = run_model(test_code, num_beams=10)\n",
    "result[\"loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot import PythonType\n",
    "from spot.type_env import apply_annotations\n",
    "\n",
    "\n",
    "def type_to_annot(ty: PythonType) -> str:\n",
    "    return cst.Annotation(cst.parse_expression(str(ty)))\n",
    "\n",
    "\n",
    "def run_aug_model(src: Path, cwd: Path):\n",
    "    result = run_model(read_file(src), num_beams=10)\n",
    "    pred_annots = {\n",
    "        info.path: type_to_annot(t)\n",
    "        for info, t in zip(result[\"annots_info\"], result[\"predicted_types\"])\n",
    "    }\n",
    "    m1 = apply_annotations(cst.parse_module(read_file(src)), pred_annots)\n",
    "    write_file(src, m1.code)\n",
    "    checker_r = MypyChecker.check_project(src, cwd)\n",
    "    pos_to_preds = {\n",
    "        info.annot_range: str(ty)\n",
    "        for info, ty in zip(result[\"annots_info\"], result[\"predicted_types\"])\n",
    "    }\n",
    "    return {\n",
    "        \"model_result\": result,\n",
    "        \"module\": m1,\n",
    "        \"checker_feedback\": checker_r,\n",
    "        \"pos_to_preds\": pos_to_preds,\n",
    "    }\n",
    "\n",
    "\n",
    "aug_r = run_aug_model(inference_dir / \"env_code_2.py\", inference_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- model output ----\n",
      "<pad><s><extra_id_0>int<extra_id_1>int<extra_id_2>int<extra_id_3>int<extra_id_4>int, y : int<extra_id_5>int<extra_id_6>Optional[int]<extra_id_7>int<extra_id_8>int<extra_id_9>Bar[int, int, int, float, float]</s>\n",
      "---- checker_feedback ----\n",
      "env_code_2.py:20:14: error: Incompatible types in assignment (expression has type \"str\", variable has type \"int\")  [assignment]\n",
      "env_code_2.py:32:29: error: Argument 1 to \"len\" has incompatible type \"int\"; expected \"Sized\"  [arg-type]\n",
      "env_code_2.py:35:6: error: \"Bar\" expects no type arguments, but 5 given  [type-arg]\n",
      "Found 3 errors in 1 file (checked 1 source file)\n",
      "\n",
      "---- new input ----\n",
      "# Env example 2: some existing annotations\n",
      "\n",
      "from typing import *\n",
      "\n",
      "\n",
      "def fib(n: /* int */<extra_id_0>):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fib(n - 1) + fib(n - 2)\n",
      "\n",
      "\n",
      "def foo(bar: /* int */<extra_id_1>):\n",
      "    return fib(bar)\n",
      "\n",
      "\n",
      "class Bar:\n",
      "    z: /* int */<extra_id_2> = /* error: Incompatible types in assignment (expression has type \"str\", variable has type \"int\")  */\"hello\"\n",
      "    w: /* int */<extra_id_3>\n",
      "\n",
      "    def __init__(self, x: /* Any */<extra_id_4>):\n",
      "        self.x: /* int */<extra_id_5> = x\n",
      "        self.y: /* Optional[int] */<extra_id_6> = None\n",
      "        self.reset(self.z)\n",
      "\n",
      "    def reset(self, w0):\n",
      "        self.w = w0\n",
      "\n",
      "    def foo(self, z: /* int */<extra_id_7>) -> /* int */<extra_id_8>:\n",
      "        return self.x + len(/* error: Argument 1 to \"len\" has incompatible type \"int\"; expected \"Sized\"  */z)\n",
      "\n",
      "\n",
      "bar: /* Bar[int, int, int, float, float] *//* error: \"Bar\" expects no type arguments, but 5 given  */<extra_id_9> = Bar(3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import patch_code_with_extra\n",
    "print(\"---- predicted types ----\")\n",
    "print(aug_r['model_result']['predicted_types'])\n",
    "print(\"---- model output ----\")\n",
    "print(tokenizer.decode(aug_r[\"model_result\"][\"output_ids\"], skip_special_tokens=False))\n",
    "print(\"---- checker_feedback ----\")\n",
    "print(aug_r[\"checker_feedback\"].output_str)\n",
    "\n",
    "print(\"---- new input ----\")\n",
    "new_input = patch_code_with_extra(\n",
    "    aug_r[\"module\"].code,\n",
    "    aug_r[\"pos_to_preds\"],\n",
    "    aug_r[\"checker_feedback\"].error_dict[\"env_code_2.py\"],\n",
    ")\n",
    "print(new_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_types': [int,\n",
       "  int,\n",
       "  int,\n",
       "  int,\n",
       "  int,\n",
       "  int,\n",
       "  None,\n",
       "  int,\n",
       "  int,\n",
       "  Bar[int, int, int, float, float]],\n",
       " 'generation': '<pad><s><extra_id_0>int<extra_id_1>int<extra_id_2>int<extra_id_3>int<extra_id_4>int<extra_id_5>int<extra_id_6>None<extra_id_7>int<extra_id_8>int<extra_id_9>Bar[int, int, int, float, float]</s>'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_model_with_extra(code: str, num_beams=16):\n",
    "    input_ids = tokenizer.encode(code, return_tensors=\"pt\").to(device)\n",
    "    dec = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_target_length,\n",
    "        num_beams=num_beams,\n",
    "    )[0]\n",
    "    return {\n",
    "        \"predicted_types\": output_ids_as_types(dec, tokenizer),\n",
    "        \"generation\": tokenizer.decode(dec),\n",
    "    }\n",
    "\n",
    "\n",
    "run_model_with_extra(new_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Env example 2: some existing annotations\n",
      "\n",
      "from typing import *\n",
      "\n",
      "\n",
      "def fib(n: int):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fib(n - 1) + fib(n - 2)\n",
      "\n",
      "\n",
      "def foo(bar: int):\n",
      "    return fib(bar)\n",
      "\n",
      "\n",
      "class Bar:\n",
      "    z: int = /*[assignment]*/\"hello\"\n",
      "    w: int\n",
      "\n",
      "    def __init__(self, x: Any):\n",
      "        self.x: int = x\n",
      "        self.y: Optional[int] = None\n",
      "        self.reset(self.z)\n",
      "\n",
      "    def reset(self, w0):\n",
      "        self.w = w0\n",
      "\n",
      "    def foo(self, z: int) -> int:\n",
      "        return self.x + len(z)\n",
      "\n",
      "\n",
      "bar: Bar[int, int, int, float, float] = Bar(3)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import insert_strings\n",
    "\n",
    "print(insert_strings(aug_r[\"module\"].code, [(19, 13, \"/*[assignment]*/\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "@dataclass\n",
      "class GitRepo:\n",
      "    author:<extra_id_0>\n",
      "    name:<extra_id_1>\n",
      "    url:<extra_id_2>\n",
      "    stars:<extra_id_3>\n",
      "    forks:<extra_id_4>\n",
      "\n",
      "    def authorname(self):\n",
      "        return self.author + \"__\" + self.name\n",
      "\n",
      "    def repo_dir(self, repos_dir:<extra_id_5>) -><extra_id_6>:\n",
      "        return repos_dir / \"downloaded\" / self.authorname()\n",
      "\n",
      "    def download(self, repos_dir:<extra_id_7>, timeout=None) -><extra_id_8>:\n",
      "        pass\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Replace all types to predict with special tokens\n",
    "print(tokenizer.decode(result[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Ċ', '@', 'data', 'class', 'Ċ', 'class', 'ĠGit', 'Repo', ':', 'Ċ', 'ĠĠĠ', 'Ġauthor', ':', '<extra_id_0>', 'Ċ', 'ĠĠĠ', 'Ġname', ':', '<extra_id_1>', 'Ċ', 'ĠĠĠ', 'Ġurl', ':', '<extra_id_2>', 'Ċ', 'ĠĠĠ', 'Ġstars', ':', '<extra_id_3>', 'Ċ', 'ĠĠĠ', 'Ġfor', 'ks', ':', '<extra_id_4>', 'Ċ', 'Ċ', 'ĠĠĠ', 'Ġdef', 'Ġauthor', 'name', '(', 'self', '):', 'Ċ', 'ĠĠĠĠĠĠĠ', 'Ġreturn', 'Ġself', '.', 'author', 'Ġ+', 'Ġ\"__', '\"', 'Ġ+', 'Ġself', '.', 'name', 'Ċ', 'Ċ', 'ĠĠĠ', 'Ġdef', 'Ġrepo', '_', 'dir', '(', 'self', ',', 'Ġrepos', '_', 'dir', ':', '<extra_id_5>', ')', 'Ġ->', '<extra_id_6>', ':', 'Ċ', 'ĠĠĠĠĠĠĠ', 'Ġreturn', 'Ġrepos', '_', 'dir', 'Ġ/', 'Ġ\"', 'down', 'loaded', '\"', 'Ġ/', 'Ġself', '.', 'author', 'name', '()', 'Ċ', 'Ċ', 'ĠĠĠ', 'Ġdef', 'Ġdownload', '(', 'self', ',', 'Ġrepos', '_', 'dir', ':', '<extra_id_7>', ',', 'Ġtimeout', '=', 'None', ')', 'Ġ->', '<extra_id_8>', ':', 'Ċ', 'ĠĠĠĠĠĠĠ', 'Ġpass', 'Ċ', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize using Byte Pair Encoding (BPE)\n",
    "print(tokenizer.convert_ids_to_tokens(result[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<s>', '<extra_id_0>', 'str', '<extra_id_1>', 'str', '<extra_id_2>', 'str', '<extra_id_3>', 'List', '[', 'str', ']', 'Ġ+', 'ĠList', '[', 'str', ']', '<extra_id_4>', 'List', '[', 'str', ']', 'Ġ+', 'ĠList', '[', 'str', ']', 'Ġ+', 'ĠList', '[', 'str', ']', '<extra_id_5>', 'Path', '<extra_id_6>', 'Path', 'Ġ.', 'ĠPath', '<extra_id_7>', 'Path', 'Ġ.', 'ĠPath', '<extra_id_8>', 'Path', 'Ġ.', 'ĠPath', 'Ġ[', 'Ġstr', ']', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Let model predict a sequence of types using BPE\n",
    "print(tokenizer.convert_ids_to_tokens(result[\"output_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[str, str, str, Any, Any, Path, Path.Path, Path.Path, Path.Path[str]]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract the predicted types\n",
    "print(result[\"predicted_types\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 83.00%\n",
      "a_details:\n",
      "   ...\n",
      "b: 32.00%\n"
     ]
    }
   ],
   "source": [
    "acc_dict = {\n",
    "    \"a\": 0.83,\n",
    "    \"a_details\": {\n",
    "        \"acc\": 0.86,\n",
    "        \"partial\": 0.12,\n",
    "        \"breakdown\": {\n",
    "            \"e\": 0.7,\n",
    "            \"xx\": None,\n",
    "        }\n",
    "    },\n",
    "    \"b\": 0.32,\n",
    "}\n",
    "from spot.data import pretty_print_accuracies\n",
    "pretty_print_accuracies(acc_dict, max_indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert: (test task finished) Time taken: 1.0s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from spot.utils import run_long_task\n",
    "\n",
    "with run_long_task(\"test task\"):\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
