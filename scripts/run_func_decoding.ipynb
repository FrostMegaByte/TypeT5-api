{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Model loaded to cuda:1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# first, load the trained model\n",
    "import os\n",
    "import torch\n",
    "from typing import *\n",
    "\n",
    "from spot.model import ModelWrapper\n",
    "from spot.utils import get_model_dir, proj_root\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "gpu_id = 1\n",
    "modeldir = get_model_dir()\n",
    "\n",
    "# model_name=\"model-v4--TrainingConfig(func_only=True, drop_env_types=False, left_margin=1536, preamble_size=768, right_margin=2048)\"\n",
    "model_name=\"model-v5--TrainingConfig(drop_env_types=False)\"\n",
    "wrapper = ModelWrapper.from_pretrained(\n",
    "    modeldir / model_name\n",
    ")\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "wrapper.to(device)\n",
    "print(f\"Model loaded to {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.static_analysis import (\n",
    "    PythonProject,\n",
    "    PythonModule,\n",
    "    UsageAnalysis,\n",
    "    mask_types,\n",
    "    remove_comments,\n",
    ")\n",
    "from spot.utils import cst, read_file, SpecialNames\n",
    "from spot.function_dataset import data_project_from_dir\n",
    "from spot.visualization import show_code_range\n",
    "\n",
    "# ex_code = read_file(\"src/spot/function_decoding.py\")\n",
    "# ex_module = mask_types(cst.parse_module(ex_code))\n",
    "# ex_project = PythonProject.from_modules([PythonModule.from_cst(ex_module, \"spot.function_decoding\")])\n",
    "\n",
    "src_set = {\n",
    "    \"function_decoding.py\",\n",
    "    \"data.py\",\n",
    "    \"type_env.py\",\n",
    "    \"function_dataset.py\",\n",
    "    \"tokenized_src.py\",\n",
    "    \"type_check.py\",\n",
    "    \"model.py\",\n",
    "    \"utils.py\",\n",
    "    \"static_analysis.py\",\n",
    "}\n",
    "\n",
    "ex_project = data_project_from_dir(proj_root(), file_filter=lambda f: f.name in {\"model.py\", \"utils.py\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_on_projects: 100%|██████████| 134/134 [00:44<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_acc: 70.27% (count=185)\n",
      "full_acc: 68.11% (count=185)\n",
      "full_acc_by_common:\n",
      "   rare: 68.11% (count=185)\n",
      "full_acc_by_cat:\n",
      "   FuncArg: 63.37% (count=101)\n",
      "   FuncReturn: 65.45% (count=55)\n",
      "   ClassAtribute: 89.29% (count=28)\n",
      "   GlobalVar: 100.00% (count=1)\n",
      "full_acc_by_pos:\n",
      "   range(0, 1): 69.79% (count=96)\n",
      "   range(1, 2): 61.54% (count=52)\n",
      "   range(2, 4): 75.76% (count=33)\n",
      "   range(4, 8): 50.00% (count=4)\n",
      "avg_label_size: 1.1459\n",
      "avg_pred_size: 1.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    ProcessPoolExecutor,\n",
    "    ThreadPoolExecutor,\n",
    ")\n",
    "from spot.model import DecodingArgs\n",
    "from spot.visualization import pretty_print_dict\n",
    "\n",
    "ctx_args = wrapper.args.ctx_args\n",
    "wrapper.args = DecodingArgs(\n",
    "    sampling_max_tokens=ctx_args.ctx_size,\n",
    "    ctx_args=ctx_args,\n",
    "    do_sample=False,\n",
    "    num_beams=16,\n",
    "    tokens_per_type=16,\n",
    "    length_penalty=0.2,\n",
    ")\n",
    "\n",
    "rctx = RolloutCtx(\n",
    "    model=wrapper,\n",
    ")\n",
    "\n",
    "pre_args = PreprocessArgs()\n",
    "\n",
    "evalr = await rctx.evaluate_on_projects(\n",
    "    [ex_project], pre_args, DecodingOrders.RandomOrder(),\n",
    ")\n",
    "\n",
    "pretty_print_dict(evalr.accuracies(None, wrapper.common_type_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.model/DecodingArgs.max_workers\n",
      "prediction: [ty'int']\n",
      "input: import random\n",
      "import numpy as np\n",
      "from mypy_extensions import mypyc_attr\n",
      "from.type_env import PythonType\n",
      "from.utils import *\n",
      "from copy import copy, deepcopy\n",
      "from collections import Counter\n",
      "from typing import NamedTuple, overload\n",
      "from datasets.arrow_dataset import Dataset\n",
      "from torch import Tensor\n",
      "from torch.utils.data import DataLoader, RandomSampler\n",
      "from transformers.data.data_collator import DataCollatorForSeq2Seq\n",
      "from.data import (\n",
      "    ChunkedDataset,\n",
      "    CtxArgs,\n",
      "    TokenizedSrcSet,\n",
      "    output_ids_as_types,\n",
      "    preds_to_accuracies,\n",
      ")\n",
      "@dataclass\n",
      "class DecodingArgs:\n",
      "   ...\n",
      "@dataclass\n",
      "class DatasetPredResult(Generic[T1]):\n",
      "   ...\n",
      "@dataclass\n",
      "class ModelWrapper:\n",
      "   ...\n",
      "\n",
      "# Used:\n",
      "# spot.utils\n",
      "DefaultWorkers:... = multiprocessing.cpu_count() // 2\n",
      "\n",
      "# Target:\n",
      "# spot.model\n",
      "@dataclass\n",
      "class DecodingArgs:\n",
      "    max_workers: <extra_id_0> = DefaultWorkers\n",
      "\n",
      "# Users:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import decode_tokens\n",
    "from spot.static_analysis import ProjectPath\n",
    "\n",
    "rollout = evalr.predictions[0]\n",
    "elems_to_show = [ProjectPath(\"spot.model\", \"DecodingArgs.max_workers\")]\n",
    "\n",
    "for path in elems_to_show:\n",
    "    print(path)\n",
    "    print(\"prediction:\", rollout.elem2preds[path])\n",
    "    print(\"input:\", decode_tokens(rollout.elem2inputs[path][\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[203, 7, 5916, 30, 203]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.utils import DefaultTokenizer\n",
    "\n",
    "DefaultTokenizer.encode(\"\\n# Target:\\n\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_on_projects: 1796it [18:50,  1.59it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_acc: 70.18% (count=1.1k)\n",
      "full_acc: 65.77% (count=1.1k)\n",
      "full_acc_by_common:\n",
      "   rare: 65.77% (count=1.1k)\n",
      "full_acc_by_cat:\n",
      "   FuncArg: 60.06% (count=641)\n",
      "   FuncReturn: 72.76% (count=246)\n",
      "   ClassAtribute: 74.88% (count=211)\n",
      "   GlobalVar: 66.67% (count=12)\n",
      "full_acc_by_pos:\n",
      "   range(0, 1): 64.26% (count=568)\n",
      "   range(1, 2): 63.04% (count=257)\n",
      "   range(2, 4): 71.78% (count=202)\n",
      "   range(4, 8): 71.23% (count=73)\n",
      "   range(8, 16): 60.00% (count=10)\n",
      "avg_label_size: 1.1739\n",
      "avg_pred_size: 1.1\n"
     ]
    }
   ],
   "source": [
    "evalr = await rctx.evaluate_on_projects(\n",
    "    [ex_project], pre_args, DecodingOrders.DoubleTraversal()\n",
    ")\n",
    "\n",
    "pretty_print_dict(evalr.accuracies(None, wrapper.common_type_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.function_decoding/DecodingOrders.caller2callee 4\n",
      "spot.function_decoding/DecodingOrders.random_order 2\n",
      "spot.function_decoding/RolloutCtx.project_rollout 8\n",
      "spot.function_decoding/RolloutCtx.model 1\n",
      "spot.function_decoding/RolloutPrediction.elem2inputs 1\n",
      "spot.function_decoding/RolloutPrediction.elem2preds 1\n",
      "spot.function_decoding/RolloutPrediction.assignments 1\n",
      "spot.function_decoding/construct_model_inputs 7\n",
      "spot.function_decoding/is_mask_annot 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    ProcessPoolExecutor,\n",
    "    ThreadPoolExecutor,\n",
    ")\n",
    "\n",
    "rctx = RolloutCtx(\n",
    "    model=wrapper,\n",
    ")\n",
    "\n",
    "pre_args = PreprocessArgs()\n",
    "\n",
    "with ProcessPoolExecutor(20) as cpu_executor, ThreadPoolExecutor(1) as model_executor:\n",
    "    result = await rctx.project_rollout(\n",
    "        ex_project,\n",
    "        pre_args,\n",
    "        decode_order=DecodingOrders.Callee2Caller(),\n",
    "        cpu_executor=cpu_executor,\n",
    "        model_executor=model_executor,\n",
    "        progress_cbk=lambda e, p: print(e.path, len(p)),\n",
    "    )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.utils import decode_tokens\n",
    "\n",
    "for elem, preds in result.elem2preds.items():\n",
    "    if \"function_decoding\" in elem.module:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(f\"{elem.path}: {[str(p) for p in preds]}\")\n",
    "        print(\"model inputs:\")\n",
    "        print(decode_tokens(result.elem2inputs[elem][\"input_ids\"][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
