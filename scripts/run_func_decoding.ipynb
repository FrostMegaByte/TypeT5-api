{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to cuda:1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# first, load the trained model\n",
    "import os\n",
    "import torch\n",
    "from typing import *\n",
    "\n",
    "from spot.model import ModelWrapper\n",
    "from spot.utils import get_model_dir, proj_root, get_data_dir\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "gpu_id = 1\n",
    "datadir = get_data_dir()\n",
    "modeldir = get_model_dir()\n",
    "\n",
    "model_name=\"model-v4--TrainingConfig(func_only=True, drop_env_types=False, left_margin=1536, preamble_size=768, right_margin=2048)\"\n",
    "wrapper = ModelWrapper.from_pretrained(\n",
    "    modeldir / f\"checkpoints/lit-saved/{model_name}\"\n",
    ")\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "wrapper.to(device)\n",
    "print(f\"Model loaded to {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.static_analysis import (\n",
    "    PythonProject,\n",
    "    PythonModule,\n",
    "    UsageAnalysis,\n",
    "    mask_types,\n",
    "    remove_comments,\n",
    ")\n",
    "from spot.utils import cst, read_file, SpecialNames\n",
    "\n",
    "# ex_code = read_file(\"src/spot/function_decoding.py\")\n",
    "# ex_module = mask_types(cst.parse_module(ex_code))\n",
    "# ex_project = PythonProject.from_modules([PythonModule.from_cst(ex_module, \"spot.function_decoding\")])\n",
    "\n",
    "src_set = {\n",
    "    \"function_decoding.py\",\n",
    "    \"data.py\",\n",
    "    \"type_env.py\",\n",
    "    \"function_dataset.py\",\n",
    "    \"tokenized_src.py\",\n",
    "    \"type_check.py\",\n",
    "    \"model.py\",\n",
    "    \"utils.py\",\n",
    "    \"static_analysis.py\",\n",
    "}\n",
    "\n",
    "def handle_msak(m: cst.Module):\n",
    "    new_code = remove_comments(m).code.replace(\"SPOT_TYPE_MASK\", \"Not_A_Mask\")\n",
    "    return cst.parse_module(new_code)\n",
    "    \n",
    "\n",
    "ex_project = PythonProject.from_root(\n",
    "    proj_root(),\n",
    "    src_transform=lambda m: handle_msak(m),\n",
    "    # file_filter=lambda f: \"dagger\" not in f.name and \"critic\" not in f.name,\n",
    "    # file_filter=lambda f: f.name in src_set,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate_on_projects: 100%|██████████| 898/898 [09:25<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_acc: 68.20% (count=1.1k)\n",
      "full_acc: 62.97% (count=1.1k)\n",
      "full_acc_by_common:\n",
      "   rare: 62.97% (count=1.1k)\n",
      "full_acc_by_cat:\n",
      "   FuncArg: 57.41% (count=641)\n",
      "   FuncReturn: 71.14% (count=246)\n",
      "   ClassAtribute: 71.09% (count=211)\n",
      "   GlobalVar: 50.00% (count=12)\n",
      "full_acc_by_pos:\n",
      "   range(0, 1): 60.56% (count=568)\n",
      "   range(1, 2): 63.42% (count=257)\n",
      "   range(2, 4): 69.31% (count=202)\n",
      "   range(4, 8): 67.12% (count=73)\n",
      "   range(8, 16): 30.00% (count=10)\n",
      "avg_label_size: 1.1739\n",
      "avg_pred_size: 1.1\n"
     ]
    }
   ],
   "source": [
    "from spot.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    ProcessPoolExecutor,\n",
    "    ThreadPoolExecutor,\n",
    ")\n",
    "from spot.model import DecodingArgs\n",
    "from spot.visualization import pretty_print_dict\n",
    "\n",
    "ctx_args = wrapper.args.ctx_args\n",
    "wrapper.args = DecodingArgs(\n",
    "    sampling_max_tokens=ctx_args.ctx_size,\n",
    "    ctx_args=ctx_args,\n",
    "    do_sample=False,\n",
    "    num_beams=16,\n",
    "    tokens_per_type=16,\n",
    "    length_penalty=0.2,\n",
    ")\n",
    "\n",
    "rctx = RolloutCtx(\n",
    "    model=wrapper,\n",
    ")\n",
    "\n",
    "pre_args = PreprocessArgs()\n",
    "\n",
    "evalr = await rctx.evaluate_on_projects(\n",
    "    [ex_project], pre_args, DecodingOrders.random_order, common_type_names=set()\n",
    ")\n",
    "\n",
    "pretty_print_dict(evalr.accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.function_decoding/DecodingOrders.caller2callee 4\n",
      "spot.function_decoding/DecodingOrders.random_order 2\n",
      "spot.function_decoding/RolloutCtx.project_rollout 8\n",
      "spot.function_decoding/RolloutCtx.model 1\n",
      "spot.function_decoding/RolloutPrediction.elem2inputs 1\n",
      "spot.function_decoding/RolloutPrediction.elem2preds 1\n",
      "spot.function_decoding/RolloutPrediction.assignments 1\n",
      "spot.function_decoding/construct_model_inputs 7\n",
      "spot.function_decoding/is_mask_annot 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    ProcessPoolExecutor,\n",
    "    ThreadPoolExecutor,\n",
    ")\n",
    "\n",
    "rctx = RolloutCtx(\n",
    "    model=wrapper,\n",
    ")\n",
    "\n",
    "pre_args = PreprocessArgs()\n",
    "\n",
    "with ProcessPoolExecutor(20) as cpu_executor, ThreadPoolExecutor(1) as model_executor:\n",
    "    result = await rctx.project_rollout(\n",
    "        ex_project,\n",
    "        pre_args,\n",
    "        decode_order=DecodingOrders.caller2callee,\n",
    "        cpu_executor=cpu_executor,\n",
    "        model_executor=model_executor,\n",
    "        progress_cbk=lambda e, p: print(e.path, len(p)),\n",
    "    )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.utils import decode_tokens\n",
    "\n",
    "for elem, preds in result.elem2preds.items():\n",
    "    if \"function_decoding\" in elem.module:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(f\"{elem.path}: {[str(p) for p in preds]}\")\n",
    "        print(\"model inputs:\")\n",
    "        print(decode_tokens(result.elem2inputs[elem][\"input_ids\"][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
