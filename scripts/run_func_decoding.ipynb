{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to cuda:1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# first, load the trained model\n",
    "import os\n",
    "import torch\n",
    "from typing import *\n",
    "\n",
    "from spot.model import ModelWrapper\n",
    "from spot.utils import get_model_dir, proj_root, get_data_dir\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "gpu_id = 1\n",
    "datadir = get_data_dir()\n",
    "modeldir = get_model_dir()\n",
    "\n",
    "model_name=\"model-v4--TrainingConfig(func_only=True, drop_env_types=False, left_margin=1536, preamble_size=768, right_margin=2048)\"\n",
    "wrapper = ModelWrapper.from_pretrained(\n",
    "    modeldir / f\"checkpoints/lit-saved/{model_name}\"\n",
    ")\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "wrapper.to(device)\n",
    "print(f\"Model loaded to {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.static_analysis import (\n",
    "    PythonProject,\n",
    "    PythonModule,\n",
    "    UsageAnalysis,\n",
    "    mask_types,\n",
    "    remove_comments,\n",
    ")\n",
    "from spot.utils import cst, read_file, SpecialNames\n",
    "\n",
    "# ex_code = read_file(\"src/spot/function_decoding.py\")\n",
    "# ex_module = mask_types(cst.parse_module(ex_code))\n",
    "# ex_project = PythonProject.from_modules([PythonModule.from_cst(ex_module, \"spot.function_decoding\")])\n",
    "\n",
    "ex_project = PythonProject.from_root(\n",
    "    proj_root(),\n",
    "    src_filter=lambda code: SpecialNames.TypeMask not in code,\n",
    "    src_transform=lambda m: mask_types(remove_comments(m)),\n",
    "    # file_filter=lambda f: \"dagger\" not in f.name and \"critic\" not in f.name,\n",
    "    file_filter=lambda f: f.name == \"function_decoding.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot.function_decoding/DecodingOrders.caller2callee 4\n",
      "spot.function_decoding/DecodingOrders.random_order 2\n",
      "spot.function_decoding/RolloutCtx.project_rollout 8\n",
      "spot.function_decoding/RolloutCtx.model 1\n",
      "spot.function_decoding/RolloutPrediction.elem2inputs 1\n",
      "spot.function_decoding/RolloutPrediction.elem2preds 1\n",
      "spot.function_decoding/RolloutPrediction.assignments 1\n",
      "spot.function_decoding/construct_model_inputs 7\n",
      "spot.function_decoding/is_mask_annot 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spot.function_decoding import (\n",
    "    RolloutCtx,\n",
    "    PreprocessArgs,\n",
    "    DecodingOrders,\n",
    "    ProcessPoolExecutor,\n",
    "    ThreadPoolExecutor,\n",
    ")\n",
    "\n",
    "rctx = RolloutCtx(\n",
    "    model=wrapper,\n",
    ")\n",
    "\n",
    "pre_args = PreprocessArgs()\n",
    "\n",
    "with ProcessPoolExecutor(20) as cpu_executor, ThreadPoolExecutor(1) as model_executor:\n",
    "    result = await rctx.project_rollout(\n",
    "        ex_project,\n",
    "        pre_args,\n",
    "        decode_order=DecodingOrders.caller2callee,\n",
    "        cpu_executor=cpu_executor,\n",
    "        model_executor=model_executor,\n",
    "        progress_cbk=lambda e, p: print(e.path, len(p)),\n",
    "    )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecodingOrders.caller2callee: ['UsageAnalysis', 'list[ProjectPath]', 'ProjectPath', 'None']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "class DecodingOrders:\n",
      "    @staticmethod\n",
      "    def caller2callee(analysis: <extra_id_0>) -> <extra_id_1>:\n",
      "        sorted = list[ProjectPath]()\n",
      "        visited = set[ProjectPath]()\n",
      "\n",
      "        def visit(p: <extra_id_2>) -> <extra_id_3>:\n",
      "            if p in visited or p not in analysis.path2elem:\n",
      "                return\n",
      "            visited.add(p)\n",
      "            for u in analysis.used2user.get(p, []):\n",
      "                visit(u.user)\n",
      "            sorted.append(p)\n",
      "\n",
      "        for m in reversed(list(analysis.project.all_elems())):\n",
      "            visit(m.path)\n",
      "        return sorted\n",
      "    \n",
      "\n",
      "# END\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "DecodingOrders.random_order: ['UsageAnalysis', 'list[ProjectPath]']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "class DecodingOrders:\n",
      "    @staticmethod\n",
      "    def random_order(analysis: <extra_id_0>) -> <extra_id_1>:\n",
      "        elems = [e.path for e in analysis.project.all_elems()]\n",
      "        random.shuffle(elems)\n",
      "        return elems\n",
      "    \n",
      "\n",
      "# END\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "RolloutCtx.project_rollout: ['PythonProject', 'PreprocessArgs', 'DecodingOrders', 'asyncio.AbstractEventLoop', 'asyncio.AbstractEventLoop', 'Callable[[Any, Any], None]', 'RolloutPrediction', 'UsageAnalysis']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments:...\n",
      "    elem2preds:...\n",
      "    elem2inputs:...\n",
      "\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a):...\n",
      "\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code,\n",
      "    left_m,\n",
      "    right_m,\n",
      "    preamble,\n",
      "    preamble_tkns,\n",
      "    ctx_args,\n",
      "):...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: <extra_id_0>,\n",
      "        pre_args: <extra_id_1>,\n",
      "        decode_order: <extra_id_2>,\n",
      "        cpu_executor: <extra_id_3>,\n",
      "        model_executor: <extra_id_4>,\n",
      "        progress_cbk: <extra_id_5> = lambda x, y: None,\n",
      "    ) -> <extra_id_6>:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis: <extra_id_7> = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "# END\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "RolloutCtx.model: ['ModelWrapper']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    model: <extra_id_0>\n",
      "\n",
      "# END\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "RolloutPrediction.elem2inputs: ['dict[ProjectPath, dict]']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments:...\n",
      "    elem2preds:...\n",
      "\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a):...\n",
      "\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code,\n",
      "    left_m,\n",
      "    right_m,\n",
      "    preamble,\n",
      "    preamble_tkns,\n",
      "    ctx_args,\n",
      "):...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    elem2inputs: <extra_id_0>\n",
      "\n",
      "# END\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: PythonProject,\n",
      "        pre_args: PreprocessArgs,\n",
      "        decode_order: DecodingOrders,\n",
      "        cpu_executor: asyncio.AbstractEventLoop,\n",
      "        model_executor: asyncio.AbstractEventLoop,\n",
      "        progress_cbk: Callable[[Any, Any], None] = lambda x, y: None,\n",
      "    ) -> RolloutPrediction:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis:... = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "RolloutPrediction.elem2preds: ['dict[ProjectPath, Sequence[PythonType]]']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments:...\n",
      "    elem2inputs: dict[ProjectPath, dict]\n",
      "\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a):...\n",
      "\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code,\n",
      "    left_m,\n",
      "    right_m,\n",
      "    preamble,\n",
      "    preamble_tkns,\n",
      "    ctx_args,\n",
      "):...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    elem2preds: <extra_id_0>\n",
      "\n",
      "# END\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: PythonProject,\n",
      "        pre_args: PreprocessArgs,\n",
      "        decode_order: DecodingOrders,\n",
      "        cpu_executor: asyncio.AbstractEventLoop,\n",
      "        model_executor: asyncio.AbstractEventLoop,\n",
      "        progress_cbk: Callable[[Any, Any], None] = lambda x, y: None,\n",
      "    ) -> RolloutPrediction:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis:... = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "RolloutPrediction.assignments: ['dict[ProjectPath, ElemSignature]']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    elem2preds: dict[ProjectPath, Sequence[PythonType]]\n",
      "    elem2inputs: dict[ProjectPath, dict]\n",
      "\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a):...\n",
      "\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code,\n",
      "    left_m,\n",
      "    right_m,\n",
      "    preamble,\n",
      "    preamble_tkns,\n",
      "    ctx_args,\n",
      "):...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments: <extra_id_0>\n",
      "\n",
      "# END\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: PythonProject,\n",
      "        pre_args: PreprocessArgs,\n",
      "        decode_order: DecodingOrders,\n",
      "        cpu_executor: asyncio.AbstractEventLoop,\n",
      "        model_executor: asyncio.AbstractEventLoop,\n",
      "        progress_cbk: Callable[[Any, Any], None] = lambda x, y: None,\n",
      "    ) -> RolloutPrediction:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis:... = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "construct_model_inputs: ['PythonElem', 'Optional[PythonFunction]', 'Optional[PythonFunction]', 'str', 'str', 'CtxArgs', 'List[SrcChunkInfo]']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments: dict[ProjectPath, ElemSignature]\n",
      "    elem2preds: dict[ProjectPath, Sequence[PythonType]]\n",
      "    elem2inputs: dict[ProjectPath, dict]\n",
      "\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a):...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code: <extra_id_0>,\n",
      "    left_m: <extra_id_1>,\n",
      "    right_m: <extra_id_2>,\n",
      "    preamble: <extra_id_3>,\n",
      "    preamble_tkns: <extra_id_4>,\n",
      "    ctx_args: <extra_id_5>,\n",
      ") -> <extra_id_6>:\n",
      "    main_code_string = \"# BEGIN\\n\" + main_code.code + \"# END\\n\"\n",
      "    code_segs = main_code_string.split(SpecialNames.TypeMask)\n",
      "    n_labels = len(code_segs) - 1\n",
      "\n",
      "    if n_labels == 0:\n",
      "        return []\n",
      "\n",
      "    left_tks = None\n",
      "    if left_m is not None:\n",
      "        left_tks = DefaultTokenizer.encode(left_m.code, add_special_tokens=False)\n",
      "    right_tks = None\n",
      "    if right_m is not None:\n",
      "        right_tks = DefaultTokenizer.encode(right_m.code, add_special_tokens=False)\n",
      "\n",
      "    annots, types = collect_user_annotations(main_code)\n",
      "    assert_eq(\n",
      "        len(annots), n_labels, extra_message=lambda: f\"main code:\\n{main_code_string}\"\n",
      "    )\n",
      "\n",
      "    src = tokenized_src_from_segs(\n",
      "        file=Path(\"[construct_model_inputs]\"),\n",
      "        repo=Path(\"[construct_model_inputs]\"),\n",
      "        preamble=preamble,\n",
      "        tokenized_preamble=preamble_tkns,\n",
      "        code_segs=code_segs,\n",
      "        types=types,\n",
      "        types_str=[SpecialNames.TypeMask] * n_labels,\n",
      "        annots_info=annots,\n",
      "        cst_code=main_code_string,\n",
      "        left_extra_tks=left_tks,\n",
      "        right_extra_tks=right_tks,\n",
      "    )\n",
      "    chunks, _ = src_to_chunks(src, (0, n_labels), ctx_args)\n",
      "    for i, chunk in enumerate(chunks):\n",
      "        chunks[i] = {\n",
      "            \"input_ids\": torch.tensor([chunk[\"input_ids\"]]),\n",
      "            \"labels\": torch.tensor([chunk[\"labels\"]]),\n",
      "            \"n_labels\": [chunk[\"n_labels\"]],\n",
      "        }\n",
      "    return chunks\n",
      "\n",
      "# END\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: PythonProject,\n",
      "        pre_args: PreprocessArgs,\n",
      "        decode_order: DecodingOrders,\n",
      "        cpu_executor: asyncio.AbstractEventLoop,\n",
      "        model_executor: asyncio.AbstractEventLoop,\n",
      "        progress_cbk: Callable[[Any, Any], None] = lambda x, y: None,\n",
      "    ) -> RolloutPrediction:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis:... = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "is_mask_annot: ['cst.Annotation', 'bool']\n",
      "model inputs:\n",
      "import asyncio\n",
      "import copy\n",
      "import random\n",
      "import torch\n",
      "from.type_env import AnnotInfo, collect_user_annotations\n",
      "from.model import ModelWrapper\n",
      "from.utils import *\n",
      "from.static_analysis import (\n",
      "    ModuleName,\n",
      "    ProjectPath,\n",
      "    PythonElem,\n",
      "    PythonFunction,\n",
      "    PythonProject,\n",
      "    PythonVariable,\n",
      "    UsageAnalysis,\n",
      "    VariableSingature,\n",
      ")\n",
      "from.data import CtxArgs, SrcChunkInfo, src_to_chunks\n",
      "from.function_dataset import (\n",
      "    ElemSignature,\n",
      "    ctx_modules_for_elem,\n",
      "    mk_preamble,\n",
      "    reformat_elems,\n",
      ")\n",
      "from.tokenized_src import (\n",
      "    PreprocessArgs,\n",
      "    TokenSeq,\n",
      "    TokenizedSrc,\n",
      "    tokenized_src_from_segs,\n",
      ")\n",
      "from.type_check import PythonType\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "   ...\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "   ...\n",
      "class DecodingOrders:\n",
      "   ...\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutPrediction:\n",
      "    assignments: dict[ProjectPath, ElemSignature]\n",
      "    elem2preds: dict[ProjectPath, Sequence[PythonType]]\n",
      "    elem2inputs: dict[ProjectPath, dict]\n",
      "\n",
      "# spot.function_decoding\n",
      "def construct_model_inputs(\n",
      "    main_code: PythonElem,\n",
      "    left_m: Optional[PythonFunction],\n",
      "    right_m: Optional[PythonFunction],\n",
      "    preamble: str,\n",
      "    preamble_tkns: str,\n",
      "    ctx_args: CtxArgs,\n",
      ") -> List[SrcChunkInfo]:...\n",
      "\n",
      "# BEGIN\n",
      "# spot.function_decoding\n",
      "def is_mask_annot(a: <extra_id_0>) -> <extra_id_1>:\n",
      "    match a.annotation:\n",
      "        case cst.Name(value=SpecialNames.TypeMask):\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "# END\n",
      "# spot.function_decoding\n",
      "@dataclass\n",
      "class RolloutCtx:\n",
      "    async def project_rollout(\n",
      "        self,\n",
      "        project: PythonProject,\n",
      "        pre_args: PreprocessArgs,\n",
      "        decode_order: DecodingOrders,\n",
      "        cpu_executor: asyncio.AbstractEventLoop,\n",
      "        model_executor: asyncio.AbstractEventLoop,\n",
      "        progress_cbk: Callable[[Any, Any], None] = lambda x, y: None,\n",
      "    ) -> RolloutPrediction:\n",
      "\n",
      "        if model_executor._max_workers > 1:\n",
      "            logging.warning(\"Model executor is not single threaded.\")\n",
      "\n",
      "        eloop = asyncio.get_event_loop()\n",
      "        analysis:... = await eloop.run_in_executor(\n",
      "            cpu_executor, UsageAnalysis, project\n",
      "        )\n",
      "        elements = [analysis.path2elem[p] for p in decode_order(analysis)]\n",
      "        assert_eq(len(elements), len(list(project.all_elems())))\n",
      "        preamble_cache = dict[ModuleName, tuple[str, TokenSeq]]()\n",
      "\n",
      "        assignments = dict[ProjectPath, ElemSignature]()\n",
      "        elem2preds = dict[ProjectPath, Sequence[PythonType]]()\n",
      "        elem2inputs = dict[ProjectPath, dict]()\n",
      "        mask_annot = cst.Annotation(cst.Name(SpecialNames.TypeMask))\n",
      "\n",
      "        for elem in elements:\n",
      "            assert (\n",
      "                elem.path not in assignments\n",
      "            ), f\"Element with path {elem.path} already assigned with signature {assignments[elem.path]}\"\n",
      "            cur_module = elem.path.module\n",
      "            if cur_module not in preamble_cache:\n",
      "                preamble_tuple = await eloop.run_in_executor(\n",
      "                    cpu_executor,\n",
      "                    mk_preamble,\n",
      "                    project.modules[cur_module].tree,\n",
      "                    pre_args,\n",
      "                )\n",
      "                preamble_cache[cur_module] = preamble_tuple\n",
      "            preamble, tokenized_preamble = preamble_cache[cur_module]\n",
      "\n",
      "            if isinstance(elem, PythonVariable):\n",
      "                sig = elem.get_signature()\n",
      "                elem_map = {\n",
      "                    elem.path: VariableSingature(sig.annot if sig.annot else mask_annot)\n",
      "                }\n",
      "            elif isinstance(elem, PythonFunction):\n",
      "                sig = elem.get_signature()\n",
      "                elem_sig = copy.deepcopy(sig)\n",
      "                for i, a in enumerate(elem_sig.annots):\n",
      "                    if a is None:\n",
      "                        elem_sig.annots[i] = mask_annot\n",
      "                elem_map = {elem.path: elem_sig}\n",
      "            else:\n",
      "                raise NotImplemented(f\"Unsupported element type {type(elem)}\")\n",
      "            main_lines = reformat_elems(\n",
      "                [elem],\n",
      "                analysis.path2class,\n",
      "                cast(dict[ProjectPath, ElemSignature], elem_map),\n",
      "                keep_body_types=True,\n",
      "            )\n",
      "\n",
      "            left_m, right_m = ctx_modules_for_elem(\n",
      "                elem, analysis, pre_args, assignments\n",
      "            )\n",
      "\n",
      "            model_inputs = await eloop.run_in_executor(\n",
      "                cpu_executor,\n",
      "                construct_model_inputs,\n",
      "                cst.Module(main_lines),\n",
      "                left_m,\n",
      "                right_m,\n",
      "                preamble,\n",
      "                tokenized_preamble,\n",
      "                self.model.args.ctx_args,\n",
      "            )\n",
      "\n",
      "            pred_types = list[PythonType]()\n",
      "            if model_inputs:\n",
      "                for chunk in model_inputs:\n",
      "                    preds, _ = await eloop.run_in_executor(\n",
      "                        model_executor, self.model.predict_on_batch, chunk\n",
      "                    )\n",
      "                    pred_types.extend(preds[0])\n",
      "                elem2inputs[elem.path] = model_inputs[0]\n",
      "\n",
      "                sig = copy.deepcopy(sig)\n",
      "                if isinstance(sig, VariableSingature):\n",
      "                    assert sig.annot is None or is_mask_annot(\n",
      "                        sig.annot\n",
      "                    ), f\"For {elem}, sig={sig}\"\n",
      "                    assert_eq(len(pred_types), 1)\n",
      "                    sig.annot = cst.Annotation(cst.parse_expression(str(pred_types[0])))\n",
      "                elif isinstance(elem, PythonFunction):\n",
      "                    for i, a in enumerate(sig.annots):\n",
      "                        if a is None or is_mask_annot(a):\n",
      "                            new_type = cst.parse_expression(str(pred_types[i]))\n",
      "                            sig.annots[i] = cst.Annotation(new_type)\n",
      "            assignments[elem.path] = sig\n",
      "            elem2preds[elem.path] = pred_types\n",
      "            progress_cbk(elem, pred_types)\n",
      "\n",
      "        return RolloutPrediction(assignments, elem2preds, elem2inputs)\n",
      "    \n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import decode_tokens\n",
    "\n",
    "for elem, preds in result.elem2preds.items():\n",
    "    if \"function_decoding\" in elem.module:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(f\"{elem.path}: {[str(p) for p in preds]}\")\n",
    "        print(\"model inputs:\")\n",
    "        print(decode_tokens(result.elem2inputs[elem][\"input_ids\"][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
