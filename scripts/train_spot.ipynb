{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from typing import *\n",
    "\n",
    "from spot.utils import proj_root, get_data_dir\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "datadir = get_data_dir()\n",
    "repos_dir = datadir / \"SPOT-data/repos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets:  src_datasets-all_labels-drop_comments\n"
     ]
    }
   ],
   "source": [
    "# experiment configurations\n",
    "\n",
    "import torch\n",
    "\n",
    "from spot.data import (\n",
    "    SrcDataset,\n",
    "    get_dataset_name,\n",
    "    load_src_datasets,\n",
    ")\n",
    "from spot.model import CtxArgs, DecodingArgs, ModelSPOT, ModelWrapper\n",
    "from copy import copy\n",
    "from spot.train import TrainingConfig, TypeCheckArgs\n",
    "\n",
    "config = TrainingConfig(quicktest=False, all_labels=True)\n",
    "train_R1: bool = True\n",
    "load_trained: bool = True\n",
    "gpu_id = 0\n",
    "\n",
    "project_name = \"test-SPOT\" if config.quicktest else \"SPOT\"\n",
    "train_ctx_args = config.train_ctx_args()\n",
    "tc_args = TypeCheckArgs(check_in_isolation=config.check_in_isolation)\n",
    "\n",
    "max_tokens_per_file = config.ctx_size\n",
    "dec_args = DecodingArgs(\n",
    "    sampling_max_tokens=8 * max_tokens_per_file,\n",
    "    ctx_args=config.dec_ctx_args(),\n",
    "    max_workers=20,\n",
    ")\n",
    "\n",
    "\n",
    "datasets_name = get_dataset_name(\n",
    "    drop_comments=config.drop_comments,\n",
    "    all_labels=config.all_labels,\n",
    ")\n",
    "\n",
    "r0_model_name = \"R0-model--\" + config.as_name()\n",
    "\n",
    "src_datasets = load_src_datasets(\n",
    "    datadir,\n",
    "    datasets_name,\n",
    "    data_reduction=config.data_reduction,\n",
    "    repos_root=datadir / \"SPOT-data/repos\",\n",
    "    quicktest=config.quicktest,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from spot.train import ModelTrainingArgs, train_spot_model, TypeCheckArgs\n",
    "import wandb\n",
    "\n",
    "train_args = ModelTrainingArgs(\n",
    "    train_ctx_args,\n",
    "    dec_args,\n",
    "    train_max_tokens=max_tokens_per_file,\n",
    "    eval_max_tokens=2 * max_tokens_per_file,\n",
    "    max_epochs=2,\n",
    "    tc_args=tc_args,\n",
    ")\n",
    "\n",
    "if not load_trained:\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        name=r0_model_name,\n",
    "        config=config.as_dict(),\n",
    "        dir=str(datadir),\n",
    "    )\n",
    "    r0_wrapper, r0_extra = train_spot_model(\n",
    "        src_datasets,\n",
    "        r0_model_name,\n",
    "        train_args=train_args,\n",
    "        record_batches=train_R1,\n",
    "        gpus=[gpu_id],\n",
    "        quicktest=config.quicktest,\n",
    "        use_small_model=config.use_small_model,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecodingArgs(ctx_args=CtxArgs(ctx_size=4096, left_margin=2048, right_margin=1024), sampling_max_tokens=32768, max_workers=20)\n"
     ]
    }
   ],
   "source": [
    "# load trained model\n",
    "from spot.utils import pickle_load, pickle_dump\n",
    "\n",
    "r0_wrapper = ModelWrapper.from_pretrained(\n",
    "    datadir / f\"checkpoints/lit-saved/{r0_model_name}\"\n",
    ")\n",
    "if train_R1:\n",
    "    r0_extra = pickle_load(datadir / f\"checkpoints/lit-saved/{r0_model_name}/extra.pkl\")\n",
    "    r1_src_datasets: dict[str, SrcDataset] = r0_extra[\"R1-src_datasets\"]\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "r0_wrapper.to(device)\n",
    "r0_wrapper.args.do_sample = False\n",
    "print(r0_wrapper.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_acc (ImNone): 75.42% (count=16.9k)\n",
      "full_acc (ImNone): 72.22% (count=16.9k)\n",
      "partial_acc: 73.96% (count=16.9k)\n",
      "ast_acc: 67.52% (count=21.3k)\n",
      "full_acc: 69.25% (count=16.9k)\n",
      "partial_acc_by_cat:\n",
      "   FuncArg: 68.85% (count=8.0k)\n",
      "   FuncReturn: 83.87% (count=5.7k)\n",
      "   ClassAtribute: 65.95% (count=2.7k)\n",
      "   GlobalVar: 86.54% (count=104)\n",
      "   LocalVar: 82.11% (count=531)\n",
      "partial_acc_by_pos:\n",
      "   range(0, 1): 74.83% (count=1.6k)\n",
      "   range(1, 2): 77.19% (count=1.6k)\n",
      "   range(2, 4): 75.92% (count=2.8k)\n",
      "   range(4, 8): 73.75% (count=4.6k)\n",
      "   range(8, 16): 72.23% (count=6.3k)\n",
      "avg_label_size: 1.2589\n",
      "avg_pred_size: 1.2327\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from spot.train import evaluate_model\n",
    "from spot.utils import PickleCache\n",
    "from spot.visualization import visualize_dicts, pretty_print_dict\n",
    "\n",
    "r0_cache = PickleCache(datadir / f\"checkpoints/lit-saved/{r0_model_name}/eval_cache\")\n",
    "r0_eval = evaluate_model(\n",
    "    r0_wrapper,\n",
    "    None,\n",
    "    src_datasets[\"test\"],\n",
    "    eval_cache=r0_cache,\n",
    "    tc_args=train_args.tc_args,\n",
    ")\n",
    "for d in [x[1].accuracies for x in r0_eval]:\n",
    "    pretty_print_dict(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa936a9391447c4a2515eb5f5c5d1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▅▅▅▅█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.decoder.final_layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.q.weight_epoch</td><td> ▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.DenseReluDense.wi.weight_epoch</td><td> ▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.k.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.DenseReluDense.wi.weight_epoch</td><td> ▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.q.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.DenseReluDense.wo.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.o.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.v.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.DenseReluDense.wi.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.k.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.o.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.q.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.v.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.DenseReluDense.wi.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.DenseReluDense.wo.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.layer_norm.weight_epoch</td><td>█▁</td></tr><tr><td>grad_2.0_norm/model.encoder.final_layer_norm.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm/model.shared.weight_epoch</td><td>▁█</td></tr><tr><td>grad_2.0_norm_total_epoch</td><td> ▁</td></tr><tr><td>trainer/global_step</td><td>▁▂▃▃▅▆▇▇█</td></tr><tr><td>valid/loss</td><td>██▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.k.weight_epoch</td><td>0.1291</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.o.weight_epoch</td><td>0.8254</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.q.weight_epoch</td><td>0.15374</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight_epoch</td><td>0.10869</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.SelfAttention.v.weight_epoch</td><td>1.17765</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.0.layer_norm.weight_epoch</td><td>0.47247</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.k.weight_epoch</td><td>0.70331</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.o.weight_epoch</td><td>1.57787</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.q.weight_epoch</td><td>0.71179</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.EncDecAttention.v.weight_epoch</td><td>2.05928</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.1.layer_norm.weight_epoch</td><td>0.46317</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.09358</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.DenseReluDense.wo.weight_epoch</td><td>1.05345</td></tr><tr><td>grad_2.0_norm/model.decoder.block.0.layer.2.layer_norm.weight_epoch</td><td>1.20196</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.k.weight_epoch</td><td>0.37319</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.o.weight_epoch</td><td>0.76905</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.q.weight_epoch</td><td>0.45435</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.SelfAttention.v.weight_epoch</td><td>1.27074</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.0.layer_norm.weight_epoch</td><td>1.99897</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.k.weight_epoch</td><td>0.76864</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.o.weight_epoch</td><td>1.74283</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.q.weight_epoch</td><td>0.83061</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.EncDecAttention.v.weight_epoch</td><td>1.79702</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.1.layer_norm.weight_epoch</td><td>1.0615</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.32885</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.DenseReluDense.wo.weight_epoch</td><td>1.04196</td></tr><tr><td>grad_2.0_norm/model.decoder.block.1.layer.2.layer_norm.weight_epoch</td><td>0.87856</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.k.weight_epoch</td><td>0.36741</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.o.weight_epoch</td><td>0.30557</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.q.weight_epoch</td><td>0.42096</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.SelfAttention.v.weight_epoch</td><td>0.41247</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.0.layer_norm.weight_epoch</td><td>0.23513</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.k.weight_epoch</td><td>0.45617</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.o.weight_epoch</td><td>0.40546</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.q.weight_epoch</td><td>0.55096</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.EncDecAttention.v.weight_epoch</td><td>0.41443</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.1.layer_norm.weight_epoch</td><td>0.27188</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.DenseReluDense.wi.weight_epoch</td><td>0.9663</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.49343</td></tr><tr><td>grad_2.0_norm/model.decoder.block.10.layer.2.layer_norm.weight_epoch</td><td>0.22946</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.k.weight_epoch</td><td>0.27587</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.o.weight_epoch</td><td>0.33186</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.q.weight_epoch</td><td>0.29234</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.SelfAttention.v.weight_epoch</td><td>0.4656</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.0.layer_norm.weight_epoch</td><td>0.49441</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.k.weight_epoch</td><td>0.3816</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.o.weight_epoch</td><td>0.36969</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.q.weight_epoch</td><td>0.54048</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.EncDecAttention.v.weight_epoch</td><td>0.36865</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.1.layer_norm.weight_epoch</td><td>1.1189</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.DenseReluDense.wi.weight_epoch</td><td>0.95491</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.53133</td></tr><tr><td>grad_2.0_norm/model.decoder.block.11.layer.2.layer_norm.weight_epoch</td><td>0.54624</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.k.weight_epoch</td><td>0.70121</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.o.weight_epoch</td><td>0.6911</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.q.weight_epoch</td><td>0.94529</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.SelfAttention.v.weight_epoch</td><td>0.93185</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.0.layer_norm.weight_epoch</td><td>1.96757</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.k.weight_epoch</td><td>0.60449</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.o.weight_epoch</td><td>1.38668</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.q.weight_epoch</td><td>0.62485</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.EncDecAttention.v.weight_epoch</td><td>1.49245</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.1.layer_norm.weight_epoch</td><td>0.38086</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.51103</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.DenseReluDense.wo.weight_epoch</td><td>1.37401</td></tr><tr><td>grad_2.0_norm/model.decoder.block.2.layer.2.layer_norm.weight_epoch</td><td>0.51684</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.k.weight_epoch</td><td>0.30571</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.o.weight_epoch</td><td>0.59364</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.q.weight_epoch</td><td>0.41197</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.SelfAttention.v.weight_epoch</td><td>0.86014</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.0.layer_norm.weight_epoch</td><td>0.34237</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.k.weight_epoch</td><td>0.50869</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.o.weight_epoch</td><td>0.93796</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.q.weight_epoch</td><td>0.56329</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.EncDecAttention.v.weight_epoch</td><td>1.14022</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.1.layer_norm.weight_epoch</td><td>0.35197</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.43353</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.98682</td></tr><tr><td>grad_2.0_norm/model.decoder.block.3.layer.2.layer_norm.weight_epoch</td><td>0.34605</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.k.weight_epoch</td><td>0.48346</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.o.weight_epoch</td><td>0.5358</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.q.weight_epoch</td><td>0.55411</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.SelfAttention.v.weight_epoch</td><td>0.76278</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.0.layer_norm.weight_epoch</td><td>0.71563</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.k.weight_epoch</td><td>0.51407</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.o.weight_epoch</td><td>0.66788</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.q.weight_epoch</td><td>0.58427</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.EncDecAttention.v.weight_epoch</td><td>0.99455</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.1.layer_norm.weight_epoch</td><td>0.38636</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.34373</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.88195</td></tr><tr><td>grad_2.0_norm/model.decoder.block.4.layer.2.layer_norm.weight_epoch</td><td>0.25354</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.k.weight_epoch</td><td>0.44236</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.o.weight_epoch</td><td>0.58753</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.q.weight_epoch</td><td>0.51248</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.SelfAttention.v.weight_epoch</td><td>0.84055</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.0.layer_norm.weight_epoch</td><td>0.70632</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.k.weight_epoch</td><td>0.53812</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.o.weight_epoch</td><td>0.66942</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.q.weight_epoch</td><td>0.62165</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.EncDecAttention.v.weight_epoch</td><td>0.97052</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.1.layer_norm.weight_epoch</td><td>0.38982</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.33924</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.95495</td></tr><tr><td>grad_2.0_norm/model.decoder.block.5.layer.2.layer_norm.weight_epoch</td><td>0.23238</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.k.weight_epoch</td><td>0.96206</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.o.weight_epoch</td><td>0.55731</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.q.weight_epoch</td><td>1.00245</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.SelfAttention.v.weight_epoch</td><td>0.80432</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.0.layer_norm.weight_epoch</td><td>1.37095</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.k.weight_epoch</td><td>0.54258</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.o.weight_epoch</td><td>0.56533</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.q.weight_epoch</td><td>0.59508</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.EncDecAttention.v.weight_epoch</td><td>0.73855</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.1.layer_norm.weight_epoch</td><td>0.28357</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.3673</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.8723</td></tr><tr><td>grad_2.0_norm/model.decoder.block.6.layer.2.layer_norm.weight_epoch</td><td>0.18011</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.k.weight_epoch</td><td>0.62348</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.o.weight_epoch</td><td>0.44595</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.q.weight_epoch</td><td>0.68388</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.SelfAttention.v.weight_epoch</td><td>0.70675</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.0.layer_norm.weight_epoch</td><td>0.41072</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.k.weight_epoch</td><td>0.60398</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.o.weight_epoch</td><td>0.51412</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.q.weight_epoch</td><td>0.7184</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.EncDecAttention.v.weight_epoch</td><td>0.66396</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.1.layer_norm.weight_epoch</td><td>0.42341</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.23493</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.85376</td></tr><tr><td>grad_2.0_norm/model.decoder.block.7.layer.2.layer_norm.weight_epoch</td><td>0.14363</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.k.weight_epoch</td><td>0.66375</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.o.weight_epoch</td><td>0.40154</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.q.weight_epoch</td><td>0.71235</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.SelfAttention.v.weight_epoch</td><td>0.60844</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.0.layer_norm.weight_epoch</td><td>0.7393</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.k.weight_epoch</td><td>0.48499</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.o.weight_epoch</td><td>0.45097</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.q.weight_epoch</td><td>0.54689</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.EncDecAttention.v.weight_epoch</td><td>0.50095</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.1.layer_norm.weight_epoch</td><td>0.26601</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.DenseReluDense.wi.weight_epoch</td><td>1.11057</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.65741</td></tr><tr><td>grad_2.0_norm/model.decoder.block.8.layer.2.layer_norm.weight_epoch</td><td>0.10296</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.k.weight_epoch</td><td>0.34297</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.o.weight_epoch</td><td>0.35939</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.q.weight_epoch</td><td>0.39406</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.SelfAttention.v.weight_epoch</td><td>0.46989</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.0.layer_norm.weight_epoch</td><td>0.26794</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.k.weight_epoch</td><td>0.40804</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.o.weight_epoch</td><td>0.45663</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.q.weight_epoch</td><td>0.48089</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.EncDecAttention.v.weight_epoch</td><td>0.43702</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.1.layer_norm.weight_epoch</td><td>0.22482</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.DenseReluDense.wi.weight_epoch</td><td>0.91237</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.DenseReluDense.wo.weight_epoch</td><td>0.56241</td></tr><tr><td>grad_2.0_norm/model.decoder.block.9.layer.2.layer_norm.weight_epoch</td><td>0.1008</td></tr><tr><td>grad_2.0_norm/model.decoder.final_layer_norm.weight_epoch</td><td>0.0395</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.k.weight_epoch</td><td>0.61898</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.o.weight_epoch</td><td>2.73863</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.q.weight_epoch</td><td>0.85465</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight_epoch</td><td>0.22326</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.SelfAttention.v.weight_epoch</td><td>2.55423</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.0.layer_norm.weight_epoch</td><td>1.2021</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.DenseReluDense.wi.weight_epoch</td><td>3.34481</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.DenseReluDense.wo.weight_epoch</td><td>2.62009</td></tr><tr><td>grad_2.0_norm/model.encoder.block.0.layer.1.layer_norm.weight_epoch</td><td>2.81661</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.k.weight_epoch</td><td>0.79915</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.o.weight_epoch</td><td>1.87347</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.q.weight_epoch</td><td>0.85543</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.SelfAttention.v.weight_epoch</td><td>2.34657</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.0.layer_norm.weight_epoch</td><td>7.01143</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.DenseReluDense.wi.weight_epoch</td><td>2.69544</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.30265</td></tr><tr><td>grad_2.0_norm/model.encoder.block.1.layer.1.layer_norm.weight_epoch</td><td>1.08167</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.k.weight_epoch</td><td>0.70693</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.o.weight_epoch</td><td>0.98145</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.q.weight_epoch</td><td>0.75452</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.SelfAttention.v.weight_epoch</td><td>1.04466</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.0.layer_norm.weight_epoch</td><td>0.74855</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.DenseReluDense.wi.weight_epoch</td><td>1.55705</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.07678</td></tr><tr><td>grad_2.0_norm/model.encoder.block.10.layer.1.layer_norm.weight_epoch</td><td>0.15436</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.k.weight_epoch</td><td>0.75466</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.o.weight_epoch</td><td>0.94615</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.q.weight_epoch</td><td>0.7399</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.SelfAttention.v.weight_epoch</td><td>0.99365</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.0.layer_norm.weight_epoch</td><td>1.06646</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.DenseReluDense.wi.weight_epoch</td><td>1.55634</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.13942</td></tr><tr><td>grad_2.0_norm/model.encoder.block.11.layer.1.layer_norm.weight_epoch</td><td>0.17786</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.k.weight_epoch</td><td>1.24212</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.o.weight_epoch</td><td>1.62937</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.q.weight_epoch</td><td>1.71214</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.SelfAttention.v.weight_epoch</td><td>2.76237</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.0.layer_norm.weight_epoch</td><td>15.3213</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.DenseReluDense.wi.weight_epoch</td><td>3.88956</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.52771</td></tr><tr><td>grad_2.0_norm/model.encoder.block.2.layer.1.layer_norm.weight_epoch</td><td>1.53672</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.k.weight_epoch</td><td>1.00119</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.o.weight_epoch</td><td>1.65385</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.q.weight_epoch</td><td>1.14469</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.SelfAttention.v.weight_epoch</td><td>2.37528</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.0.layer_norm.weight_epoch</td><td>12.58946</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.DenseReluDense.wi.weight_epoch</td><td>3.36543</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.70565</td></tr><tr><td>grad_2.0_norm/model.encoder.block.3.layer.1.layer_norm.weight_epoch</td><td>1.09421</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.k.weight_epoch</td><td>1.01575</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.o.weight_epoch</td><td>1.61361</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.q.weight_epoch</td><td>1.08445</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.SelfAttention.v.weight_epoch</td><td>2.09977</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.0.layer_norm.weight_epoch</td><td>7.30461</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.DenseReluDense.wi.weight_epoch</td><td>5.65604</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.68945</td></tr><tr><td>grad_2.0_norm/model.encoder.block.4.layer.1.layer_norm.weight_epoch</td><td>0.95071</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.k.weight_epoch</td><td>0.84958</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.o.weight_epoch</td><td>1.40409</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.q.weight_epoch</td><td>0.83181</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.SelfAttention.v.weight_epoch</td><td>1.67237</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.0.layer_norm.weight_epoch</td><td>2.49232</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.DenseReluDense.wi.weight_epoch</td><td>2.42081</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.39333</td></tr><tr><td>grad_2.0_norm/model.encoder.block.5.layer.1.layer_norm.weight_epoch</td><td>0.38796</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.k.weight_epoch</td><td>0.87575</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.o.weight_epoch</td><td>1.28087</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.q.weight_epoch</td><td>0.96785</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.SelfAttention.v.weight_epoch</td><td>1.50564</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.0.layer_norm.weight_epoch</td><td>1.71745</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.DenseReluDense.wi.weight_epoch</td><td>2.31755</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.40221</td></tr><tr><td>grad_2.0_norm/model.encoder.block.6.layer.1.layer_norm.weight_epoch</td><td>0.38505</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.k.weight_epoch</td><td>1.02157</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.o.weight_epoch</td><td>1.21525</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.q.weight_epoch</td><td>1.07337</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.SelfAttention.v.weight_epoch</td><td>1.39674</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.0.layer_norm.weight_epoch</td><td>0.8322</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.DenseReluDense.wi.weight_epoch</td><td>2.20162</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.21921</td></tr><tr><td>grad_2.0_norm/model.encoder.block.7.layer.1.layer_norm.weight_epoch</td><td>0.30583</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.k.weight_epoch</td><td>0.99592</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.o.weight_epoch</td><td>1.14964</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.q.weight_epoch</td><td>1.01596</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.SelfAttention.v.weight_epoch</td><td>1.22053</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.0.layer_norm.weight_epoch</td><td>1.33877</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.DenseReluDense.wi.weight_epoch</td><td>2.19121</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.19997</td></tr><tr><td>grad_2.0_norm/model.encoder.block.8.layer.1.layer_norm.weight_epoch</td><td>0.28115</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.k.weight_epoch</td><td>0.95362</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.o.weight_epoch</td><td>0.96527</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.q.weight_epoch</td><td>1.00581</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.SelfAttention.v.weight_epoch</td><td>1.08325</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.0.layer_norm.weight_epoch</td><td>1.00099</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.DenseReluDense.wi.weight_epoch</td><td>1.65544</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.DenseReluDense.wo.weight_epoch</td><td>1.0259</td></tr><tr><td>grad_2.0_norm/model.encoder.block.9.layer.1.layer_norm.weight_epoch</td><td>0.21389</td></tr><tr><td>grad_2.0_norm/model.encoder.final_layer_norm.weight_epoch</td><td>1.27774</td></tr><tr><td>grad_2.0_norm/model.shared.weight_epoch</td><td>1.47505</td></tr><tr><td>grad_2.0_norm_total_epoch</td><td>30.49054</td></tr><tr><td>trainer/global_step</td><td>6</td></tr><tr><td>valid/loss</td><td>2.3563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">R0-model--quicktest=True-all_labels=True</strong>: <a href=\"https://wandb.ai/mrvplusone/test-SPOT/runs/1g9yago6\" target=\"_blank\">https://wandb.ai/mrvplusone/test-SPOT/runs/1g9yago6</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/mnt/data0/jiayi/wandb/run-20220619_135919-1g9yago6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# close wandb\n",
    "from spot.utils import pretty_show_dict\n",
    "from spot.visualization import string_to_html\n",
    "import wandb\n",
    "\n",
    "\n",
    "def wandb_string(s: str):\n",
    "    return wandb.Html(string_to_html(s))\n",
    "\n",
    "\n",
    "if not load_trained:\n",
    "    for i, e in enumerate(r0_eval):\n",
    "        wandb.log({f\"test/R{i}\": wandb_string(pretty_show_dict(e[1].accuracies))})\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting: 100%|██████████| 164/164 [00:01<00:00, 132.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# export the code with inlined predictions as HTML\n",
    "\n",
    "from spot.visualization import export_preds_on_code, display_persist, proj_root\n",
    "\n",
    "eval_to_viz = r0_eval[0][1]\n",
    "sub_ids = range(0, len(eval_to_viz.chunks), 10)\n",
    "export_preds_on_code(\n",
    "    eval_to_viz.chunks[sub_ids],\n",
    "    [eval_to_viz.predictions[i] for i in sub_ids],\n",
    "    {},\n",
    "    export_to=proj_root() / \"R0_predictions\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: Training Critic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict:   9%|▉         | 182/2002 [01:37<16:11,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating R1 dataset: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:14<00:00, 63.36it/s] \n",
      "verify_labels: 100%|██████████| 1637/1637 [00:00<00:00, 11356.96it/s]\n",
      "chunk_srcs_per_file: 100%|██████████| 1087/1087 [00:17<00:00, 61.75it/s]\n",
      "verify_labels: 100%|██████████| 2002/2002 [00:00<00:00, 11629.19it/s]\n",
      "chunk_srcs_per_file: 100%|██████████| 16281/16281 [04:16<00:00, 63.36it/s] \n",
      "verify_labels: 100%|██████████| 29269/29269 [00:01<00:00, 16372.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_check_success_ratio: 1\n",
      "feedbacks_per_file:\n",
      "   mean: 0\n",
      "   median: 0\n",
      "   min: 0\n",
      "   max: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90005a41bc194682888084a8e70bcd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feedbacks_to_tokenized_src:   0%|          | 0/12225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating R1 dataset: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 2002/2002 [08:32<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_check_success_ratio: 1\n",
      "feedbacks_per_file:\n",
      "   mean: 0\n",
      "   median: 0\n",
      "   min: 0\n",
      "   max: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b3a6eb16a74734bb0ac10c68007280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feedbacks_to_tokenized_src:   0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating R1 dataset: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 1637/1637 [06:28<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_check_success_ratio: 1\n",
      "feedbacks_per_file:\n",
      "   mean: 0\n",
      "   median: 0\n",
      "   min: 0\n",
      "   max: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd93d26a7584785ae4f5299bf8cf735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feedbacks_to_tokenized_src:   0%|          | 0/933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inline_predictions: 100%|██████████| 12225/12225 [08:07<00:00, 25.09it/s] \n",
      "inline_predictions: 100%|██████████| 1087/1087 [00:39<00:00, 27.58it/s]\n",
      "inline_predictions: 100%|██████████| 933/933 [01:12<00:00, 12.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3kdtaypx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3kdtaypx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data0/jiayi/wandb/run-20220628_153602-1iic0pki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mrvplusone/SPOT/runs/1iic0pki\" target=\"_blank\">critic-model--no_feedback-all_labels=True</a></strong> to <a href=\"https://wandb.ai/mrvplusone/SPOT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk_srcs_per_file: 100%|██████████| 1087/1087 [00:12<00:00, 84.07it/s]\n",
      "verify_labels: 100%|██████████| 1465/1465 [00:00<00:00, 11335.04it/s]\n",
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:10<00:00, 93.02it/s] \n",
      "verify_labels: 100%|██████████| 1165/1165 [00:00<00:00, 10628.82it/s]\n",
      "chunk_srcs_per_file: 100%|██████████| 12225/12225 [02:19<00:00, 87.54it/s] \n",
      "verify_labels: 100%|██████████| 15438/15438 [00:01<00:00, 11623.82it/s]\n",
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:347: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1ad3ee86ed4d2492f7dcb915efd443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        valid/F1            0.33512205387205385\n",
      "     valid/accuracy         0.3752533491522072\n",
      "       valid/loss           0.7158970236778259\n",
      "     valid/pos_rate         0.20045478641986847\n",
      "     valid/precision        0.7854500616522812\n",
      "      valid/recall          0.21300073563833344\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CriticModel | 109 M \n",
      "--------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "219.216   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e709b1b1f014f9d9c205bbb593cac5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4728844202b8485eab6762c357072763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143b9402490849aabd9fbdfeb3a4fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991c6173d97e44f8834194c51eab44e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa5c2471fea43a6b53c4d1c478dd02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c892a2a12d254ba3bc21545977a6e9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374187d122904326a5c91a81ead25de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce56dd6bdd145c289af4bf0e63a5b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cfc570d7a343b69619069b5f72345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9139a6d12b3148bdb0269f9d981b9b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b9d51d76d544cf833c8ba7c396bf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test/F1             0.832843137254902\n",
      "      test/accuracy         0.7585840707964602\n",
      "        test/loss           0.5557802319526672\n",
      "      test/pos_rate         0.7882006168365479\n",
      "     test/precision         0.7630239520958084\n",
      "       test/recall           0.916726618705036\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Pushover: (Failed: Training Critic.) 'ZMQDisplayPublisher' object has no attribute '_orig_publish'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ZMQDisplayPublisher' object has no attribute '_orig_publish'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=46'>47</a>\u001b[0m critic, critic_extra \u001b[39m=\u001b[39m train_critic_model(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=47'>48</a>\u001b[0m     critic_src_datasets,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=48'>49</a>\u001b[0m     critic_train_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=53'>54</a>\u001b[0m     use_small_model\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39muse_small_model,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=54'>55</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=55'>56</a>\u001b[0m \u001b[39m# critic.save_pretrained(\"CriticSaved\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/train_spot.ipynb#ch0000006vscode-remote?line=56'>57</a>\u001b[0m wandb\u001b[39m.\u001b[39;49mfinish()\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:3324\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   3314\u001b[0m \u001b[39m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \n\u001b[1;32m   3316\u001b[0m \u001b[39mThis is used when creating multiple runs in the same process.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3321\u001b[0m \u001b[39m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   3322\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39mrun:\n\u001b[0;32m-> 3324\u001b[0m     wandb\u001b[39m.\u001b[39;49mrun\u001b[39m.\u001b[39;49mfinish(exit_code\u001b[39m=\u001b[39;49mexit_code, quiet\u001b[39m=\u001b[39;49mquiet)\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:256\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         wandb\u001b[39m.\u001b[39mtermwarn(message, repeat\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    254\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mDummy()\n\u001b[0;32m--> 256\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:222\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    221\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_attaching \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1678\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[39m@_run_decorator\u001b[39m\u001b[39m.\u001b[39m_noop\n\u001b[1;32m   1667\u001b[0m \u001b[39m@_run_decorator\u001b[39m\u001b[39m.\u001b[39m_attach\n\u001b[1;32m   1668\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfinish\u001b[39m(\u001b[39mself\u001b[39m, exit_code: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, quiet: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1669\u001b[0m     \u001b[39m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \n\u001b[1;32m   1671\u001b[0m \u001b[39m    This is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[39m        quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1678\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finish(exit_code, quiet)\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1689\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown_hooks:\n\u001b[1;32m   1688\u001b[0m     \u001b[39mif\u001b[39;00m hook\u001b[39m.\u001b[39mstage \u001b[39m==\u001b[39m TeardownStage\u001b[39m.\u001b[39mEARLY:\n\u001b[0;32m-> 1689\u001b[0m         hook\u001b[39m.\u001b[39;49mcall()\n\u001b[1;32m   1691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atexit_cleanup(exit_code\u001b[39m=\u001b[39mexit_code)\n\u001b[1;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl\u001b[39m.\u001b[39m_global_run_stack) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/SPOT/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:368\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_pause_backend\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m hook\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m:\n\u001b[1;32m    367\u001b[0m         ipython\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39munregister(\u001b[39m\"\u001b[39m\u001b[39mpost_run_cell\u001b[39m\u001b[39m\"\u001b[39m, hook)\n\u001b[0;32m--> 368\u001b[0m ipython\u001b[39m.\u001b[39mdisplay_pub\u001b[39m.\u001b[39mpublish \u001b[39m=\u001b[39m ipython\u001b[39m.\u001b[39;49mdisplay_pub\u001b[39m.\u001b[39;49m_orig_publish\n\u001b[1;32m    369\u001b[0m \u001b[39mdel\u001b[39;00m ipython\u001b[39m.\u001b[39mdisplay_pub\u001b[39m.\u001b[39m_orig_publish\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ZMQDisplayPublisher' object has no attribute '_orig_publish'"
     ]
    }
   ],
   "source": [
    "# train the critic\n",
    "from spot.critic import CriticModel, ModelSPOT, train_critic_model, CriticTrainArgs\n",
    "from spot.utils import pickle_load, run_long_task, PickleCache\n",
    "from spot.train import R1_srcs_from_extra\n",
    "import wandb\n",
    "\n",
    "critic_no_feedback = True\n",
    "\n",
    "if train_R1:\n",
    "    with run_long_task(\"Training Critic\", notify=not load_trained):\n",
    "        critic_train_args = CriticTrainArgs(\n",
    "            ctx_args=train_ctx_args,\n",
    "            train_max_tokens=max_tokens_per_file,\n",
    "            eval_max_tokens=2 * max_tokens_per_file,\n",
    "            max_epochs=1,\n",
    "        )\n",
    "        feedback_tag = \"no_feedback-\" if critic_no_feedback else \"\"\n",
    "        critic_name = \"critic-model--\" + feedback_tag + config.as_name()\n",
    "\n",
    "        critic_tc_args = tc_args._replace(no_feedback=critic_no_feedback)\n",
    "        critic_cache = PickleCache(\n",
    "            datadir / f\"checkpoints/lit-saved/CriticData-{critic_name}\"\n",
    "        )\n",
    "        # critic_cache.remove(\"src_datasets\")\n",
    "        critic_src_datasets: dict[str, SrcDataset] = critic_cache.cached(\n",
    "            \"src_datasets\",\n",
    "            lambda: {\n",
    "                k: v.inline_predictions(as_comment=False)\n",
    "                for k, v in R1_srcs_from_extra(\n",
    "                    r0_wrapper,\n",
    "                    src_datasets,\n",
    "                    extra=pickle_load(\n",
    "                        datadir / f\"checkpoints/lit-saved/{r0_model_name}/extra.pkl\"\n",
    "                    ),\n",
    "                    tc_args=critic_tc_args,\n",
    "                ).items()\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if not load_trained:\n",
    "            wandb.init(\n",
    "                project=project_name,\n",
    "                name=critic_name,\n",
    "                config=config.as_dict(),\n",
    "                dir=str(datadir),\n",
    "            )\n",
    "            critic, critic_extra = train_critic_model(\n",
    "                critic_src_datasets,\n",
    "                critic_train_args,\n",
    "                critic_name,\n",
    "                gpus=[gpu_id],\n",
    "                quicktest=config.quicktest,\n",
    "                use_early_stop=False,\n",
    "                use_small_model=config.use_small_model,\n",
    "            )\n",
    "            # critic.save_pretrained(\"CriticSaved\")\n",
    "            wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic loaded.\n"
     ]
    }
   ],
   "source": [
    "# load trained critic\n",
    "from spot.utils import pickle_load, pickle_dump\n",
    "from spot.critic import CriticModel\n",
    "\n",
    "critic = CriticModel.load(datadir / f\"checkpoints/lit-saved/{critic_name}\")\n",
    "if train_R1 and (\"r1_src_datasets\" not in globals()):\n",
    "    r0_extra = pickle_load(datadir / f\"checkpoints/lit-saved/{r0_model_name}/extra.pkl\")\n",
    "    r1_src_datasets: dict[str, SrcDataset] = r0_extra[\"R1-src_datasets\"]\n",
    "\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "critic.to(device)\n",
    "print(\"Critic loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:10<00:00, 92.38it/s] \n",
      "verify_labels: 100%|██████████| 1165/1165 [00:00<00:00, 10572.36it/s]\n",
      "predict: 100%|██████████| 1165/1165 [02:11<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.75858\n",
      "F1: 0.83284\n",
      "precision: 0.76302\n",
      "recall: 0.91673\n",
      "pos_rate: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# show critic performance\n",
    "\n",
    "from spot.visualization import visualize_preds_on_code, pretty_print_dict\n",
    "\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "critic.to(device)\n",
    "r1_testset = critic_src_datasets[\"test\"]\n",
    "critic_eval = critic.eval_on_src_dataset(\n",
    "    r1_testset, train_ctx_args, dec_args.sampling_max_tokens\n",
    ")\n",
    "nicer_preds = [[f\"{x:.1%}\" for x in xs] for xs in critic_eval[1]]\n",
    "pretty_print_dict(critic_eval[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65605\n",
      "F1: 0.7923\n",
      "precision: 0.65605\n",
      "recall: 1\n",
      "pos_rate: 1\n",
      "accuracy: 0.49876\n",
      "F1: 0.56807\n",
      "precision: 0.65345\n",
      "recall: 0.50243\n",
      "pos_rate: 0.50442\n"
     ]
    }
   ],
   "source": [
    "# The performance achieved by always predicting true or random values\n",
    "\n",
    "from spot.utils import not_none, pretty_print_dict\n",
    "from spot.type_check import normalize_type\n",
    "from spot.critic import CriticModel\n",
    "import random\n",
    "\n",
    "\n",
    "def dummy_performance(dataset: SrcDataset, pred_f):\n",
    "    targets = list[bool]()\n",
    "    for s in dataset.srcs_with_labels():\n",
    "        for p, t in zip(not_none(s.prev_types).values(), s.types):\n",
    "            targets.append(normalize_type(t) == normalize_type(p))\n",
    "\n",
    "    preds = [pred_f() for _ in range(len(targets))]\n",
    "    return CriticModel.compute_metrics(preds, targets)\n",
    "\n",
    "\n",
    "pretty_print_dict(dummy_performance(r1_testset, lambda: True))\n",
    "pretty_print_dict(dummy_performance(r1_testset, lambda: random.choice([True, False])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:14<00:00, 65.79it/s] \n",
      "verify_labels: 100%|██████████| 1656/1656 [00:00<00:00, 17364.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4945652173913043"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spot.utils import DefaultTokenizer, decode_tokens, np\n",
    "\n",
    "def chunk_has_fdbk(tks):\n",
    "    return \"/* error:\" in decode_tokens(tks)\n",
    "\n",
    "\n",
    "test_chunks = r1_src_datasets[\"test\"].to_chunks(DefaultTokenizer, dec_args.ctx_args)\n",
    "fraction_chunks_with_fdbk = np.mean([chunk_has_fdbk(tks) for tks in test_chunks.data[\"input_ids\"]])\n",
    "print(\"Fraction of chunks with feedback:\", fraction_chunks_with_fdbk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "error_code=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "name-defined",
          "arg-type",
          "attr-defined",
          "return-value",
          "assignment",
          "misc",
          "override",
          "index",
          "operator",
          "union-attr",
          "dict-item",
          "call-overload",
          "has-type",
          "call-arg",
          "var-annotated",
          "return",
          "type-var",
          "list-item",
          "type-arg",
          "literal-required",
          "func-returns-value",
          "str-bytes-safe",
          "exit-return",
          "typeddict-item"
         ],
         "xaxis": "x",
         "y": [
          784,
          372,
          352,
          195,
          101,
          61,
          41,
          39,
          35,
          31,
          30,
          17,
          16,
          15,
          8,
          8,
          7,
          6,
          4,
          4,
          3,
          1,
          1,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Error code frequencies"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "error_code"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"18da514e-9391-4fdf-88a1-2a3b7777358c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"18da514e-9391-4fdf-88a1-2a3b7777358c\")) {                    Plotly.newPlot(                        \"18da514e-9391-4fdf-88a1-2a3b7777358c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"error_code=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"name-defined\",\"arg-type\",\"attr-defined\",\"return-value\",\"assignment\",\"misc\",\"override\",\"index\",\"operator\",\"union-attr\",\"dict-item\",\"call-overload\",\"has-type\",\"call-arg\",\"var-annotated\",\"return\",\"type-var\",\"list-item\",\"type-arg\",\"literal-required\",\"func-returns-value\",\"str-bytes-safe\",\"exit-return\",\"typeddict-item\"],\"xaxis\":\"x\",\"y\":[784,372,352,195,101,61,41,39,35,31,30,17,16,15,8,8,7,6,4,4,3,1,1,1],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"error_code\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Error code frequencies\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('18da514e-9391-4fdf-88a1-2a3b7777358c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedbacks_per_file:\n",
      "   mean: 2.2851\n",
      "   median: 0\n",
      "   min: 0\n",
      "   max: 291\n",
      "type_check_success_ratio: 1\n",
      "total_feedbacks: 2132\n",
      "feedbacks_per_label: 0.12578\n",
      "fraction_files_with_feedbacks: 0.29582\n",
      "top_feedbacks:\n",
      "   name-defined: 784\n",
      "   arg-type: 372\n",
      "   attr-defined: 352\n",
      "   return-value: 195\n",
      "   assignment: 101\n",
      "   misc: 61\n",
      "   override: 41\n",
      "   index: 39\n",
      "   operator: 35\n",
      "   union-attr: 31\n"
     ]
    }
   ],
   "source": [
    "# checking mypy feedbacks\n",
    "from spot.visualization import show_feedback_stats\n",
    "\n",
    "if train_R1:\n",
    "    error_groups = show_feedback_stats(r1_src_datasets[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b3907c11f14d648adbcfa69622f48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=194), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize feedback samples\n",
    "\n",
    "from spot.utils import seq_flatten, add_line_numbers\n",
    "from spot.visualization import code_inline_type_masks, visualize_sequence, display\n",
    "\n",
    "\n",
    "if train_R1:\n",
    "    to_display = []\n",
    "    for xs in error_groups[\"return-value\"]: # seq_flatten(error_groups.values()):\n",
    "        src = xs[1]\n",
    "        code = code_inline_type_masks(src.origin_code, src.types)\n",
    "        to_display.append(\n",
    "            f\"feedback: {xs[0]}\\n\" + \"=========code=========\\n\" + add_line_numbers(code)\n",
    "        )\n",
    "    if len(to_display) > 0:\n",
    "        display(visualize_sequence(to_display))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback: MypyFeedback('[return-value]225:20: Incompatible return value type (got \"Tuple[ReturnCodes, Tuple[Any, Any]]\", expected \"Tuple[int, Tuple[str, str]]\") )'\n",
      "=========code=========\n",
      "  1|  from typing import Any, List, Tuple, Dict, Set # SPOT\n",
      "  2|  import importlib\n",
      "  3|  import os\n",
      "  4|  import subprocess\n",
      "  5|  import sys\n",
      "  6|  import tempfile\n",
      "  7|  from configparser import ConfigParser\n",
      "  8|  from pathlib import Path\n",
      "  9|  from typing import (\n",
      " 10|      TYPE_CHECKING,\n",
      " 11|      Any,\n",
      " 12|      Callable,\n",
      " 13|      Dict,\n",
      " 14|      List,\n",
      " 15|      Optional,\n",
      " 16|      Tuple,\n",
      " 17|      Union,\n",
      " 18|      no_type_check,\n",
      " 19|  )\n",
      " 20|  \n",
      " 21|  import py\n",
      " 22|  import pytest\n",
      " 23|  from _pytest._code import ExceptionInfo\n",
      " 24|  from _pytest._code.code import ReprEntry, ReprFileLocation, TerminalRepr\n",
      " 25|  from _pytest._io import TerminalWriter\n",
      " 26|  from _pytest.config import Config\n",
      " 27|  from mypy import build\n",
      " 28|  from mypy.fscache import FileSystemCache\n",
      " 29|  from mypy.main import process_options\n",
      " 30|  \n",
      " 31|  if TYPE_CHECKING:\n",
      " 32|      from _pytest._code.code import _TracebackStyle\n",
      " 33|  \n",
      " 34|  from pytest_mypy_plugins import utils\n",
      " 35|  from pytest_mypy_plugins.collect import File, YamlTestFile\n",
      " 36|  from pytest_mypy_plugins.utils import (\n",
      " 37|      OutputMatcher,\n",
      " 38|      TypecheckAssertionError,\n",
      " 39|      assert_expected_matched_actual,\n",
      " 40|      capture_std_streams,\n",
      " 41|      fname_to_module,\n",
      " 42|  )\n",
      " 43|  \n",
      " 44|  \n",
      " 45|  class TraceLastReprEntry(ReprEntry):\n",
      " 46|      def toterminal(self, tw: TerminalWriter/* TerminalWriter */) -> None/* None */:\n",
      " 47|          if not self.reprfileloc:\n",
      " 48|              return\n",
      " 49|  \n",
      " 50|          self.reprfileloc.toterminal(tw)\n",
      " 51|          for line in self.lines:\n",
      " 52|              red = line.startswith(\"E   \")\n",
      " 53|              tw.line(line, bold=True, red=red)\n",
      " 54|          return\n",
      " 55|  \n",
      " 56|  \n",
      " 57|  def make_files(rootdir: Path/* Path */, files_to_create: Dict[str, str]/* Dict[str, str] */) -> List[str]/* List[str] */:\n",
      " 58|      created_modules = []\n",
      " 59|      for rel_fpath, file_contents in files_to_create.items():\n",
      " 60|          fpath = rootdir / rel_fpath\n",
      " 61|          fpath.parent.mkdir(parents=True, exist_ok=True)\n",
      " 62|          fpath.write_text(file_contents)\n",
      " 63|  \n",
      " 64|          created_module = fname_to_module(fpath, root_path=rootdir)\n",
      " 65|          if created_module:\n",
      " 66|              created_modules.append(created_module)\n",
      " 67|      return created_modules\n",
      " 68|  \n",
      " 69|  \n",
      " 70|  def replace_fpath_with_module_name(line: str/* str */, rootdir: Path/* Path */) -> str/* str */:\n",
      " 71|      if \":\" not in line:\n",
      " 72|          return line\n",
      " 73|      out_fpath, res_line = line.split(\":\", 1)\n",
      " 74|      line = os.path.relpath(out_fpath, start=rootdir) + \":\" + res_line\n",
      " 75|      return line.strip().replace(\".py:\", \":\")\n",
      " 76|  \n",
      " 77|  \n",
      " 78|  def maybe_to_abspath(rel_or_abs: str/* str */, rootdir: Optional[Path]/* Optional[Path] */) -> str/* str */:\n",
      " 79|      rel_or_abs = os.path.expandvars(rel_or_abs)\n",
      " 80|      if rootdir is None or os.path.isabs(rel_or_abs):\n",
      " 81|          return rel_or_abs\n",
      " 82|      return str(rootdir / rel_or_abs)\n",
      " 83|  \n",
      " 84|  \n",
      " 85|  class ReturnCodes:\n",
      " 86|      SUCCESS = 0\n",
      " 87|      FAIL = 1\n",
      " 88|      FATAL_ERROR = 2\n",
      " 89|  \n",
      " 90|  \n",
      " 91|  def run_mypy_typechecking(cmd_options: List[str]/* Tuple[str, ...] */) -> int/* ReturnCodes */:\n",
      " 92|      fscache = FileSystemCache()\n",
      " 93|      sources, options = process_options(cmd_options, fscache=fscache)\n",
      " 94|  \n",
      " 95|      error_messages = []\n",
      " 96|  \n",
      " 97|      def flush_errors(new_messages: List[str]/* List[str] */, serious: bool/* bool */) -> None/* None */:\n",
      " 98|          error_messages.extend(new_messages)\n",
      " 99|          f = sys.stderr if serious else sys.stdout\n",
      "100|          try:\n",
      "101|              for msg in new_messages:\n",
      "102|                  f.write(msg + \"\\n\")\n",
      "103|              f.flush()\n",
      "104|          except BrokenPipeError:\n",
      "105|              sys.exit(ReturnCodes.FATAL_ERROR)\n",
      "106|  \n",
      "107|      try:\n",
      "108|          build.build(sources, options, flush_errors=flush_errors, fscache=fscache)\n",
      "109|  \n",
      "110|      except SystemExit as sysexit:\n",
      "111|          return /* error: Incompatible return value type (got \"int\", expected \"ReturnCodes\")  */sysexit.code\n",
      "112|      finally:\n",
      "113|          fscache.flush()\n",
      "114|  \n",
      "115|      if error_messages:\n",
      "116|          return /* error: Incompatible return value type (got \"int\", expected \"ReturnCodes\")  */ReturnCodes.FAIL\n",
      "117|  \n",
      "118|      return /* error: Incompatible return value type (got \"int\", expected \"ReturnCodes\")  */ReturnCodes.SUCCESS\n",
      "119|  \n",
      "120|  \n",
      "121|  class YamlTestItem(pytest.Item):\n",
      "122|      def __init__(\n",
      "123|          self,\n",
      "124|          name: str/* str */,\n",
      "125|          parent: Optional[YamlTestFile]/* Optional[Config] */ = None,\n",
      "126|          config: Optional[Config]/* Optional[Config] */ = None,\n",
      "127|          *,\n",
      "128|          files: List[File]/* List[YamlTestFile] */,\n",
      "129|          starting_lineno: int/* Optional[int] */,\n",
      "130|          expected_output: List[OutputMatcher]/* OutputMatcher */,\n",
      "131|          environment_variables: Dict[str, Any]/* Dict[str, str] */,\n",
      "132|          disable_cache: bool/* bool */,\n",
      "133|          mypy_config: str/* Config */,\n",
      "134|          parsed_test_data: Dict[str, Any]/* Dict[str, Any] */,\n",
      "135|          expect_fail: bool/* bool */,\n",
      "136|      ) -> None/* None */:\n",
      "137|          super().__init__(name, parent, config)\n",
      "138|          self.files = files\n",
      "139|          self.environment_variables = environment_variables\n",
      "140|          self.disable_cache = disable_cache\n",
      "141|          self.expect_fail = expect_fail\n",
      "142|          self.expected_output = expected_output\n",
      "143|          self.starting_lineno = starting_lineno\n",
      "144|          self.additional_mypy_config = mypy_config\n",
      "145|          self.parsed_test_data = parsed_test_data\n",
      "146|          self.same_process = self.config.option.mypy_same_process\n",
      "147|          self.test_only_local_stub = self.config.option.mypy_only_local_stub\n",
      "148|  \n",
      "149|          self.root_directory = self.config.option.mypy_testing_base\n",
      "150|          if self.config.option.mypy_ini_file:\n",
      "151|              self.base_ini_fpath = os.path.abspath(self.config.option.mypy_ini_file)\n",
      "152|          else:\n",
      "153|              self.base_ini_fpath = None\n",
      "154|          self.incremental_cache_dir = os.path.join(self.root_directory, \".mypy_cache\")\n",
      "155|  \n",
      "156|      def make_test_file(self, file: File/* YamlTestFile */) -> None/* None */:\n",
      "157|          current_directory = Path.cwd()\n",
      "158|          fpath = current_directory / file.path\n",
      "159|          fpath.parent.mkdir(parents=True, exist_ok=True)\n",
      "160|          fpath.write_text(file.content)\n",
      "161|  \n",
      "162|      def make_test_files_in_current_directory(self) -> None/* None */:\n",
      "163|          for file in self.files:\n",
      "164|              self.make_test_file(file)\n",
      "165|  \n",
      "166|      def remove_cache_files(self, fpath_no_suffix: Path/* Path */) -> None/* None */:\n",
      "167|          cache_file = Path(self.incremental_cache_dir)\n",
      "168|          cache_file /= \".\".join([str(part) for part in sys.version_info[:2]])\n",
      "169|          for part in fpath_no_suffix.parts:\n",
      "170|              cache_file /= part\n",
      "171|  \n",
      "172|          data_json_file = cache_file.with_suffix(\".data.json\")\n",
      "173|          if data_json_file.exists():\n",
      "174|              data_json_file.unlink()\n",
      "175|          meta_json_file = cache_file.with_suffix(\".meta.json\")\n",
      "176|          if meta_json_file.exists():\n",
      "177|              meta_json_file.unlink()\n",
      "178|  \n",
      "179|          for parent_dir in cache_file.parents:\n",
      "180|              if (\n",
      "181|                  parent_dir.exists()\n",
      "182|                  and len(list(parent_dir.iterdir())) == 0\n",
      "183|                  and str(self.incremental_cache_dir) in str(parent_dir)\n",
      "184|              ):\n",
      "185|                  parent_dir.rmdir()\n",
      "186|  \n",
      "187|      def typecheck_in_new_subprocess(\n",
      "188|          self, execution_path: Path/* Path */, mypy_cmd_options: List[Any]/* List[str] */\n",
      "189|      ) -> Tuple[int, Tuple[str, str]]/* Tuple[int, Tuple[str, str]] */:\n",
      "190|          import shutil\n",
      "191|  \n",
      "192|          mypy_executable = shutil.which(\"mypy\")\n",
      "193|          assert mypy_executable is not None, \"mypy executable is not found\"\n",
      "194|  \n",
      "195|          rootdir = getattr(getattr(self.parent, \"config\", None), \"rootdir\", None)\n",
      "196|          self._collect_python_path(rootdir, execution_path)\n",
      "197|          self._collect_mypy_path(rootdir)\n",
      "198|  \n",
      "199|          if \"SYSTEMROOT\" in os.environ:\n",
      "200|              self.environment_variables[\"SYSTEMROOT\"] = os.environ[\"SYSTEMROOT\"]\n",
      "201|  \n",
      "202|          completed = subprocess.run(\n",
      "203|              [mypy_executable, *mypy_cmd_options],\n",
      "204|              stdout=subprocess.PIPE,\n",
      "205|              stderr=subprocess.PIPE,\n",
      "206|              cwd=os.getcwd(),\n",
      "207|              env=self.environment_variables,\n",
      "208|          )\n",
      "209|          captured_stdout = completed.stdout.decode()\n",
      "210|          captured_stderr = completed.stderr.decode()\n",
      "211|          return completed.returncode, (captured_stdout, captured_stderr)\n",
      "212|  \n",
      "213|      def typecheck_in_same_process(\n",
      "214|          self, execution_path: Path/* Path */, mypy_cmd_options: List[Any]/* List[str] */\n",
      "215|      ) -> Tuple[int, Tuple[str, str]]/* Tuple[int, Tuple[str, str]] */:\n",
      "216|          with utils.temp_environ(), utils.temp_path(), utils.temp_sys_modules():\n",
      "217|              for key, val in self.environment_variables.items():\n",
      "218|                  os.environ[key] = val\n",
      "219|  \n",
      "220|              sys.path.insert(0, str(execution_path))\n",
      "221|  \n",
      "222|              with capture_std_streams() as (stdout, stderr):\n",
      "223|                  return_code = run_mypy_typechecking(/* error: Argument 1 to \"run_mypy_typechecking\" has incompatible type \"List[str]\"; expected \"Tuple[str, ...]\"  */mypy_cmd_options)\n",
      "224|  \n",
      "225|              return /* error: Incompatible return value type (got \"Tuple[ReturnCodes, Tuple[Any, Any]]\", expected \"Tuple[int, Tuple[str, str]]\")  */return_code, (stdout.getvalue(), stderr.getvalue())\n",
      "226|  \n",
      "227|      def execute_extension_hook(self) -> None/* None */:\n",
      "228|          extension_hook_fqname = self.config.option.mypy_extension_hook\n",
      "229|          module_name, func_name = extension_hook_fqname.rsplit(\".\", maxsplit=1)\n",
      "230|          module = importlib.import_module(module_name)\n",
      "231|          extension_hook = getattr(module, func_name)\n",
      "232|          extension_hook(self)\n",
      "233|  \n",
      "234|      def runtest(self) -> None/* None */:\n",
      "235|          try:\n",
      "236|              temp_dir = tempfile.TemporaryDirectory(prefix=\"pytest-mypy-\", dir=self.root_directory)\n",
      "237|  \n",
      "238|          except (FileNotFoundError, PermissionError, NotADirectoryError) as e:\n",
      "239|  \n",
      "240|              raise TypecheckAssertionError(\n",
      "241|                  error_message=f\"Testing base directory {self.root_directory} must exist and be writable\"\n",
      "242|              ) from e\n",
      "243|  \n",
      "244|          try:\n",
      "245|              execution_path = Path(temp_dir.name)\n",
      "246|  \n",
      "247|              with utils.cd(execution_path):\n",
      "248|                  if (\n",
      "249|                      hasattr(self.config.option, \"mypy_extension_hook\")\n",
      "250|                      and self.config.option.mypy_extension_hook is not None\n",
      "251|                  ):\n",
      "252|                      self.execute_extension_hook()\n",
      "253|  \n",
      "254|                  main_file = str(execution_path / \"main.py\")\n",
      "255|                  mypy_cmd_options = self.prepare_mypy_cmd_options(execution_path)\n",
      "256|                  mypy_cmd_options.append(main_file)\n",
      "257|  \n",
      "258|                  self.make_test_files_in_current_directory()\n",
      "259|  \n",
      "260|                  if self.same_process:\n",
      "261|                      returncode, (stdout, stderr) = self.typecheck_in_same_process(execution_path, mypy_cmd_options)\n",
      "262|                  else:\n",
      "263|                      returncode, (stdout, stderr) = self.typecheck_in_new_subprocess(execution_path, mypy_cmd_options)\n",
      "264|  \n",
      "265|                  mypy_output = stdout + stderr\n",
      "266|                  if returncode == ReturnCodes.FATAL_ERROR:\n",
      "267|                      print(mypy_output, file=sys.stderr)\n",
      "268|                      raise TypecheckAssertionError(error_message=\"Critical error occurred\")\n",
      "269|  \n",
      "270|                  output_lines = []\n",
      "271|                  for line in mypy_output.splitlines():\n",
      "272|                      output_line = replace_fpath_with_module_name(line, rootdir=execution_path)\n",
      "273|                      output_lines.append(output_line)\n",
      "274|                  try:\n",
      "275|                      assert_expected_matched_actual(expected=self.expected_output, actual=output_lines)\n",
      "276|                  except TypecheckAssertionError as e:\n",
      "277|                      if not self.expect_fail:\n",
      "278|                          raise e\n",
      "279|                  else:\n",
      "280|                      if self.expect_fail:\n",
      "281|                          raise TypecheckAssertionError(\"Expected failure, but test passed\")\n",
      "282|  \n",
      "283|          finally:\n",
      "284|              temp_dir.cleanup()\n",
      "285|              if not self.disable_cache:\n",
      "286|                  for file in self.files:\n",
      "287|                      path = Path(file.path)\n",
      "288|                      self.remove_cache_files(path.with_suffix(\"\"))\n",
      "289|  \n",
      "290|          assert not os.path.exists(temp_dir.name)\n",
      "291|  \n",
      "292|      def prepare_mypy_cmd_options(self, execution_path: Path/* Path */) -> List[str]/* List[str] */:\n",
      "293|          mypy_cmd_options = [\n",
      "294|              \"--show-traceback\",\n",
      "295|              \"--no-error-summary\",\n",
      "296|              \"--no-pretty\",\n",
      "297|              \"--hide-error-context\",\n",
      "298|          ]\n",
      "299|          if not self.test_only_local_stub:\n",
      "300|              mypy_cmd_options.append(\"--no-silence-site-packages\")\n",
      "301|          if not self.disable_cache:\n",
      "302|              mypy_cmd_options.extend([\"--cache-dir\", self.incremental_cache_dir])\n",
      "303|  \n",
      "304|          mypy_ini_config = ConfigParser()\n",
      "305|          if self.base_ini_fpath:\n",
      "306|              mypy_ini_config.read(self.base_ini_fpath)\n",
      "307|          if self.additional_mypy_config:\n",
      "308|              additional_config = self.additional_mypy_config\n",
      "309|              if \"[mypy]\" not in additional_config:\n",
      "310|                  additional_config = \"[mypy]\\n\" + additional_config\n",
      "311|              mypy_ini_config.read_string(additional_config)\n",
      "312|  \n",
      "313|          if mypy_ini_config.sections():\n",
      "314|              mypy_config_file_path = execution_path / \"mypy.ini\"\n",
      "315|              with mypy_config_file_path.open(\"w\") as f:\n",
      "316|                  mypy_ini_config.write(f)\n",
      "317|              mypy_cmd_options.append(f\"--config-file={str(mypy_config_file_path)}\")\n",
      "318|  \n",
      "319|          return mypy_cmd_options\n",
      "320|  \n",
      "321|      def repr_failure(\n",
      "322|          self, excinfo: ExceptionInfo[BaseException]/* ExceptionInfo */, style: Optional[\"_TracebackStyle\"]/* Optional[_TracebackStyle] */ = None\n",
      "323|      ) -> Union[str, TerminalRepr]/* ExceptionInfo */:\n",
      "324|          if excinfo.errisinstance(SystemExit):\n",
      "325|              return excinfo.exconly(tryshort=True)\n",
      "326|          elif excinfo.errisinstance(TypecheckAssertionError):\n",
      "327|              exception_repr = excinfo.getrepr(style=\"short\")\n",
      "328|              exception_repr.reprcrash.message = \"\"  \n",
      "329|              repr_file_location = ReprFileLocation(\n",
      "330|                  path=self.fspath, lineno=self.starting_lineno + excinfo.value.lineno, message=\"\"  \n",
      "331|              )\n",
      "332|              repr_tb_entry = TraceLastReprEntry(\n",
      "333|                  exception_repr.reprtraceback.reprentries[-1].lines[1:], None, None, repr_file_location, \"short\"\n",
      "334|              )\n",
      "335|              exception_repr.reprtraceback.reprentries = [repr_tb_entry]\n",
      "336|              return exception_repr\n",
      "337|          else:\n",
      "338|              return super().repr_failure(excinfo, style=\"native\")\n",
      "339|  \n",
      "340|      @no_type_check\n",
      "341|      def reportinfo(self) -> Tuple[Union[py.path.local, Path, str], Optional[int], str]/* Tuple[Optional[str], Optional[str], str] */:\n",
      "342|          path = getattr(self, \"path\", None) or getattr(self, \"fspath\")\n",
      "343|          return path, None, self.name\n",
      "344|  \n",
      "345|      def _collect_python_path(\n",
      "346|          self,\n",
      "347|          rootdir: Optional[Path]/* Path */,\n",
      "348|          execution_path: Path/* Path */,\n",
      "349|      ) -> None/* None */:\n",
      "350|          python_path_parts = []\n",
      "351|  \n",
      "352|          existing_python_path = os.environ.get(\"PYTHONPATH\")\n",
      "353|          if existing_python_path:\n",
      "354|              python_path_parts.append(existing_python_path)\n",
      "355|          if execution_path:\n",
      "356|              python_path_parts.append(str(execution_path))\n",
      "357|          python_path_key = self.environment_variables.get(\"PYTHONPATH\")\n",
      "358|          if python_path_key:\n",
      "359|              python_path_parts.append(maybe_to_abspath(python_path_key, rootdir))\n",
      "360|              python_path_parts.append(python_path_key)\n",
      "361|  \n",
      "362|          self.environment_variables[\"PYTHONPATH\"] = \":\".join(python_path_parts)\n",
      "363|  \n",
      "364|      def _collect_mypy_path(self, rootdir: Optional[Path]/* Path */) -> None/* None */:\n",
      "365|          mypy_path_parts = []\n",
      "366|  \n",
      "367|          existing_mypy_path = os.environ.get(\"MYPYPATH\")\n",
      "368|          if existing_mypy_path:\n",
      "369|              mypy_path_parts.append(existing_mypy_path)\n",
      "370|          if self.base_ini_fpath:\n",
      "371|              mypy_path_parts.append(os.path.dirname(self.base_ini_fpath))\n",
      "372|          mypy_path_key = self.environment_variables.get(\"MYPYPATH\")\n",
      "373|          if mypy_path_key:\n",
      "374|              mypy_path_parts.append(maybe_to_abspath(mypy_path_key, rootdir))\n",
      "375|              mypy_path_parts.append(mypy_path_key)\n",
      "376|  \n",
      "377|          self.environment_variables[\"MYPYPATH\"] = \":\".join(mypy_path_parts)\n",
      "378|  \n"
     ]
    }
   ],
   "source": [
    "print(to_display[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R1 training\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from spot.data import SrcDataset, get_dataset_name\n",
    "from spot.model import CtxArgs, DecodingArgs, ModelSPOT, ModelWrapper\n",
    "\n",
    "r1_model_name = \"R1-model--\" + config.as_name()\n",
    "\n",
    "if not load_trained:\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        name=r1_model_name,\n",
    "        config=config.as_dict(),\n",
    "        dir=str(datadir),\n",
    "    )\n",
    "\n",
    "    r1_train_args = copy(train_args)\n",
    "    r1_train_args.max_epochs = 1\n",
    "\n",
    "    r1_wrapper, r1_extra = train_spot_model(\n",
    "        r1_src_datasets,\n",
    "        r1_model_name,\n",
    "        train_args=r1_train_args,\n",
    "        gpus=[gpu_id],\n",
    "        record_batches=False,\n",
    "        quicktest=config.quicktest,\n",
    "        use_early_stop=False,\n",
    "        use_small_model=config.use_small_model,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No cache found at: /mnt/data0/jiayi/checkpoints/lit-saved/R1-model--all_labels=True/eval_cache, skip clearing.\n",
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:14<00:00, 64.89it/s]\n",
      "verify_labels: 100%|██████████| 1637/1637 [00:00<00:00, 15724.40it/s]\n",
      "predict: 100%|██████████| 1637/1637 [06:27<00:00,  4.22it/s]\n",
      "map type_check_src_in_project: 100%|██████████| 933/933 [02:04<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_check_success_ratio: 1\n",
      "feedbacks_per_file:\n",
      "   mean: 2.2851\n",
      "   median: 0\n",
      "   min: 0\n",
      "   max: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feedbacks_to_tokenized_src: 100%|██████████| 933/933 [00:06<00:00, 151.15it/s]\n",
      "inline_predictions: 100%|██████████| 933/933 [00:35<00:00, 25.92it/s]\n",
      "chunk_srcs_per_file: 100%|██████████| 933/933 [00:14<00:00, 64.02it/s]\n",
      "verify_labels: 100%|██████████| 1659/1659 [00:00<00:00, 15586.34it/s]\n",
      "predict: 100%|██████████| 1659/1659 [07:12<00:00,  3.83it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c802417c664d4aeeb9414464a3c7ab31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(HTML(value=\"<div style='white-space: pre-wrap; line-height: 1.2; fo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load trained model and evaluate\n",
    "from spot.train import evaluate_model\n",
    "from spot.visualization import visualize_dicts\n",
    "\n",
    "r1_wrapper = ModelWrapper.from_pretrained(\n",
    "    datadir / f\"checkpoints/lit-saved/{r1_model_name}\"\n",
    ")\n",
    "r1_wrapper.to(device)\n",
    "\n",
    "r1_cache = PickleCache(datadir / f\"checkpoints/lit-saved/{r1_model_name}/eval_cache\")\n",
    "r1_cache.clear()\n",
    "r1_eval = evaluate_model(\n",
    "    r0_wrapper,\n",
    "    r1_wrapper,\n",
    "    src_datasets[\"test\"],\n",
    "    tc_args=tc_args,\n",
    "    eval_cache=r1_cache,\n",
    ")\n",
    "visualize_dicts([x[1].accuracies for x in r1_eval])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting: 100%|██████████| 166/166 [00:01<00:00, 100.50it/s]\n",
      "Computing accuracies: 100%|██████████| 166/166 [00:00<00:00, 11120.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from spot.visualization import export_preds_on_code, display_persist, proj_root\n",
    "\n",
    "eval_to_viz = r1_eval[1][1]\n",
    "sub_ids = range(0, len(eval_to_viz.chunks), 10)\n",
    "export_preds_on_code(\n",
    "    eval_to_viz.chunks[sub_ids],\n",
    "    [eval_to_viz.predictions[i] for i in sub_ids],\n",
    "    {},\n",
    "    export_to=proj_root() / \"R1_predictions\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a546d61f2aa3427a94c9bde1caff1b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='round', max=1), IntSlider(value=10, continuous_update=Fa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spot.visualization import visualize_conf_matrix\n",
    "\n",
    "visualize_conf_matrix({n: x[1] for n, x in zip([\"R0\", \"R1\"], r1_eval)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spot.utils import pretty_show_dict\n",
    "\n",
    "if not load_trained:\n",
    "    for i, e in enumerate(r1_eval):\n",
    "        wandb.log({f\"test/R{i}\": wandb_string(pretty_show_dict(e[1].accuracies))})\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1486fe85182649d99d5a9f540f7c3d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='i', max=1204), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39776ca377f143299c9206674c544d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Output(),), layout=Layout(overflow='scroll'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f6de56f494403b901e5c52240341aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value=\"<pre style='line-height: 1.2; padding: 10px; color: rgb(212,212,212); background-col…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "from spot.visualization import visualize_preds_on_code\n",
    "\n",
    "round = 1\n",
    "pred_dataset = r1_eval[round][1].chunks\n",
    "visualize_preds_on_code(pred_dataset, r1_eval[round][1].predictions)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
