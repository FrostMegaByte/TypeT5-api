{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from spot.data import get_tk_dataset_name, load_tokenized_srcsets\n",
    "from spot.function_dataset import data_project_from_dir\n",
    "from spot.model import ModelWrapper\n",
    "from spot.train import TrainingConfig, PreprocessArgs\n",
    "from spot.type_env import AccuracyMetric\n",
    "from spot.utils import (\n",
    "    PickleCache,\n",
    "    assert_eq,\n",
    "    get_dataroot,\n",
    "    get_dataset_dir,\n",
    "    get_eval_dir,\n",
    "    get_gpu_id,\n",
    "    get_model_dir,\n",
    "    pickle_dump,\n",
    "    pmap,\n",
    "    pretty_print_dict,\n",
    "    pretty_show_dict,\n",
    "    proj_root,\n",
    "    run_long_task,\n",
    "    write_file,\n",
    ")\n",
    "from spot.visualization import string_to_html\n",
    "from termcolor import colored\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "\n",
    "def wandb_string(s: str):\n",
    "    return wandb.Html(string_to_html(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU_ID not set, using: 1\n",
      "\u001b[32mUse GPU: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# experiment configurations\n",
    "quicktest = False\n",
    "\n",
    "gpu_id = get_gpu_id(1)\n",
    "model_name = \"model-v6--TrainingConfig(func_only=False, left_margin=2048, preamble_size=800, right_margin=1536)\"\n",
    "pre_args = PreprocessArgs()\n",
    "dataset_name = \"ManyTypes4Py\"\n",
    "# dataset_name = \"SPOT-src\"\n",
    "experiment_name = dataset_name + \": \" + model_name\n",
    "\n",
    "print(colored(f\"Use GPU: {gpu_id}\", \"green\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test projects: 100%|██████████| 50/50 [00:20<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TokenizedSrcSets:  /mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs()\n",
      "258M\t/mnt/nas/jiayi/SPOT/TokenizedSrcSets/ManyTypes4Py-v5-PreprocessArgs()\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "# model = ModelWrapper.from_pretrained(get_model_dir() / model_name)\n",
    "# device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# print(f\"Model loaded to {device}\")\n",
    "\n",
    "# load test projects\n",
    "repos_dir = get_dataset_dir(dataset_name) / \"repos\" / \"test\"\n",
    "test_repo_paths = [f for f in repos_dir.iterdir() if f.is_dir()]\n",
    "test_projects = pmap(\n",
    "    data_project_from_dir,\n",
    "    test_repo_paths,\n",
    "    desc=\"Loading test projects\",\n",
    ")\n",
    "assert len(test_projects) > 0\n",
    "\n",
    "sdata_name = get_tk_dataset_name(dataset_name, pre_args, func_only=False)\n",
    "sdata_path = get_dataroot() / \"TokenizedSrcSets\" / sdata_name\n",
    "tk_dataset = load_tokenized_srcsets(\n",
    "    sdata_path,\n",
    "    quicktest=quicktest,\n",
    "    sets_to_load=[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "from spot.function_decoding import (\n",
    "    DecodingOrders,\n",
    "    EvalResult,\n",
    "    PreprocessArgs,\n",
    "    RolloutCtx,\n",
    "    sigmap_from_file_predictions,\n",
    ")\n",
    "from spot.static_analysis import SignatureErrorAnalysis\n",
    "\n",
    "# ctx_args = model.args.ctx_args\n",
    "# model.args.sampling_max_tokens = ctx_args.ctx_size\n",
    "# model.args.do_sample = False\n",
    "# model.args.num_beams = 10\n",
    "# model.args.tokens_per_type = 16\n",
    "\n",
    "eval_cache = PickleCache(get_eval_dir(dataset_name, model_name) / \"eval_cache\")\n",
    "# eval_cache.clear()\n",
    "pre_r = eval_cache.cached(\n",
    "    \"dataset_pred.pkl\",\n",
    "    lambda: model.eval_on_dataset(tk_dataset[\"test\"]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_acc:\n",
      "   plain_acc: 67.46% (count=15.7k)\n",
      "   plain_acc_by_common:\n",
      "      rare: 52.61% (count=5.6k)\n",
      "      common: 75.62% (count=10.1k)\n",
      "   plain_acc_by_cat:\n",
      "      FuncArg: 65.21% (count=8.0k)\n",
      "      FuncReturn: 75.88% (count=5.8k)\n",
      "      ClassAtribute: 50.87% (count=1.8k)\n",
      "      GlobalVar: 66.36% (count=107)\n",
      "   plain_acc_label_size: 1.4194\n",
      "   plain_acc_pred_size: 1.3838\n",
      "   plain_acc_ignored_labels: 0\n",
      "   n_skipped_types: 0\n",
      "   n_missing_types: 53\n",
      "acc:\n",
      "   acc: 67.47% (count=13.2k)\n",
      "   acc_by_common:\n",
      "      rare: 55.59% (count=5.6k)\n",
      "      common: 76.11% (count=7.6k)\n",
      "   acc_by_cat:\n",
      "      FuncArg: 66.93% (count=6.7k)\n",
      "      FuncReturn: 68.01% (count=4.9k)\n",
      "      ClassAtribute: 67.73% (count=1.5k)\n",
      "      GlobalVar: 72.73% (count=99)\n",
      "   acc_label_size: 1.3155\n",
      "   acc_pred_size: 1.2906\n",
      "   acc_ignored_labels: 2521\n",
      "   n_skipped_types: 0\n",
      "   n_missing_types: 53\n",
      "base_acc:\n",
      "   base_acc: 74.71% (count=13.2k)\n",
      "   base_acc_by_common:\n",
      "      rare: 62.27% (count=4.8k)\n",
      "      common: 81.79% (count=8.4k)\n",
      "   base_acc_by_cat:\n",
      "      FuncArg: 74.06% (count=6.7k)\n",
      "      FuncReturn: 74.73% (count=4.9k)\n",
      "      ClassAtribute: 77.26% (count=1.5k)\n",
      "      GlobalVar: 78.79% (count=99)\n",
      "   base_acc_label_size: 1\n",
      "   base_acc_pred_size: 1\n",
      "   base_acc_ignored_labels: 2521\n",
      "   n_skipped_types: 0\n",
      "   n_missing_types: 53\n"
     ]
    }
   ],
   "source": [
    "common_names = ModelWrapper.load_common_type_names(get_model_dir() / model_name)\n",
    "pred_map, label_map = sigmap_from_file_predictions(pre_r, test_projects, repos_dir)\n",
    "accs = {\n",
    "    m.name: SignatureErrorAnalysis(pred_map, label_map, m).accuracies\n",
    "    for m in AccuracyMetric.default_metrics(common_names)\n",
    "}\n",
    "\n",
    "pretty_print_dict(accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
