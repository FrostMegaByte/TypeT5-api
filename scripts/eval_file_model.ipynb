{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from spot.data import get_tk_dataset_name\n",
    "from spot.function_dataset import data_project_from_dir\n",
    "from spot.model import ModelWrapper\n",
    "from spot.train import TrainingConfig, PreprocessArgs\n",
    "from spot.type_env import AccuracyMetric\n",
    "from spot.utils import (\n",
    "    PickleCache,\n",
    "    assert_eq,\n",
    "    get_dataroot,\n",
    "    get_dataset_dir,\n",
    "    get_eval_dir,\n",
    "    get_gpu_id,\n",
    "    get_model_dir,\n",
    "    pickle_dump,\n",
    "    pmap,\n",
    "    pretty_print_dict,\n",
    "    pretty_show_dict,\n",
    "    proj_root,\n",
    "    run_long_task,\n",
    "    write_file,\n",
    ")\n",
    "from spot.visualization import string_to_html\n",
    "from termcolor import colored\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "\n",
    "def wandb_string(s: str):\n",
    "    return wandb.Html(string_to_html(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU_ID not set, using: 1\n",
      "\u001b[32mUse GPU: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# experiment configurations\n",
    "quicktest = False\n",
    "\n",
    "gpu_id = get_gpu_id(1)\n",
    "# model_name = \"model-v6--TrainingConfig(func_only=False, left_margin=2048, preamble_size=800, right_margin=1536)\"\n",
    "model_name = \"model-v6--TrainingConfig(func_only=False, imports_in_preamble=False, stub_in_preamble=False, left_margin=2048, right_margin=1536)\"\n",
    "pre_args = PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n",
    "# dataset_name = \"ManyTypes4Py\"\n",
    "dataset_name = \"InferTypes4Py\"\n",
    "# dataset_name = \"SPOT-src\"\n",
    "experiment_name = dataset_name + \": \" + model_name\n",
    "\n",
    "print(colored(f\"Use GPU: {gpu_id}\", \"green\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TokenizedSrcSets:  /mnt/nas/jiayi/SPOT/TokenizedSrcSets/InferTypes4Py-v5-PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n",
      "2.4M\t/mnt/nas/jiayi/SPOT/TokenizedSrcSets/InferTypes4Py-v5-PreprocessArgs(imports_in_preamble=False, stub_in_preamble=False)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "from spot.data import load_tokenized_srcsets, create_tokenized_srcsets\n",
    "\n",
    "sdata_name = get_tk_dataset_name(dataset_name, pre_args, func_only=False)\n",
    "sdata_path = get_dataroot() / \"TokenizedSrcSets\" / sdata_name\n",
    "recreate=False\n",
    "if recreate or not sdata_path.exists():\n",
    "    create_tokenized_srcsets(\n",
    "        dataset_name,\n",
    "        sdata_path,\n",
    "        func_only=False,\n",
    "        pre_args=pre_args,\n",
    "    )\n",
    "tk_dataset = load_tokenized_srcsets(\n",
    "    sdata_path,\n",
    "    quicktest=quicktest,\n",
    "    sets_to_load=[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "from spot.function_decoding import (\n",
    "    DecodingOrders,\n",
    "    EvalResult,\n",
    "    PreprocessArgs,\n",
    "    RolloutCtx,\n",
    ")\n",
    "from spot.function_dataset import sigmap_from_file_predictions\n",
    "from spot.static_analysis import SignatureErrorAnalysis\n",
    "\n",
    "# load model\n",
    "model = ModelWrapper.from_pretrained(get_model_dir() / model_name)\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "ctx_args = model.args.ctx_args\n",
    "model.args.sampling_max_tokens = ctx_args.ctx_size\n",
    "model.args.do_sample = False\n",
    "model.args.num_beams = 10\n",
    "model.args.tokens_per_type = 16\n",
    "\n",
    "eval_cache = PickleCache(get_eval_dir(dataset_name, model_name) / f\"{pre_args}\")\n",
    "# eval_cache.clear()\n",
    "pre_r = eval_cache.cached(\n",
    "    \"DatasetPredResult.pkl\",\n",
    "    lambda: model.eval_on_dataset(tk_dataset[\"test\"]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test projects: 100%|██████████| 3/3 [00:10<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_acc:\n",
      "   plain_acc: 68.80% (count=2.7k)\n",
      "   plain_acc_by_common:\n",
      "      rare: 51.64% (count=916)\n",
      "      common: 77.83% (count=1.7k)\n",
      "   plain_acc_by_simple:\n",
      "      complex: 54.35% (count=863)\n",
      "      simple: 75.75% (count=1.8k)\n",
      "   plain_acc_by_cat:\n",
      "      FuncArg: 68.73% (count=1.8k)\n",
      "      FuncReturn: 72.62% (count=650)\n",
      "      ClassAtribute: 58.61% (count=244)\n",
      "      GlobalVar: 100.00% (count=4)\n",
      "   plain_acc_label_size: 1.7192\n",
      "   plain_acc_pred_size: 1.6417\n",
      "   plain_acc_ignored_labels: 0\n",
      "   n_missing_types: 2\n",
      "acc:\n",
      "   acc: 68.95% (count=2.5k)\n",
      "   acc_by_common:\n",
      "      rare: 53.28% (count=916)\n",
      "      common: 78.06% (count=1.6k)\n",
      "   acc_by_simple:\n",
      "      complex: 54.04% (count=731)\n",
      "      simple: 75.14% (count=1.8k)\n",
      "   acc_by_cat:\n",
      "      FuncArg: 68.72% (count=1.6k)\n",
      "      FuncReturn: 71.45% (count=613)\n",
      "      ClassAtribute: 64.46% (count=242)\n",
      "      GlobalVar: 0.00% (count=1)\n",
      "   acc_label_size: 1.6482\n",
      "   acc_pred_size: 1.5636\n",
      "   acc_ignored_labels: 164\n",
      "   n_missing_types: 2\n",
      "base_acc:\n",
      "   base_acc: 77.78% (count=2.5k)\n",
      "   base_acc_by_common:\n",
      "      rare: 66.47% (count=662)\n",
      "      common: 81.87% (count=1.8k)\n",
      "   base_acc_by_simple:\n",
      "      simple: 77.78% (count=2.5k)\n",
      "   base_acc_by_cat:\n",
      "      FuncArg: 77.64% (count=1.6k)\n",
      "      FuncReturn: 78.96% (count=613)\n",
      "      ClassAtribute: 76.03% (count=242)\n",
      "      GlobalVar: 0.00% (count=1)\n",
      "   base_acc_label_size: 1\n",
      "   base_acc_pred_size: 1\n",
      "   base_acc_ignored_labels: 164\n",
      "   n_missing_types: 2\n"
     ]
    }
   ],
   "source": [
    "repos_dir = get_dataset_dir(dataset_name) / \"repos\" / \"test\"\n",
    "test_repo_paths = [f for f in repos_dir.iterdir() if f.is_dir()]\n",
    "test_projects = pmap(\n",
    "    data_project_from_dir,\n",
    "    test_repo_paths,\n",
    "    desc=\"Loading test projects\",\n",
    ")\n",
    "assert len(test_projects) > 0\n",
    "\n",
    "common_names = ModelWrapper.load_common_type_names(get_model_dir() / model_name)\n",
    "pred_map, label_map = sigmap_from_file_predictions(pre_r, test_projects, repos_dir)\n",
    "accs = {\n",
    "    m.name: SignatureErrorAnalysis(pred_map, label_map, m).accuracies\n",
    "    for m in AccuracyMetric.default_metrics(common_names)\n",
    "}\n",
    "\n",
    "pretty_print_dict(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting: 100%|██████████| 1851/1851 [00:16<00:00, 114.20it/s]\n",
      "Computing accuracies: 100%|██████████| 1851/1851 [00:00<00:00, 12425.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from spot.utils import decode_tokens, Path\n",
    "from spot.visualization import export_preds_on_code\n",
    "\n",
    "export_to = Path(f\"caches/model_predictions/eval_file_model/{dataset_name}\")\n",
    "export_preds_on_code(pre_r.chunks, pre_r.predictions, export_to, AccuracyMetric(common_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
